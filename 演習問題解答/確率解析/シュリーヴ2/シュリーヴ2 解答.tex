\documentclass[uplatex]{jsarticle}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{mathtools}

\usepackage{xcolor}
\usepackage[dvipdfmx]{graphicx}


\usepackage{applekeys}
\usepackage{mandorasymb}
\usepackage{ulem}
\usepackage{braket}
\usepackage{framed}


%%%%%ハイパーリンク
\usepackage[setpagesize=false,dvipdfmx]{hyperref}
\usepackage{aliascnt}
\hypersetup{
    colorlinks=true,
    citecolor=blue,
    linkcolor=blue,
    urlcolor=blue,
}
%%%%%ハイパーリンク




%%%%%図式
\usepackage{tikz}%%%図
\usetikzlibrary{arrows}
\usepackage{amscd}%%%簡単な図式
%%%%%図式


%%%%%%%%%%%%定理環境%%%%%%%%%%%%
%%%%%%%%%%%%定理環境%%%%%%%%%%%%
%%%%%%%%%%%%定理環境%%%%%%%%%%%%

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{thm}{定理}[section]
\newcommand{\thmautorefname}{定理}

\newaliascnt{prop}{thm}%%%カウンター「prop」の定義（thmと同じ）
\newtheorem{prop}[prop]{命題}
\aliascntresetthe{prop}
\newcommand{\propautorefname}{命題}%%%カウンター名propは「命題」で参照する

\newaliascnt{cor}{thm}
\newtheorem{cor}[cor]{系}
\aliascntresetthe{cor}
\newcommand{\corautorefname}{系}

\newaliascnt{lem}{thm}
\newtheorem{lem}[lem]{補題}
\aliascntresetthe{lem}
\newcommand{\lemautorefname}{補題}

\newaliascnt{defi}{thm}
\newtheorem{defi}[defi]{定義}
\aliascntresetthe{defi}
\newcommand{\defiautorefname}{定義}

\newaliascnt{prob}{thm}
\newtheorem{prob}[prob]{練習問題}
\aliascntresetthe{prob}
\newcommand{\probautorefname}{練習問題}


%%%%%%%番号づけない定理環境
\newtheorem*{exam*}{例}
\newtheorem*{rrem*}{ゆじノート}
\newtheorem*{question*}{疑問}
\newtheorem*{defi*}{定義}

\newtheorem*{nikki*}{日記}

%%%証明環境を「proof」から「証明.」に変えるやつ
\renewcommand\proofname{\bf 解答.}
\renewcommand{\qedsymbol}{\kinoposymbniko}


%%%%%%%%%%%%定理環境%%%%%%%%%%%%
%%%%%%%%%%%%定理環境%%%%%%%%%%%%
%%%%%%%%%%%%定理環境%%%%%%%%%%%%




%%%%%箇条書き環境
\usepackage[]{enumitem}

\makeatletter
\AddEnumerateCounter{\fnsymbol}{\c@fnsymbol}{9}%%%%fnsymbolという文字をenumerate環境のパラメーターで使えるようにする。
\makeatother

\renewcommand{\theenumi}{(\arabic{enumi})}%%%%%itemは(1),(2),(3)で番号付ける。
\renewcommand{\labelenumi}{\theenumi}
%%%%%箇条書き環境


\usepackage{latexsym}
\renewcommand{\emptyset}{\varnothing}
\def\ep{\varepsilon}
\def\id{\mathrm{id}}

\def\C{\mathbb{C}}
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\P{\mathbb{P}}


\def\E{\mathbb{E}}
\def\I{\mathbb{I}}

\def\mcA{\mathcal{A}}
\def\mcB{\mathcal{B}}
\def\mcC{\mathcal{C}}
\def\mcD{\mathcal{D}}
\def\mcE{\mathcal{E}}
\def\mcF{\mathcal{F}}
\def\mcG{\mathcal{G}}
\def\mcH{\mathcal{H}}
\def\mcI{\mathcal{I}}
\def\mcJ{\mathcal{J}}
\def\mcK{\mathcal{K}}
\def\mcL{\mathcal{L}}
\def\mcM{\mathcal{M}}
\def\mcN{\mathcal{N}}
\def\mcO{\mathcal{O}}
\def\mcP{\mathcal{P}}
\def\mcQ{\mathcal{Q}}
\def\mcR{\mathcal{R}}
\def\mcS{\mathcal{S}}
\def\mcT{\mathcal{T}}
\def\mcU{\mathcal{U}}
\def\mcV{\mathcal{V}}
\def\mcW{\mathcal{W}}
\def\mcX{\mathcal{X}}
\def\mcY{\mathcal{Y}}
\def\mcZ{\mathcal{Z}}

\def\dfn{:\overset{\mbox{{\scriptsize def}}}{=}}

\renewcommand{\ae}{\text{a.e.}}
\newcommand{\as}{\text{a.s.}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}

\allowdisplaybreaks[1]

\begin{document}


\title{シュリーヴ ファイナンスのための確率解析 II 解答}

\date{\today}
\author{ゆじとも}

\maketitle

\begin{abstract}
  このノートはS.E.シュリーヴ氏による「ファイナンスのための確率解析 II」の練習問題の解答である。
  問題文は端折って書いている。
  解いていない問題：\autoref{prob: 7.1} \ref{enumi: 7.1-8}から\ref{enumi: 7.1-11}、
  \autoref{prob: 7.2}、\autoref{prob: 7.5}、\autoref{prob: 7.6}。
\end{abstract}

\tableofcontents

\


\begin{nikki*}
  以下は日記とかノートとかがごっちゃになったもの。
  解答はそのあとにあります。
  \begin{itemize}
    \item
    2020.5.13 (水)：
    購入。1章の内容は測度論の授業でなんとなくやってた。なつかしい。
    簡単に復習して、\autoref{prob: 1.9}までやった。
    \item
    2020.5.14 (木)：
    1章の残りの演習を終わらせた。
    2章を読みつつ\autoref{prob: 2.4}までやった。
    条件付き期待値は保健数学の授業などで扱ったことがあったはずだけど、
    全く覚えてなかった。
    \item
    2020.5.15 (金)：
    2章の残りの演習を終わらせた。
    3章を読みつつ\autoref{prob: 3.6}までやった。
    演習をやっていると条件つき期待値の扱いに慣れてくるなあと思った。
    ブラウン運動やマルコフ過程の定義を初めて知った。
    \item
    2020.5.16 (土)：
    3章の残りの演習を終わらせた。
    2次変分というこの分野特有の概念にあまり慣れてない
    (3章の演習をやってもわかった感が得られない)
    ので4章を読みながら復習。
    伊藤積文の話に2次変分がたくさん出てくるから、
    4章を読みつつ復習して慣れていけばいいかなと思った。
    4章に書いてあることは、
    基本的には、伊藤積文の定義、伊藤の公式、それに関する例、の3種類だけ。
    \autoref{prob: 4.9}までやった。
    伊藤の公式を使って確率微分方程式を解くのは楽しいが、
    ただの式変形の問題は (\TeX に打つのが) つらい。
    \item
    2020.5.17 (日)：
    朝起きて思った。数学科だから数学はやればわかる。
    これはやるだけ。難しくない。
    でも世間知らずだから金融っぽいことがわからない。
    これがわからないとこの本は多分全然価値がない！！！
    ヨーロピアン・コール・オプションて何！！！
    というわけで今日は4.5節をきっちりと理解することを目標にする
    (適宜前の章に戻る)。
    こういうのって演習問題やってても理解できないパートな気がする。
    だってこの本の演習問題って数学的にはすでにちゃんと定式化されてる問題だから。
    でも本当は現実に起こっている状況をどう数学的に定式化するか、
    という部分の方も、数学的に処理する部分と同等か、それ以上に大切なはず。
    1巻買うのもあり。
    メモ：
    \begin{itemize}
      \item
      \textbf{金融商品}：なんか時間ごとに価格の変わる商品。
      金とか、株とか、原油とか。
      \item
      \textbf{デリバティブ}：
      基礎となる別の金融商品があって、
      その価値の変動に応じて相対的に価値が決まっていく派生した商品。
      \item
      \textbf{オプション}：デリバティブの一種。
      基礎となる金融商品 (\textbf{原資産}) \(A\)が何かあって、
      \(A\)を時刻 (\textbf{満期}) \(T\)までに、
      固定された金額 (\textbf{権利行使価格}) \(K\)で、
      「買ったり売ったりする権利」
      がオプションという金融商品。
      「買う権利」を\textbf{コール・オプション}、
      「売る権利」を\textbf{プット・オプション}という。
      次の例を見るとわかりやすい？：
      \begin{framed}
        \begin{exam*}
          \textbf{ヨーロピアン・オプション}というオプションの例がある。
          これは満期においてのみ購入した権利を行使することができる、
          というタイプのオプションである。
          たとえば私が
          (ある金融商品\(A\)から派生した)
          ヨーロピアン・コール・オプションを購入した場合、
          満期\(T\)において商品\(A\)を
          (\(A\)の時刻\(T\)における価格に関わらず!!)
          権利行使価格\(K\)で買うことができる
          (買わないという選択をとることもできる)。
          \(A\)の時刻\(T\)での価格が\(K\)より低いこともある。
          この場合は\(A\)を買ったら損だから買わない方がいい。
          \(A\)の時刻\(T\)での価格が\(K\)より高いなら、
          買った方がお得なので買った方がいい感じ？
        \end{exam*}
      \end{framed}
      オプションの価格を\textbf{プレミアム}という。
      次は
      \href{https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E5%8F%96%E5%BC%95}
      {Wikipedia}
      の例を個人的に書き換えたもの：
      \begin{framed}
        \begin{exam*}
          以下の設定で考える：
          \begin{itemize}
            \item
            原資産を金とする。
            金の時刻\(t\)での価値を\(K(t)\)とする。
            \item
            二人の投資家\(A\)さんと\(B\)さんがいる。
            \(A\)さんは\textbf{金を保有しているとは限らない}とする。
            \item
            現在 (時刻\(0\)とする)
            の金の価値は\(1\)kgあたり\(10\)万円とする。
            つまり\(K(0)=10\)とする。
            \item
            \textbf{オプションを売る側の視点に立つ}。
            \(A\)さんは\(1\)年後に金の価値\(K\)が下がると予想した。
            つまり\(K(1) < 10\)と予想した。
            このとき
            \begin{center}
              「\(1\)年後に金を\(1\)kgを\(10\)万円で
               (\(A\)さんから) 買う権利」

              = 「ヨーロピアン・プット・オプション」
            \end{center}
            を\(A\)さんが\(c\)万円で販売すると
             (\(A\)さんの予想通りの金の価格の変動になれば)
            利益が生じる。
            つまり、別の人\(B\)さんがこのオプションを
            \(A\)さんから\(c\)万円購入し、
            実際に\(K(1)<10\)となれば、
            \(B\)さんは
            「\(A\)さんから金\(1\)kgを\(10\)万円で買う権利」
            を行使するよりも、
            「普通に金\(1\)kgを\(K(1)\)万円で金を買う」
            方がお得だから、
            「\textbf{買う権利を放棄}」することとなり、
            \(c\)万円は\(A\)さんの利益となる。
            \(B\)さんの損失はオプションの購入価格、つまり\(c\)万円だけである。

            買う権利を放棄しなかった場合でも、
            \(A\)さんが\(K(1)\)万円で金\(1\)kgを買って
            \(10\)万円でその金\(1\)kgを\(A'\)さんに売れば、
            差額\(10-K(1) > 0\)万円
            (とオプションの販売価格\(c\)万円)
            は\(A\)さんの利益である。

            以上から、\(A\)さんは上のオプションを販売することにした。
            \item
            \textbf{オプションを買う側の視点に立つ}。
            \(B\)さんは\(1\)年後に金の価値\(K\)が上がり、
            \(K(1) > 10 + c\)になると予想した。
            このとき\(B\)さんは\(A\)さんの売っているオプションを購入すると
            お得である。
            実際に\(1\)年後に\(K(1) > 10 + c\)となれば、
            \(B\)さんは\(A\)さんから金\(1\)kgを\(10\)万円で買って、
            その金\(1\)kgを\(K(1)\)万円で売れば、
            差額\(K(1) - 10 > c\)万円分から
            オプションの購入価格\(c\)を差し引いた
            \(K(1) - 10 - c > 0\)万円が\(B\)さんの利益になる。

            \(A\)さんが\textbf{金を保有していない場合}も、
            \(B\)さんが権利行使したら、
            \(A\)さんは\textbf{金を売る義務}が生じるので、
            \(A\)さんは金\(1\)kgを\(K(1)\)万円で購入して
            \(10\)万円で\(B\)さんに売らなければならない。
            差額\(K(1)-10 > c\)万円から
            オプションの販売によって得た利益\(c\)万円
            を引いた分\(K(1)-10-c > 0\)万円は\(A\)さんの損失である。
            \item
            以上の議論を見れば分かる通り、
            \textbf{オプションを売る側の損失は
            (\(K(1)\)の値がおおきくなればなるほど)
            際限なく膨らんでいく}のに対して、
            \textbf{オプションを買う側の損失は高々オプションの購入価格程度}
            である。
            \item
            \textbf{どういう人がオプションを買うのか？}
            例えば上の例では\(B\)さんがオプションを買う側。
            \(B\)さんとしては、
            実際に金を用いてモノを製造する (業務を遂行する) 宝飾品製造会社
            などが考えられる。
            \(B\)さんとしては、どんなに金の価格が高騰しようとも、
            実物の金が用意できなければ業務を遂行できなくなるから、
            絶対に金を用意しなければならない。
            でも金の価格がものすごい高騰したら\(B\)さんは困るから、
            \textbf{金の値上がりに対するリスクを回避する}
            ために\(B\)さんはオプションを購入する。
            オプションを買えば、
            \(B\)さんの損失は高々オプションの購入額\(c\)万円で済む。
            このあたりはWikipediaの解説が上手。
            \item
            \textbf{どういう人がオプションを売るのか？}
            これは\textbf{金融機関の仕事}である
            (本書の前書き)。
            金融機関の役割は、
            「商品に関係する顧客の間のリスクを減らす仲介者」。
            上の場合では、金融機関\(A\)さんは、
            宝飾品製造会社\(B\)さんのリスクを減らしてあげるために、
            このオプションを開発して\(B\)さんに売る、
            という感じ。
            この点は本書の前書きがイントロとしていい感じなんじゃないかと思うけど、
            実際に金融機関の抱える「ヘッジの問題」というのが何なのかよくわからない。
          \end{itemize}
        \end{exam*}
      \end{framed}
      \item
      \textbf{ポートフォリオ} = 今考えているすべての資産 (お金)。
      これを株に投資したりマネー・マーケット・アカウントに投資したりして運営する。
      \item
      \textbf{マネー・マーケット・アカウント}：
      たぶん「すごい理想的な振る舞いをする投資先」みたいな感じ？
      株とかはめっちゃ変動するけど、こっちはあまり変わらないとか？
      国債みたいなやつらしい。
      無リスク資産。リスクのない資産。
      \item
      \textbf{リスク・プレミアム}：
      リスクのある資産の期待収益率から
      リスクのない資産の収益率を差し引いたもの。
      \item
      \textbf{ボラティリティ}：
      価格変動。変動。
      \item
      \textbf{ヘッジ}：
      \textbf{リスクヘッジ}ともいう。
      リスクに対して対応できるように体勢を整えること。
    \end{itemize}
    なんかいろいろ調べてまとめてみたけど、
    5章以降でいろんな例に触れるうちにわかってくるようになるかもしれない？
    ヨーロピアン・コール・オプションのこともなんとなくわかってきた。
    問題文を写すのが面倒臭くなったから書かなくなった。
    4章の練習問題を終わらせた。
    \item
    2020.5.18 (月)：
    5章の演習を\autoref{prob: 5.13}まで解いた。
    \autoref{prob: 5.11}で\(\Delta\)のことを
    「ポートフォリオ過程」とか言い出して、
    結局ポートフォリオってなんやねんって思った。
    \(X\)も\(\Delta\)もポートフォリオなんかいって。
    まあなんか\(\Delta\)の方は株に関するポートフォリオって感じで
    そんなに深い意味はないんだろうけども。
    昨日ちゃんとオプション取引のことを調べておいてよかった。
    5章の演習を1問だけ残して寝るのもちょっとアレだけど、
    まあ仕方ないから明日の朝にでもやろう。
    明日はセミナーだからあまりできないかもしれない。
    \item
    2020.5.19 (火)：
    もう少し数学じゃなく金融のことを勉強すべき。
    以下ノート：
    \begin{itemize}
      \item
      \textbf{フォワード契約} (先物取引と同じ？)：
      定められた決済時\(T\)において
      定められた価格 (\textbf{受け渡し価格}) \(K\)において
      特定の資産を定められた単位で購入する契約。
      \textbf{買いポジション}は決済時に資産を受け取る側。
      \textbf{売りポジション}は契約時に契約金を受け取って決済時に資産を渡す側。
      たとえば株価\(S(t)\)の株を資産とするとき、
      決済時\(T\)に価格\(K\)でフォワード契約を売る人は、
      決済時に単位あたり\(S(T)-K\)の利益が生じる (負の場合、損失)。

      決済時\(T\)に生じる損得\(S(T)-K\)に対するヘッジ・ポートフォリオとして、
      \(X(T)=S(T)-K\)となるような過程\(X\)を考えると、
      リスク中立測度のもとでは
      割引価値\(DX\)と割引株価\(DS\)はともに
      マルチンゲールであるから、
      \begin{align*}
        D(t)X(t) &= \tilde{\E}[D(T)(S(T)-K) \mid \mcF(t)] \\
        &= \tilde{\E}[D(T)S(T)\mid\mcF(t)]
        - K\tilde{\E}[D(T)\mid\mcF(t)] \\
        &= D(t)S(t) - K\tilde{\E}[D(T)\mid\mcF(t)]
      \end{align*}
      となる。
      従って
      \(X(t) = S(t) - \frac{K}{D(t)}\tilde{\E}[D(T)\mid\mcF(t)]\)
      となる。
      これは「時刻\(T\)において単位あたり価格\(K\)で株を売る」
      というフォワード契約を交わす際の契約金となる
      (フォワード契約の無裁定価格)。
      (時刻\(t\)での)
      \textbf{\(T\)-フォワード価格}とは、
      時刻\(t\)でのフォワード契約の無裁定価格が\(0\)となるような
      受け渡し価格\(K\)のこと。
    \end{itemize}
    \item
    2020.5.20 (水)：
    昨日はなかなか捗らない日だったから諦めて1問しか解かなかった。
    5章がちょうど終わったことになってキリはいいけど。
    ツナ缶でペペロンチーノを作って
    ハーゲンダッツを7個食べて
    xxxHolic読みながら朝まで白ビールを飲んだ。
    たまにはこういう日があってもいいんじゃないかな。
    ていうかxxxHolic、精神の深いところに侵入してくるような漫画だった。
    良いものが良いということをちゃんとわかる人でありたいと思った。
    そのためには落ち着きが大切なんだろう。

    起きたのが14:00だし、生活が崩れたけど、
    明日から直そう。
    今日は6章をやろう。というか予定を立てよう。
    今までペースが早すぎた気がする。
    だいたい1日1章くらい？いや、焦りすぎ。
    何をそんなに焦ることがある。まだあと2年も学生やるのに。
    5月が終わるまであと10日あるから、
    残り6章分を2日1章くらいでやればいいでしょう。
    1日5問程度かな。これでも早いと思うけど。
    \item
    2020.5.21 (木)：なんかあまりやる気が起こらずやらなかった。
    \item
    2020.5.22 (金)：
    なんか前から思ってたけど
    \begin{center}
      「その確率微分方程式はどこから来たんや」
    \end{center}
    問題がある。
    たとえばCIR過程？CIRの金利モデルとかいうやつ。金利が
    \[
    dR = (a-bR)dt + \sigma \sqrt{R}dW
    \]
    に従うって、いやこれ、この方程式、どこから来てんって。
    って感じ。これを調べてると
    \href{http://mathfin.web.fc2.com/deriv2/imi_deriv224.html}{良い記事}
    がヒットしたからメモしておく。
    まず\textbf{オルシュタイン-ウーレンベック確率微分方程式}というのがある：
    \[
    dX = -\frac{b}{2}Xdt + \frac{1}{2}\sigma dW.
    \]
    これには\textbf{離散版}があって、
    離散版は\textbf{AR(1)過程}と呼ばれる。
    \textbf{ARモデル}とは、時点\(t\)での出力が
    それ以前の出力に依存する確率過程のこと。
    確率変数の族 (確率過程)
    \(X_n\)が\textbf{AR(\(p\))過程}であるとは、
    ある定数\(c, \varphi_1,\cdots ,\varphi_p\)があって、
    各\(t\)に対して
    \[
    X_t = c + \ep_t + \sum_{i=1}^p \varphi_iX_{t-i}
    \]
    となることを言う。
    ここで\(\ep_t\)という確率過程は\textbf{ホワイトノイズ}と呼ばれるもので、
    定義は、以下を満たすということ：
    \begin{itemize}
      \item  平均\(0\)：\(\E[\ep_t] = 0\),
      \item  分散一定：\(\Var(\ep_t) = \sigma^2 < \infty\),
      \item  無相関：\(\Cov(\ep_t,\ep_{t-k}) = 0 \ , \ (k\neq 0)\).
    \end{itemize}
    ホワイトノイズの項はなんかランダムな感じを表現している。
    AR(1)過程の定義の式を整理すると、
    \[
    X_t-X_{t-1} = c + \ep_t + (\varphi_1 - 1)X_{t-1}
    = (c+(\varphi_1-1)X_{t-1})(t-(t-1)) + \ep_t
    \]
    となる。
    ここで\(X_t-X_{t-1}\)を\(dX\)で、
    \(t-(t-1)\)を\(dt\)で置き換え、
    ホワイトノイズの項を\(\sigma dW\)で置き換え
    (ブラウン運動の単位時間あたりの差分の分散は\(1\))、
    係数を適当に変更すると、
    \[
    dX = (a+bX)dt + \sigma dW
    \]
    を得る。
    こうやって得られるものがオルシュタイン-ウーレンベックの方程式である。
    つまり、オルシュタイン-ウーレンベックの方程式というのは、
    \textbf{連続自己回帰的な}確率変数ということである。
    この方程式をもう少し眺める。
    \(\sigma dW\)の項は大局的に見れば平均\(0\)の動きをするから
    とりあえず\(X\)の動きに「ランダムさ」を与えるための項と読む。
    \((a+bX)dt\)の項は、\(a,b\)を別の係数で置き換えることで
    \(a(b-X)dt\)と整理できる。
    \(a > 0\)とする。
    このとき、\(X\)の動きは、
    「\(b\)に回帰していくような動き方」をする。
    つまり、\(X(t)>b\)であれば、\(a(b-X(t))<0\)だから
    時刻\(t\)で\(X\)は\(b\)の方向に向かって動き、
    逆に\(X(t)<b\)であれば、\(a(b-X(t))>0\)だから
    同じく時刻\(t\)で\(X\)は\(b\)の方向に向かって動く。
    このように、確率過程\(X\)の値は\(b\)の方向を向くように動いていく。
    これは\textbf{平均回帰性}と呼ばれるもので、
    オルシュタイン-ウーレンベック過程は別名
    \textbf{平均回帰過程}とも呼ばれる。

    \(\circledast\)
    次に\textbf{バシチェックモデル}について
    (例題4.4.10)。
    これは上に書いたことをそのまま金利過程として採用したものである。
    つまり金利は平均値である\(b\)に向かって
    (\(a\)の「力」で) 戻ってくるように動く。
    金利には平均回帰性が確認されているらしく、
    これは現実のモデルと合う。
    一方、バシチェックモデルの問題点は、金利が負の値も取り得ることで、
    \textbf{CIRモデル}はその難点を解消した。

    \(\circledast\)
    \textbf{CIRモデル} (例題4.4.11)とは、
    金利\(R(t)\)のモデルで、
    次の方程式に従うもの：
    \[
    dR = (a-bR)dt + \sigma \sqrt{R}dW.
    \]
    これも平均である\(a/b\)に向かって\(b\)の力で戻ってくるように動く。
    ただし\(dW\)の項に\(\sqrt{R}\)がかかっているので、
    \(R(t)\)の値が小さくなればなるほど、ボラティリティが小さくなり、
    この結果\(R(t)\)が負の値をとることが阻止されることになる。
    なぜ\(\sqrt{R}\)をかけたのかについては、
    \href{http://mathfin.web.fc2.com/deriv2/imi_deriv224.html}{ここ}
    の解説が良い感じだった。
    簡単に言うと、平均回帰的に振る舞う確率変数\(Y\)について
    \(Y\)の満たすオルシュタイン-ウーレンベックの方程式の係数を適当に置いてから、
    \(R=Y^2\) (これは負にならない) の満たす方程式を書き下したら、
    なんとなく\(dW\)の係数に\(\sqrt{R}\)がかかりそうだなって感じ。

    \(\circledast\)
    \textbf{ハル-ホワイト・モデル}というのもあるけど、
    もうこの辺はよくわかんないし曖昧って
    \href{https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%AB%E3%83%BB%E3%83%9B%E3%83%AF%E3%82%A4%E3%83%88%E3%83%BB%E3%83%A2%E3%83%87%E3%83%AB}{Wikipedia}
    に書いてあった。
    とりあえず今までのモデルと同じで
    \[
    dR = (\Theta - \beta R)dt + \sigma dW
    \]
    みたいな方程式に従うやつ、
    ただし\(\Theta,\beta,\sigma\)も\(t\)に依存して動くかも。
    って感じ。
    どのみち (今までの議論と同じように) \(R\)は平均回帰的に動く。
    この場合は平均が\(\Theta/\beta\)だから平均も動くんだけど。
    平均に向かっていく力は\(\beta\)だからそれも動く。まあ全部動く。

    \(\circledast\)
    あと、なんか\textbf{確率ボラティリティモデル}というやつは
    \href{https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E3%83%9C%E3%83%A9%E3%83%86%E3%82%A3%E3%83%AA%E3%83%86%E3%82%A3%E3%83%A2%E3%83%87%E3%83%AB}{Wikipedia}を参考にするといい。

    6章の演習を終わらせた。
    ずいぶんやる気が出なかったなあ。
    明日は実家に帰るのであまりできないと思う。
    \item
    2020.5.23 (土)：
    死ぬほどお菓子を食べてしまった。
    電車の中でいろいろ演習見てたけど、
    「計算によってhogeがhogeの微分方程式を満たすことを確認したい」
    みたいな演習をやる意味が感じられないから
    これからはそういうのは飛ばしていいんじゃないか
    と思った。
    だってこれ微分と極限の計算と四則演算ができれば解けるやん、
    やる意味なくないか？
    \item
    2020.5.24 (日)：
    あまりにも計算がめんどくさいから7章の問題はいろいろとばした。
    具体的には、
    \autoref{prob: 7.1}の最後の方と、
    \autoref{prob: 7.2}、\autoref{prob: 7.5}、
    \autoref{prob: 7.6}は単純で苦痛な計算だからやらないということにした。
    今日は \autoref{prob: 7.9} \ref{enumi: 7.9-1} までやった。
    計算がつらい。
    \item
    2020.5.25 (月)：
    スタバでやったら気分が良くなった。
    \autoref{prob: 7.9} \ref{enumi: 7.9-3}が解けなくてあまりできなかったけど。
    そこを飛ばして\autoref{prob: 8.3}までやった。
    \item
    2020.5.26 (火)：
    シャワーを浴びていたら
    昨日わからなかった\autoref{prob: 7.9} \ref{enumi: 7.9-3}
    とか関連する本文の\(\gamma\)という関数
    (式(7.5.22)) の求め方とかがわかった。
    デルタ・ヘッジ法をするだけだった。
    8章の演習を終わらせた。
    \item
    2020.5.27 (水)：
    八坂神社前のスタバでアールグレイを飲みながら演習を解いた。
    9章が終わった。やっぱり計算がつらい。
    この本が終わったら次は何をやろうか...
    というので頭がいっぱいだけど、
    普通に今までに出てきたいろいろなモデルの整理や復習を一回やりたい。
    そのためのpdfでも作ろうかな。
    \item
    2020.5.28 (木)：10章わりとながい。
    なんか\autoref{prob: 10.3} \ref{enumi: 10.3-4}で
    \href{https://www.quantsummaries.com/shreve_stochcal4fin_2.pdf}
    {ネットに落ちてる答え}
    と自分の計算結果が合わなくて時間を取られ、
    結局\autoref{prob: 10.3} \ref{enumi: 10.3-3}までやった。
    \item
    2020.5.29 (金)：
    昨日のやつは結局\href{https://www.quantsummaries.com/shreve_stochcal4fin_2.pdf}
    {ネットに落ちてる答え}が違うんじゃねっておもって
    自分の答えをそのまま書いといた。
    計算はだるいから途中まで。
    解いたのは\autoref{prob: 10.8}まで。
    結局5月中に終わるか終わらないかって感じだなあ。
    すぐだったなあ。これ終わったら何しようかなあ...
    \item
    2020.5.30 (土)：
    実家で猫と戯れた。
    \autoref{prob: 10.9}と\autoref{prob: 10.10}だけといた。
    実家に持って帰ったスパティフィラムの花が猫に食べられてしまって悲しかった。
    復活してくれるかなあ。大丈夫かなあ。
    猫の方も花の方も心配。
    \item
    2020.5.31 (日)：
    今日は休憩。一問も解かなかった。
    次はC++でファイナンス系の何らかをプログラムしてみようみたいなやつでもやろうかな。
    あと黒執事を25巻まで読んだ。
    セバスチャンかっこいい。みんな強い。黒執事おもしろい。
    \item
    2020.6.1 (月)：
    6月になってしまった。
    タリーズでただのトーストにシュガーとシロップを入れるのが天才すぎておいしかった。
    いちごと蜂蜜となんかいい感じのレモン系の3種類のフレーバーティーを買ったけど、
    いちごが天才だった。毎朝飲もう。
    あと、11章の演習が最後まで終わった。
    つまり一応全部おわった。お疲れ私。
  \end{itemize}
\end{nikki*}





\newpage

\section{一般的な確率論}\label{section: 1}


\begin{rrem*}
  確率変数\(X\)が密度関数\(f(x)\)を持つとする。
  ボレル可測関数\(p:\R\to \R\)と実数\(a\)に対して
  \[
  \int_{-\infty}^a p(x)f(x)dx = \int_{X\leq a}p(X)d\P
  \]
  である。
  この式は\(X:\Omega \to \R\)によって"変数変換"をしている、と読むことができる。
  積分する領域は\((-\infty ,a]\)から
  \(X^{-1}((-\infty ,a]) = (X\leq a)\)
  に変換される。
  \(F(t)\)を\(X\)の累積分布関数とすれば、
  \(f(x)dx = dF(x)\)である。
  \(F(x) = \P(X\leq x)\)と読めば
  \(dF(x) = d\P\)っぽく見える。
\end{rrem*}



\begin{prob}\label{prob: 1.1}
  次を示せ：
  \begin{enumerate}
    \item \label{enumi: 1.1-1}
    \(A,B \in \mcF, A\subset B\)ならば\(\P(A)\leq \P(B)\)である。
    \item \label{enumi: 1.1-2}
    \(A\in \mcF, A_n\in \mcF , (n=1,2,\cdots)\)であり、
    \(A\subset A_n , (\forall n)\)かつ\(\lim_{n\to\infty}\P(A_n)=0\)ならば
    \(\P(A)=0\)である。
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 1.1-1}。
  \(B\setminus A\in \mcF\)であることと
  \(\P\)が非負の値しかとらないことと
  \(A\)と\(B\setminus A\)が交わらないことから
  \[
  \P(B) = \P(B\setminus A) + \P(A)
  \geq \P(A)
  \]
  である。

  \ref{enumi: 1.1-2}。
  (i)より\(\P(A)\leq \P(A_n)\)が任意の\(n\)で成り立つので、
  \[
  \P(A) \leq \lim \P(A_n) = 0
  \]
  となり、\(\P\)が非負の値しかとらないことから\(\P(A)=0\)となる。
\end{proof}




\begin{prob}\label{prob: 1.2}
  無限回コイン投げの空間\(\Omega_{\infty}\)の部分集合
  \[
  A \dfn \left\{ \omega = \omega_1\omega_2\cdots \in \omega_{\infty} \middle|
  \omega_{2i}=\omega_{2i-1} , \forall i \right\}
  \]
  を考える。
  以下を示せ：
  \begin{enumerate}
    \item \label{enumi: 1.2-1}
    \(A\)は非可算無限集合である。
    \item \label{enumi: 1.2-2}
    \(0<p<1\)ならば\(\P(A)=0\)である。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.2-1}。
  次のような写像を考える：
  \begin{align*}
    f:\Omega_\infty &\to \Omega_{\infty} \\
    \omega_1\omega_2\cdots &\mapsto \omega_1\omega_1\omega_2\omega_2\cdots
  \end{align*}
  写像\(f\)は\(\omega_1\omega_2\cdots\)という元を、
  各\(\omega_i\)を\(2\)つずつ並べた元へ写す写像である。
  明らかに写像\(f\)は単射であり、さらに\(A\)は写像\(f\)の像である。
  従って\(A\)は非可算無限集合である。

  \ref{enumi: 1.2-2}。
  \begin{align*}
    A_n &\dfn
    \left\{ \omega \in \Omega_\infty \middle| \omega_{2n-1}=\omega_{2n}\right\}, \\
    B_n &\dfn \bigcap_{i\leq n}A_i
  \end{align*}
  と置くと\(A=\bigcap_n B_n\subset \cdots \subset B_n \subset B_{n-1}\subset \cdots \)
  である。
  また、各\(n\)に対して
  \[\P(A_n) = (p^2+(1-p)^2) = 1-2p+2p^2 = 1+2p(p-1)\]
  となり、\(\P(B_n) = \prod _{i=1}^n \P(A_i) = (1+2p(1-p))^n\)である。
  ここで\(0<p<1\)であることから、\(2p(p-1)<0\)であるため、
  \((1+2p(p-1))^n \to 0 , (n\to \infty)\)となって
  \autoref{prob: 1.1} \ref{enumi: 1.1-2}
  より\(\P(A)=0\)である。
\end{proof}






\begin{prob}\label{prob: 1.3}
  \([0,1]\)のすべての部分集合\(A\)に対して、
  \(A\)が有限集合であれば\(\P(A)=0\)、
  \(A\)が無限集合であれば\(\P(A)=\infty\)、
  と定義された集合関数\(\P\)を考える。
  \(\P\)は(1.1.3)-(1.1.5)式を満たすが、
  (1.1.2)式を満たさないことを示せ。
\end{prob}

\begin{proof}
  空集合は有限集合であるから\(\P(\emptyset) = 0\)であり
  \(\P\)は式(1.1.3)を満たす。
  また、\(A\cup B\)が無限集合であれば\(A\)または\(B\)のいずれかが無限集合であることから、
  \(\P\)は式(1.1.4)を満すこともわかる。
  式(1.1.4)を満たす\(\P\)は式(1.1.5)も満たす。

  \(A_n = \left\{ 1/n\right\}\)という一元集合を考えれば、
  \[
  \sum _n \P(A_n) = \sum _n 0 = 0 \neq \infty = \P\left(\bigcup_n A_n\right)
  \]
  となるので\(\P\)は(1.1.2)を満たさない。
\end{proof}



\begin{prob}\label{prob: 1.4}
  \
  \begin{enumerate}
    \item \label{enumi: 1.4-1}
    例題1.1.4の確率空間\((\Omega_{\infty},\mcF_{\infty},\P)\)上で、
    表の出る確率が\(p=1/2\)であることを仮定して、
    標準正規確率変数\(Z\)を1つ構築せよ。
    \item \label{enumi: 1.4-2}
    \(\Omega_{\infty}\)上の確率変数の列\(\left\{Z_n\right\}_{n=1}^\infty\)
    で、次を満たすものを定義せよ：
    \begin{center}
      \(\forall \omega\in\Omega_{\infty}\)に対し
      \(\lim_{n\to \infty}Z_n(\omega)=Z(\omega)\)
    \end{center}
    であり、さらに各\(Z_n\)は最初の\(n\)回のコイン投げの結果にのみ依存する。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.4-1}。
  例題1.2.5の確率変数\(X\)と
  例題1.2.6の関数\(N(x)\)を用いて
  \(Z(\omega)\dfn N^{-1}(X(\omega))\)とすれば良い。

  \ref{enumi: 1.4-2}。
  例題1.2.5の確率変数\(Y_n\)を用いて
  \(X_n(\omega) \dfn \sum _{i=1}^n Y_i(\omega)/2^i\)とおき、
  \(Z_n(\omega) \dfn N^{-1}(X_n(\omega))\)とおくと、
  \(N^{-1}\)の連続性と
  \(X_n(\omega) \to X(\omega) , n\to \infty\)
  であることから\(Z_n(\omega) \to Z(\omega) , n\to \infty\)
  となる。
  また\(Y_n\)が\(n\)回目のコイン投げの結果にのみ依存することから、
  \(Z_n\)は最初の\(n\)回のコイン投げの結果にのみ依存する。
\end{proof}


\begin{prob}\label{prob: 1.5}
  \[
  \int_{\Omega}\int_0^\infty \I_{[0,X(\omega))}(x)dxd\P(\omega)
  \]
  が\(\E X\)にも\(\int_0^\infty(1-F(x))dx\)にも等しいことを示すことで
  \[
  \E X = \int_0^\infty(1-F(x))dx
  \]
  を示せ。
\end{prob}

\begin{proof}
  まず\(X\)が非負であることから
  \[
  \int_0^{\infty}\I_{[0,X(\omega))}(x)dx = X(\omega)
  \]
  となる。
  よって
  \[
  \int_{\Omega}\int_0^{\infty}\I_{[0,X(\omega))}(x)dxd\P(\omega) = \E X
  \]
  となる。

  次に、固定した\(0\leq x < \infty \)に対して
  \(\I_{[0,X(\omega))}(x)\)は\(X(\omega) < x\)のとき\(0\)、
  \(X(\omega) \geq x\)のとき\(1\)となることから
  \[
  \int_{\Omega}\I_{[0,X(\omega))}(x)d\P(\omega) = \P(X \geq x) = 1 - \P(X < x)
  \]
  となる。
  \(F(x)\)は広義単調増加であり、
  従って\(\P(X=x) \neq 0\)となる点\(x\geq 0\)は高々可算個である。
  よって
  \[
  \int_0^{\infty}\int_{\Omega}\I_{[0,X(\omega))}(x)d\P(\omega)dx
  = \int_0^{\infty}(1 - \P(X < x)) dx
  = \int_0^{\infty}(1 - F(x)) dx
  \]
  であり、以上を比較することで
  \[
  \E X = \int_0^{\infty}(1 - F(x)) dx
  \]
  を得る。
\end{proof}


\begin{prob}\label{prob: 1.6}
  \(u\in \R\)を一つ固定し、\(\varphi(x) = e^{ux}\)と置く。
  \(X\)は、平均が\(\mu \dfn \E X\)で
  標準偏差が\(\sigma \dfn [\E(X-\mu)^2]^{1/2}\)の
  正規確率変数とする。
  すなわち、\(X\)は次の密度関数を持つ：
  \[
  f(x) = \frac{1}{\sigma\sqrt{2\pi}}\exp(-(x-\mu)^2/2\sigma^2)
  \]
  \begin{enumerate}
    \item \label{enumi: 1.6-1}
    次を確かめよ：
    \[
    \E e^{uX} = \exp(u\mu + \frac{1}{2}u^2\sigma^2)
    \]
    \item \label{enumi: 1.6-2}
    Jensenの不等式
    \[
    \E \varphi(X) \geq \varphi(\E X)
    \]
    を確かめよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.6-1}。
  本文中の定理1.5.2を用いて計算する。
  以下の計算において\(\exp(x)=e^x\)である。
  \begin{align*}
    \E e^{uX} &= \E \varphi(X) = \int_{-\infty}^{\infty}\varphi(x)f(x)dx
     \ \ \ \ \ \ \ \ \ \text{(ここの二つめの等式が定理1.5.2である)} \\
    &= \int_{-\infty}^{\infty}e^{ux}\cdot
    \frac{1}{\sigma\sqrt{2\pi}}e^{-(x-\mu)^2/2\sigma^2}dx \\
    &= \frac{1}{\sigma\sqrt{2\pi}}\cdot
    \int_{-\infty}^{\infty}\exp(ux-(x-\mu)^2/2\sigma^2)dx \\
    &= \frac{1}{\sigma\sqrt{2\pi}}\cdot
    \int_{-\infty}^{\infty}\exp((2\sigma^2u+2\mu)x-x^2-\mu^2)/2\sigma^2)dx  \\
    &= \frac{1}{\sigma\sqrt{2\pi}}\cdot
    \int_{-\infty}^{\infty}\exp(-(x-(\sigma^2u+\mu))^2/2\sigma^2+\mu u+\sigma^2u^2/2)dx  \\
    &= \frac{\exp(\mu u+\sigma^2u^2/2)}{\sigma\sqrt{2\pi}}\cdot
    \int_{-\infty}^{\infty}\exp(-(x-(\sigma^2u+\mu))^2/2\sigma^2)dx  \\
    &= e^{\mu u+\sigma^2u^2/2} \\
  \end{align*}

  \ref{enumi: 1.6-2}。
  \(\sigma^2u^2 \geq 0\)なので\(e^{\sigma^2u^2/2} \geq 1\)であり、
  また\(e^{\mu u} > 0\)であるから
  \[
  \E \varphi(X) = e^{\mu u+\sigma^2u^2/2} = e^{\mu u}\cdot e^{\sigma^2u^2/2}
  \geq e^{\mu u} = \varphi(\mu) = \varphi(\E X)
  \]
  となる。
\end{proof}





\begin{prob}\label{prob: 1.7}
  各正の整数\(n\)に対し、
  \(f_n\)を平均\(0\)、分散\(n\)の正規密度関数とする。
  すなわち
  \[
  f_n(x) \dfn \frac{1}{\sqrt{2n\pi}}\exp(-x^2/2n)
  \]
  とする。
  \begin{enumerate}
    \item \label{enumi: 1.7-1}
    \(f(x)=\lim_{n\to \infty}f_n(x)\)はどんな関数か？
    \item \label{enumi: 1.7-2}
    \(\lim_{n\to \infty}\int_{-\infty}^\infty f_n(x)dx\)の値は？
    \item \label{enumi: 1.7-3}
    以上の問題より
    \[
    \lim_{n\to \infty}\int_{-\infty}^\infty f_n(x)dx
    \neq \int_{-\infty}^\infty f(x)dx
    \]
    である。
    これが単調収束定理や優収束定理に反しないことを説明せよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.7-1}。
  \(e^{-x^2/2n} \to 1 , n\to \infty\)であるから
  \(f_n(x) \to 0 , x\to \infty\)である。
  よって\(f(x)=0\)である。

  \ref{enumi: 1.7-2}。
  \(f_n(x)\)は (ある確率変数の) 密度関数であるから
  \(\int_{-\infty}^{\infty}f_n(x)dx = 1\)であり、
  従って求める値は\(1\)である。

  \ref{enumi: 1.7-3}。
  単調収束定理(1.4.5)に反しないことを見るには、
  単調収束定理の仮定を満たさないことを確かめれば良い。
  つまり
  \[
  f_1 \geq f_2 \geq \cdots \geq f_n \geq \cdots \ \ \ \ \ae
  \]
  でないことを確かめれば良い。
  \(x = \sqrt{n}\)とすれば任意の\(m\neq n\)に対して
  \(f_n(x) > f_m(x)\)となることがわかる：
  なぜならば
  \begin{itemize}
    \item[ \ ] \(f_n(x) > f_m(x)\)
    \item[\(\iff\)] \(e^{-1/2}/\sqrt{n} > e^{-n/2m}/\sqrt{m}\)
    \item[\(\iff\)] \(e^{-1+n/m} > n/m\)
  \end{itemize}
  となり、最後の式が\(m\neq n\)に対して成立することはよく知られている。
  従って関数列\(f_n\)は単調収束定理の仮定を満たさない。

  優収束定理の仮定を満たさないことを示す。
  \(g:\R\to \R\)を可測関数で
  任意の\(n\)に対して\(f_n(x) \leq g(x) , \ae\)
  とする。
  \(f_n(x) \leq g(x) , \ae\)であることと、
  各\(f_n\)は\(x>0\)で単調減少であることから、
  \(|x| < \sqrt{n}\)に対して
  \(1/\sqrt{2ne\pi} = f_n(\sqrt{n}) < g(x)\)
  となる。
  \(\sqrt{n}-\sqrt{n-1} > 1/2\sqrt{n}\)であることに注意すれば、
  \begin{align*}
    \int_{-\infty}^{\infty}g(x)dx
    &> \sum_{n=1}^{\infty}\frac{\sqrt{n}-\sqrt{n-1}}{\sqrt{2ne\pi}} \\
    &> \frac{1}{\sqrt{2e\pi}}\sum_{n=1}^{\infty}\frac{1}{2n} \\
    &= \infty
  \end{align*}
  となる。
  これは優収束定理の仮定を満たす関数\(g\)が存在しないことを示している。
\end{proof}




\begin{prob}\label{prob: 1.8}
  \(X\)を非負の確率変数とし、
  \[
  \varphi(t) \dfn \E e^{tX}
  \]
  はすべての\(t\in \R\)に対して有限であると仮定する。
  さらにすべての\(t\in \R\)に対し
  \(\E[Xe^{eX}] < \infty\)と仮定する。
  \(s_n\)を\(t\)に収束する実数の列とし、
  \[
  Y_n \dfn \frac{e^{tX}-e^{s_nX}}{t-s_n}
  \]
  を確率変数の列とする。
  \begin{enumerate}
    \item \label{enumi: 1.8-1}
    次を示せ：
    \[
    \lim_{n\to \infty}\E Y_n = \E[\lim_{n\to \infty}Y_n] = \E[Xe^{tX}]
    \]
    これより\(\varphi'(t) = \E[Xe^{tX}]\)となる。
    \item \label{enumi: 1.8-2}
    \(X\)が正の値も負の値もとりうるとし、
    任意の\(t\in \R\)に対して
    \(\E e^{tX} < \infty\)かつ
    \(\E [|X|e^{tX}] < \infty\)であると仮定する。
    このとき\(\varphi'(t) = \E[Xe^{tX}]\)を示せ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.8-1}。
  \(t\)より大きい実数\(s\)を一つとる。
  \(s_n\to t , n\to \infty\)であるから、
  十分大きな\(n\)に対して\(s_n < s\)である。
  また本文中の式(1.9.1)より、
  各\(n\)に対して\(t\)と\(s_n\)の間の値をとるある確率変数\(\theta_n\)があって
  \[
  Y_n(\omega) = \frac{e^{tX(\omega)}-e^{s_nX(\omega)}}{t-s_n}
  = X(\omega)e^{\theta_n(\omega)X(\omega)}
  \]
  となる。
  ここで十分大きな\(n\)に対して\(s_n < s\)であることから、
  十分大きな\(n\)に対して\(\theta_n < s\)であり、
  また\(X\)が非負であることから、
  従って十分大きな\(n\)に対して\(Y_n \leq Xe^{sX}\)となる。
  ここで「すべての実数\(t\)に対して\(\E [Xe^{tX}] < \infty\)である」
  という仮定から、確率変数の列\(Y_n\)は優収束定理の仮定を満たす。
  従って
  \[
  \lim \E Y_n = \E \left[ \lim Y_n\right]
  \]
  となる。
  また、各\(\omega\)に対して\(Y_n(\omega) \to X(\omega)e^{tX(\omega)} , n\to \infty\)
  であるから、
  \[
  \E \left[ \lim Y_n\right] = \E[Xe^{tX}]
  \]
  となる。

  \ref{enumi: 1.8-2}。
  \(X = X^+-X^-\)と分ける。
  \(Y^+ \dfn e^{tX^+}, Y^- \dfn e^{-tX^-}\)
  とおけば、各\(\omega\in \Omega\)に対して
  \(Y^+(\omega)\)または\(Y^-(\omega)\)のどちらか一方は必ず\(1\)であるから、
  \[e^{tX(\omega)} = Y^+(\omega) + Y^-(\omega) - 1\]
  となる。
  従って\(\varphi^+(t) \dfn \E[e^{tX^+}] , \varphi^-(t) \dfn \E[e^{tX^-}]\)
  とおけば、
  \begin{align*}
    \varphi(t) &= \int_{\Omega}e^{tX(\omega)} d\P(\omega) \\
    &= \int_{\Omega}(Y^+(\omega) + Y^-(\omega) - 1) d\P(\omega) \\
    &= \int_{\Omega}e^{tX^+(\omega)}d\P(\omega)
    + \int_{\Omega}e^{-tX^-(\omega)}d\P(\omega) - 1 \\
    &= \varphi^+(t) + \varphi^-(-t) - 1
  \end{align*}
  となる。
  \(X^+,X^-\)はそれぞれ非負の確率変数であるから、(i)より
  \[
  \varphi'(t) = (\varphi^+)'(t) - (\varphi^-)'(-t)
  = \E[X^+e^{tX^+}] - \E[X^-e^{-tX^-}]
  \]
  である。
  ここで各\(\omega\)に対して\(X^+e^{tX^+},X^-e^{-tX^-}\)のうち一方は\(0\)であるから、
  \begin{align*}
    \E[X^+e^{tX^+}] - \E[X^-e^{-tX^-}]
    &= \int_{\Omega}X^+(\omega)e^{tX^+(\omega)}d\P(\omega)
    - \int_{\Omega}X^-(\omega)e^{-tX^-(\omega)}d\P(\omega)  \\
    &= \int_{\P(X\geq 0)}X(\omega)e^{tX(\omega)}d\P(\omega)
    + \int_{\P(X\leq 0)}X(\omega)e^{tX(\omega)}d\P(\omega)  \\
    &= \int_{\Omega}X(\omega)e^{tX(\omega)}d\P(\omega) = \E[Xe^{tX}]
  \end{align*}
  となり所望の式を得る。
\end{proof}



\begin{prob}\label{prob: 1.9}
  \(X\)はある確率空間\((\Omega,\mcF,\P)\)上の確率変数であり、
  \(A\in \mcF\)とする。
  \(\R\)の任意のぼれる集合\(B\)に対して
  \[
  \int_A\I_B(X(\omega))d\P(\omega) = \P(A)\P(X\in B)
  \]
  と仮定する (\(X\)は事象\(A\)と独立)。
  このとき任意の非負値ボレル可測関数\(g\)に対して
  \[
  \int_Ag(X(\omega))d\P(\omega) = \P(A)\E g(X)
  \]
  を示せ。
\end{prob}

\begin{proof}
  定義より
  \begin{align*}
    \E [\I_B(X)] = \int_{\Omega}\I_B(X(\omega))d\P(\omega) = \P(X\in B)
  \end{align*}
  であるから、\(X\)が\(A\)と独立であることより
  \begin{align*}
    \int_A\I_B(X(\omega))d\P(\omega) = \P(A)\P(X\in B) = \P(A)\E[\I_B(X)]
  \end{align*}
  となって、\(g\)が定義関数である場合は所望の等式が確認できた。

  \(g\)が非負の単関数である場合。
  \(g = \sum _i a_i\I_{B_i}\)とし、各\(B_i\)は交わらないとする。
  このとき
  \begin{align*}
    \int_Ag(X(\omega))d\P(\omega)
    &= \int_A\sum _i a_i\I_{B_i}(X(\omega))d\P(\omega) \\
    &= \sum_i a_i \int_A \I_{B_i}(X(\omega))d\P(\omega) \\
    &= \sum_i a_i \P(A)\P(X\in B_i)  \\
    &= \P(A)\cdot \left( \sum_i a_i \P(X\in B_i)\right)
  \end{align*}
  となる。
  ここで\(\sum_i a_i \P(X\in B_i) = \E[g(X)]\)であることに注意すれば、
  \(g\)が非負の単関数である場合に所望の等式を得る。

  \(g\)が一般の非負値関数である場合。
  このとき、非負の単関数の列\(0\leq g_1\leq g_2\leq \cdots\)により
  \(g = \lim g_i\)と表すと、
  単調収束定理より
  \begin{align*}
    \int_Ag(X(\omega))d\P(\omega)
    &= \int_{\Omega}\I_A \cdot \lim _n g_n(X(\omega))d\P(\omega) \\
    &= \lim _n\int_{\Omega}\I_Ag_n(X(\omega))d\P(\omega)
  \end{align*}
  である。
  ここで\(g_n\)は非負の単関数であるから、すでに所望の等式は確認済みで、従って
  \begin{align*}
    \lim _n\int_{\Omega}\I_Ag_n(X(\omega))d\P(\omega)
    &= \lim_n \P(A)\E[g_n(X)]
  \end{align*}
  となる。
  また、非負値確率変数の単調増加な族\(g_n(X)\)に対して単調収束定理を用いれば
  \(\lim_n\E[g_n(X)] = \E[\lim_n g_n(X)] = \E[g(X)]\)
  となり、以上を組み合わせることで所望の等式を得る。
\end{proof}






\begin{prob}\label{prob: 1.10}
  \(\P\)を\(\Omega = [0,1]\)上の一様 (ルベーグ) 測度とする。
  \[
  Z(\omega) \dfn \left\{
  \begin{aligned}
    0  \ , \ (\text{\(0\leq \omega < 1/2\)のとき}), \\
    2  \ , \ (\text{\(1/2\leq \omega \leq 1\)のとき}),
  \end{aligned}
  \right.
  \]
  とし、
  \(A\in \mcB[0,1]\)に対し
  \[
  \tilde{\P}(A) \dfn \int_A Z(\omega) d\P(\omega)
  \]
  と定める。
  \begin{enumerate}
    \item \label{enumi: 1.10-1}
    \(\tilde{\P}\)が確率測度であることを示せ。
    \item \label{enumi: 1.10-2}
    \(\P(A)=0\)ならば\(\tilde{\P}(A)=0\)であることを示せ。
    \item \label{enumi: 1.10-3}
    \(\tilde{\P}(A)=0\)であるが\(\P(A)\neq 0\)となる\(A\)の存在を示せ。
    とくに\(\P\)と\(\tilde{\P}\)は同値でない。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.10-1}。
  \[
  \tilde{\P}(\Omega) = \int_{\Omega}Z(\omega)d\P(\omega)
  = 0\cdot (1/2-0) + 2\cdot (1-1/2) = 1
  \]
  であるから、あとは可算加法性を確認すれば良い。
  \(A_i\in \mcF\)を互いに交わらない集合の列、
  \(B_i \dfn \bigcup_{j\leq i}A_j\)とおき、
  \(B\dfn \bigcup_{i=1}^{\infty} A_i = \bigcup_{i=1}^{\infty} B_i\)
  と置く。
  \(B_1\subset B_2\subset \cdots \subset B\)であるから
  \(\I_{B_1}\leq \I_{B_2}\leq \cdots \leq \I_B\)であり、
  \(B=\bigcup_{i=1}^\infty B_i\)であるから
  \(\lim _i \I_{B_i} = \I_B\)である。
  従って
  \begin{align*}
    \tilde{\P}(B) &= \int_{B}Z(\omega)d\P(\omega)
    = \int_{\Omega}(\lim _i \I_{B_i})Z(\omega) d\P(\omega) \\
    &\overset{\bigstar}{=} \lim_i \int_{\Omega}\I_{B_i}Z(\omega) d\P(\omega)
    = \lim_i \sum _{j\leq i}\int_{A_j}Z(\omega)d\P(\omega)
    = \lim_i \sum _{j\leq i}\tilde{\P}(A_j)
    = \sum _{i=1}^\infty\tilde{\P}(A_j)
  \end{align*}
  である。
  ここで\(\bigstar\)の箇所に単調収束定理を用いた。

  \ref{enumi: 1.10-2}。
  \(\P(A)=0\)であるとする。
  \(A_1 \dfn A\cap [0,1/2) , A_2 \dfn A\cap [1/2,1]\)と置く。
  このとき明らかに\(A_1,A_2\in \mcF\)であり、\(\P(A_1)=\P(A_2)=0\)である。
  さらに各点\(\omega\in A_1\)に対して\(Z(\omega)=0\)であるから
  \[
  \tilde{\P}(A_1) = \int_{A_1}Z(\omega)d\P(\omega) = 0
  \]
  であり、
  各点\(\omega\in A_2\)に対して\(Z(\omega)=2\)であるから
  \[
  \tilde{\P}(A_2) = \int_{A_2}Z(\omega)d\P(\omega) = 2\P(A_2) = 0
  \]
  である。
  以上より\(\tilde{\P}(A) = \tilde{\P}(A_1) + \tilde{\P}(A_2) = 0\)
  となる。

  \ref{enumi: 1.10-3}。
  \(A\dfn [0,1/2)\)とすれば\(\P(A) = 1/2\)であるが
  \(\tilde{\P}(A)=0\)である。
\end{proof}



\begin{prob}\label{prob: 1.11}
  例題1.6.6の記号のもと
  \[
  \tilde{\E}e^{uY} = e^{u^2/2}
  \]
  を示せ。
  とくに\(Y\)は\(\tilde{\P}\)のもとでの標準正規確率変数となる。
\end{prob}

\begin{proof}
  計算すると、
  \begin{align*}
    \tilde{\E}[e^{uY}]
    &\overset{\bigstar}{=} \E[e^{uY}Z]
    \overset{\spadesuit}{=} \int_{\Omega}e^{uY(x)}Z(x)\varphi(x)dx \\
    &= \frac{1}{\sqrt{2\pi}}\int_{\Omega}\exp(u(x+\theta) - \theta x
    - \frac{1}{2}\theta^2 - \frac{1}{2}x^2)dx \\
    &= \frac{1}{\sqrt{2\pi}}\int_{\Omega}\exp(
    -\frac{1}{2}((x+\theta-u)^2 - u^2))dx \\
    &= \frac{e^{\frac{1}{2}u^2}}{\sqrt{2\pi}}
    \int_{\Omega}\exp(-\frac{1}{2}(x+\theta-u)^2)dx \\
    &= e^{\frac{1}{2}u^2} \\
  \end{align*}
  ここで\(\bigstar\)の箇所に定理1.6.1 式(1.6.4)を用い、
  \(\spadesuit\)の箇所に定理1.5.2を用いた。
  以上で所望の等式が確認できた。
\end{proof}

\begin{prob}\label{prob: 1.12}
  例題1.6.6の記号のもとで\(\hat{Z} \dfn e^{\theta Y-\theta^2/2}\)とし、
  さらに\(A\in \mcF\)に対して
  \[
  \hat{\P}(A) \dfn \int_A\hat{Z}(\omega)d\tilde{P}(\omega)
  \]
  と定める。
  このとき\(\hat{Z} = 1/Z\)と\(\hat{\P}=\P\)を示せ。
\end{prob}

\begin{proof}
  まず
  \[
  \hat{Z}(\omega) = \exp(\theta Y(\omega) - \frac{1}{2}\theta^2)
  = \exp(\theta(X+\theta) - \frac{1}{2}\theta^2)
  = \exp(\theta X + \frac{1}{2}\theta^2) = \frac{1}{Z(\omega)}
  \]
  であるから\(\hat{Z} = \frac{1}{Z}\)である。
  次に\(\hat{Z}Z=1\)を用いることで
  \[
  \hat{\P}(A) = \int_A\hat{Z}d\tilde{\P}(\omega)
  = \int_A\hat{Z(\omega)}Z(\omega)d\P(\omega)
  = \int_Ad\P(\omega) = \P(A)
  \]
  となるから\(\hat{\P}=\P\)である。
\end{proof}



\begin{prob}\label{prob: 1.13}
  例題1.6.6の記号のもと、\(\bar{\omega}\in \Omega\)を固定し、
  \(x=X(\bar{\omega})\)と置く。
  \(\ep > 0\)に対し\(B(x,\ep) \dfn [x-\ep/2, x+\ep/2]\)とし、
  \(y\dfn x+\theta, B(y,\ep) \dfn [y-\ep/2, y+\ep/2]\)と置く。
  \begin{enumerate}
    \item \label{enumi: 1.13-1}
    次を示せ：
    \[
    \frac{1}{\ep}\P(X\in B(x,\ep)) \approx
    \frac{1}{\sqrt{2\pi}}\exp(-\frac{X^2(\bar{\omega})}{2})
    \]
    \item \label{enumi: 1.13-2}
    \(Y\)が\(\tilde{\P}\)のもとで標準正規確率変数であるためには次が必要であることを示せ：
    \[
    \frac{1}{\ep}\tilde{\P}(Y\in B(y,\ep)) \approx
    \frac{1}{\sqrt{2\pi}}\exp(-\frac{Y^2(\bar{\omega})}{2})
    \]
    \item \label{enumi: 1.13-3}
    \(\left\{ X\in B(x,\ep)\right\} = \left\{ Y\in B(y,\ep)\right\}\)
    を示せ。
    これを\(A(\bar{\omega},\ep)\)と置く。
    \(\bar{\omega}\in A(\bar{\omega},\ep)\)である。
    \item \label{enumi: 1.13-4}
    \(Y\)が\(\tilde{\P}\)について標準正規確率変数であるとき、次を示せ：
    \[
    \frac{\tilde{\P}(A(\bar{\omega},\ep))}{\P(A(\bar{\omega},\ep))}
    \approx \exp(-\theta X(\bar{\omega})-\frac{1}{2}\theta^2)
    \]
    右辺は例題1.6.6における\(Z(\bar{\omega})\)であることに注意。
  \end{enumerate}
  以上の手続きにより\(Y\)が\(\tilde{\P}\)についての標準正規確率変数
  となるように\(\P\)を\(\tilde{\P}\)に変換する確率変数\(Z\)を求めることができる。
\end{prob}



\begin{proof}
  \ref{enumi: 1.13-1}。
  \(X\)は標準正規確率変数であることを用いる。
  \(\varphi(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2},
  F(x) = \int_{-\infty}^x \varphi(x)dx\)とおけば
  \(F'(x) = \varphi(x)\)であるから、
  \begin{align*}
    \frac{1}{\ep}\P(X\in B(x,\ep))
    &= \frac{F(x+\ep/2) - F(x-\ep/2)}{\ep} \\
    &= \frac{F(x+\ep/2) - F(x-\ep/2)}{(x+\ep/2) - (x-\ep/2)} \\
    &\approx \varphi(x) = \varphi(X(\bar{\omega}))
  \end{align*}
  である。
  ただし\(\approx\)の部分は微分の定義より従う。
  これは所望の近似である。

  \ref{enumi: 1.13-2}。
  \(Y\)の累積分布関数を\(F_Y(a) \dfn \tilde{\P}(Y\leq a)\)とおいて
  \(\frac{1}{\ep}\tilde{\P}(Y\in B(y,\ep))\)を計算すれば、
  \begin{align*}
    \frac{1}{\ep}\tilde{\P}(Y\in B(y,\ep))
    = \frac{F_Y(y+\ep/2) - F_Y(y-\ep/2)}{(y+\ep/2) - (y-\ep/2)}
    \approx F'_Y(y)
  \end{align*}
  である。
  \(Y\)が標準正規確率変数であるということは、
  \(F_Y(a) = \int_{-\infty}^a \varphi(t)dt\)ということであり、
  それはすなわち\(F'_Y(a) = \varphi(a)\)ということを意味する。
  従って\(Y\)が標準正規確率変数であるには
  \[
  \frac{1}{\ep}\tilde{\P}(Y\in B(y,\ep)) \approx
  \varphi(y)
  \]
  でなければならない。
  \(y = x + \theta = X(\bar{\omega}) + \theta = Y(\bar{\omega})\)であるから、
  これは所望の近似である。

  \ref{enumi: 1.13-3}。
  各\(\omega\in \Omega\)に対して
  \[
  x-\ep/2 \leq X(\omega) \leq x+\ep/2 \iff
  y-\ep/2 \leq Y(\omega) \leq y+\ep/2
  \]
  であることを確かめればよいが、
  これは\(y=x+\theta\)であることと\(Y=X+\theta\)であることから明らかである。
  また\(x = X(\bar{\omega})\)であることから、
  \(\bar{\omega}\in A(\bar{\omega},\ep)\)も従う。

  \ref{enumi: 1.13-4}。
  \(Y\)が\(\tilde{\P}\)に関する標準正規確率変数であることから、
  \begin{align*}
    \frac{\tilde{\P}(A(\bar{\omega},\ep))}{\P(A(\bar{\omega},\ep))}
    &= \frac{\tilde{\P}(Y\in B(y,\ep))}{\P(X\in B(x,\ep))} \\
    &= \frac{F(y+\ep/2) - F(y-\ep/2)}{F(x+\ep/2)-F(x-\ep/2)} \\
    &\approx \frac{\varphi(y)}{\varphi(x)} \\
    &= \exp(\frac{1}{2}x^2-\frac{1}{2}y^2) \\
    &= \exp(\frac{1}{2}x^2-\frac{1}{2}(x+\theta)^2) \\
    &= \exp(-\theta x - \frac{1}{2}\theta^2)
  \end{align*}
  となる。
  \(x = X(\bar{\omega})\)であることに注意すればこれが所望の近似であることがわかる。
\end{proof}





\begin{prob}\label{prob: 1.14}
  \(X\)を確率空間\((\Omega,\mcF,\P)\)上の非負の確率変数で
  \[
  \P(X\leq a) = 1-e^{-\lambda a} \ , \ a \geq 0
  \]
  であるとする。
  ただし\(\lambda > 0\)は定数。
  \(\tilde{\lambda}\)を別の正の定数とし、
  \[
  Z\dfn \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)X}
  \]
  として、各\(A\in \mcF\)に対し
  \[
  \tilde{\P}(A) \dfn \int_AZd\P
  \]
  と置く。
  \begin{enumerate}
    \item \label{enumi: 1.14-1}
    \(\tilde{\P}(\Omega)=1\)を示せ。
    \item \label{enumi: 1.14-2}
    確率変数\(X\)の\(\tilde{\P}\)のもとでの累積分布関数
    \(\tilde{F}(a) = \tilde{\P}(X \leq a)\)を計算せよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 1.14-1}。
  \((1-e^{-\lambda a})' = \lambda e^{-\lambda a}\)であるから、
  \(X\)の密度関数は\(f(a) = \lambda e^{-\lambda a} , a \geq 0\)である。
  実際、\(a \geq 0\)に対して
  \[
  \P(X \leq a) = 1-e^{-\lambda a} = \int_0^a \lambda e^{-\lambda t} dt
  \]
  である。
  定理1.5.2を関数
  \(g(x) = \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)x}\)
  に対して適用すれば、
  \begin{align*}
    \tilde{\P}(\Omega)
    &= \int_0^{\infty} g(x)f(x) dx \\
    &= \int_0^{\infty} \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)x}
    \cdot \lambda e^{-\lambda x} dx \\
    &= \tilde{\lambda}\int_0^{\infty} e^{-\tilde{\lambda}x} dx \\
    &= 1
  \end{align*}
  となる。

  \ref{enumi: 1.14-2}。
  \(A \dfn \left\{ X \leq a \right\}\)と置き、\(\I_A\)を定義関数とする。
  このとき、定理1.6.1より、
  \begin{align*}
    \tilde{\P}(A) &= \int_{\Omega}\I_A(\omega)d\tilde{\P} \\
    &\overset{\bigstar}{=} \int_{\Omega}\I_A(\omega)Z(\omega)d\P(\omega) \\
    &= \int_{A}Z(\omega)d\P(\omega) \\
    &= \int_{A}
    \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)X(\omega)}
    d\P(\omega)
  \end{align*}
  である (\(\bigstar\)の箇所に定理1.6.1を用いた)。
  関数\(g(x) = \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)x}\)
  に定理1.5.2を適用すれば、
  \(X\)の\(\P\)に関する密度関数が
  \(f(x) = \lambda e^{-\lambda x} , x \geq 0\)であることから、
  \begin{align*}
    &= \int_0^a
    \frac{\tilde{\lambda}}{\lambda}e^{-(\tilde{\lambda}-\lambda)x}
    \cdot \lambda e^{-\lambda x}dx \\
    &= \tilde{\lambda}\int_0^a e^{-\tilde{\lambda}x}dx \\
    &= \int_0^{\tilde{\lambda}a} e^{-t}dt \\
    &= 1-e^{-\tilde{\lambda}a}
  \end{align*}
  となる。
\end{proof}





\begin{prob}\label{prob: 1.15}
  \(X\)を確率空間\((\Omega,\mcF,\P)\)上の非負の確率変数で
  すべての\(x\in \R\)に対して正となる密度関数\(f(x)\)を持つと仮定する。
  \(g\)を狭義単調増加で微分可能な関数であって
  \[
  \lim_{y\to -\infty}g(y) = -\infty  \ , \
  \lim_{y\to \infty}g(y) = \infty
  \]
  を満たすものとし、
  確率変数\(Y\)を\(Y\dfn g(X)\)と定義する。
  \(h(y)\)を\(\int_{-\infty}^\infty h(y)dy = 1\)を満たす非負の関数とする。
  \[
  Z \dfn \frac{h(g(X))g'(X)}{f(X)}
  \]
  と定義する。
  \begin{enumerate}
    \item \label{enumi: 1.15-1}
    \(Z\)は非負で、\(\E Z=1\)となることを示せ。
    \item \label{enumi: 1.15-2}
    各\(A\in \mcF\)に対し
    \[
    \tilde{\P}(A) \dfn \int_A Zd\P
    \]
    と定義するとき、\(Y\)は\(\tilde{\P}\)のもとで密度\(h\)であることを示せ。
  \end{enumerate}
\end{prob}



\begin{proof}
  \ref{enumi: 1.15-1}。
  \(p(x) \dfn \frac{h(g(x))g'(x)}{f(x)}\)とする。
  定理1.5.2を\(p(x)\)に用いて計算すれば、
  \begin{align*}
    \E Z &= \E p(X) = \int_{-\infty}^\infty p(x)f(x) dx \\
    &= \int_{-\infty}^\infty h(g(x))g'(x) dx
  \end{align*}
  であるが、ここで\(g\)が狭義単調増加であり
  値域が\(\R\)全体であるという仮定から、
  逆関数が存在し、
  \(x=g^{-1}(t)\)という変数変換によって\(t = g(x) , dt = g'(x)dx\)となるから、
  \begin{align*}
    &= \int_{-\infty}^\infty h(t)dt = 1
  \end{align*}
  となる。

  \ref{enumi: 1.15-2}。
  示すべき等式は以下である：
  \[
  \tilde{\P}(Y \leq a) = \int_{-\infty}^a h(x)dx
  \]
  右辺を計算すると、\(x=g(t)\)という変数変換により
  \begin{align*}
    \int_{-\infty}^a h(x)dx
    &= \int_{-\infty}^{g^{-1}(a)} h(g(t))g'(t) dx \\
    &= \int_{-\infty}^{g^{-1}(a)} p(x)f(x) dx \\
    &= \int_{X \leq g^{-1}(a)}Z(\omega)d\P(\omega)
  \end{align*}
  となる。
  ここで\(g(X) = Y\)であるから
  \(\left\{ X \leq g^{-1}(a) \right\} = \left\{ Y \leq a \right\}\)
  であり、従って
  \begin{align*}
    &= \int_{Y \leq a}Z(\omega)d\P(\omega) = \tilde{\P}(Y \leq a)
  \end{align*}
  となる。
\end{proof}














\newpage


\section{情報と条件付け}\label{section: 2}



\begin{prob}\label{prob: 2.1}
  \((\Omega,\mcF,\P)\)を確率空間、
  \(\mcF_0 \dfn \left\{ \emptyset, \Omega\right\}\)
  を自明な\(\sigma\)-加法族、
  \(X\)を確率変数で\(\mcF_0\)-可測とする。
  このときある定数\(c\)が存在して任意の\(\omega\in \Omega\)に対して
  \(X(\omega)=c\)となる。
\end{prob}

\begin{proof}
  \(X(\omega_1)< X(\omega_2)\)となる異なる元\(\omega_1,\omega_2\in \Omega\)
  が存在すると仮定する。
  \(X(\omega_1) < a < X(\omega_2)\)となる実数\(a\)を取れば、
  \(X\)が\(\mcF_0\)-可測であることから
  \((X \leq a), (X\geq a)\)は\(\mcF_0\)の元を定める。
  よって\((X\leq a), (X \geq a)\)はそれぞれ\(\emptyset\)か\(\Omega\)のいずれかである。
  一方、\(\omega_1\not\in (X\geq a)\)より\((X\geq a) = \emptyset\)であるが、
  これは\(\omega_2 \in (X\geq a)\)に反する。
  以上で\(X\)は退化確率変数である。
\end{proof}



\begin{prob}\label{prob: 2.2}
  \(\Omega_2 \dfn \left\{ HH,HT,TH,TT\right\}\)とし、
  \begin{align*}
    & S_0 = 4 \ , \ S_1(H) = 8 \ , \ S_1(T) = 2, \\
    & S_2(HH) = 16 \ , \ S_2(HT) = S_2(TH) = 4 \ , \ S_2(TT) = 1
  \end{align*}
  を株価とする (\(S_0,S_1,S_2\)は確率変数で、
  \(S_0\)は定値、\(S_1\)は一つめの値で上のように決まる)。
  \begin{align*}
    & \tilde{\P}(HH) = 1/4 \ , \ \tilde{\P}(HT) = 1/4 \ , \
    \tilde{\P}(TH) = 1/4 \ , \ \tilde{\P}(TT) = 1/4, \\
    & \P(HH) = 4/9 \ , \ \P(HT) = 2/9 \ , \
    \P(TH) = 2/9 \ , \ \P(TT) = 1/9, \\
  \end{align*}
  で二つの確率測度\(\tilde{\P},\P\)を定める。
  \[
  X(\omega) \dfn
  \begin{cases}
    1 \ , \ S_2(\omega)=4, \\
    0 \ , \ S_2(\omega)\neq 4,
  \end{cases}
  \]
  を確率変数とする。
  \begin{enumerate}
    \item \label{enumi: 2.2-1}
    \(\sigma(X)\)を明示的に書け。
    \item \label{enumi: 2.2-2}
    \(\sigma(S_1)\)を明示的に書け。
    \item \label{enumi: 2.2-3}
    \(\sigma(X)\)と\(\sigma(S_1)\)は
    確率測度\(\tilde{\P}\)のもとで独立であることを示せ。
    \item \label{enumi: 2.2-4}
    \(\sigma(X)\)と\(\sigma(S_1)\)は
    確率測度\(\P\)のもとで独立でないことを示せ。
    \item \label{enumi: 2.2-5}
    \(\P\)のもとでは\(\P(S_1=8) = 2/3\)であり、
    \(\P(S_1=2) = 1/3\)である。
    \(X=1\)とわかれば\(S_1\)の分布の推定が変わることを直感的に説明せよ。
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 2.2-1}。
  \[
  \sigma (X)
  = \left\{ \emptyset, \Omega, \left\{ HH,TT\right\},
  \left\{ HT,TH\right\} \right\}
  \]

  \ref{enumi: 2.2-2}。
  \[
  \sigma (S_1)
  = \left\{ \emptyset, \Omega, \left\{ HH,HT\right\},
  \left\{ TH,TT\right\} \right\}
  \]

  \ref{enumi: 2.2-3}。
  \(A\in \sigma(X), B\in\sigma(S_1)\)とする。
  \(A,B\)の一方が\(\emptyset,\Omega\)である場合に
  \(\tilde{\P}(A\cap B) = \tilde{\P}(A)\tilde{\P}(B)\)
  となることは自明であるから、どちらも\(\emptyset,\Omega\)でないとして良い。
  このときいずれの場合も\(A\cap B\)は一元集合であり、従って
  \[
  \tilde{\P}(A\cap B) = 1/4 = 1/2 \times 1/2 = \tilde{\P}(A)\tilde{\P}(B)
  \]
  となる。
  これは\(\sigma(X),\sigma(S_1)\)が
  確率測度\(\tilde{\P}\)のもとで独立であることを示している。

  \ref{enumi: 2.2-4}。
  \(A\dfn \left\{ HH,TT\right\}\in \sigma(X) ,
  B\dfn \left\{ HH,HT\right\}\in \sigma(S_1)\)とすると
  \(A\cap B = \left\{ HH\right\}\)であるから
  \(\P(A\cap B) = \P(HH) = 4/9\)であるが、
  \(\P(A) = 4/9 + 1/9 = 5/9, \P(B) = 4/9 + 2/9 = 2/3\)であるから
  \(\P(A)\P(B) = 10/27 \neq 4/9 = \P(A\cap B)\)となる。
  これは\(\sigma(X),\sigma(S_1)\)が
  確率測度\(\P\)のもとで独立でないことを示している。

  \ref{enumi: 2.2-5}。

\end{proof}




\begin{prob}\label{prob: 2.3}
  \(X,Y\)を独立な標準正規確率変数、
  \(\theta\)を定数、
  \begin{align*}
    V &\dfn X\cos \theta + Y\sin \theta \\
    W &\dfn -X\sin \theta + Y\cos \theta
  \end{align*}
  を新たな二つの確立変数とする。
  このとき\(V,W\)が独立な標準正規確率変数であることを示せ。
\end{prob}


\begin{proof}
  \(a\in \R\)とし、
  \[
  C_a \dfn \left\{(x,y)\in \R^2
  \middle| x\cos \theta +y\sin \theta  \leq a\right\}
  \]
  と置く。
  \(X,Y\)は独立で、標準正規確率変数であるから、
  定理2.2.7(v)より
  \((X,Y)\)は同時密度関数として\(\frac{1}{2\pi}e^{-(x^2+y^2)/2}\)を持ち、
  \begin{align*}
    \P(V \leq a)
    &= \P(X\cos \theta + Y\sin \theta \leq a) \\
    &= \P((X,Y)\in C_a)  \\
    &= \frac{1}{2\pi}\iint_{C_a}e^{-(x^2+y^2)/2}dxdy
  \end{align*}
  となる。
  \(x_1=x\cos\theta + y\sin\theta\)と変数変換すれば、
  \(x^2+y^2 = \frac{1}{\cos^2\theta}(x_1^2+y^2 - 2x_1y\sin\theta),
  dxdy = \frac{1}{\cos\theta}dx_1dy\)
  であるから、
  さらに\(x_2\cos\theta = x_1,y_2\cos\theta = y\)と変数変換することで、
  \begin{align*}
    &= \frac{\cos\theta}{2\pi}\int_{-\infty}^\infty
    \int_{-\infty}^{a/\cos\theta}
    e^{-(x_2^2+y_2^2-2x_2y_2\sin\theta )/2}dx_2dy_2 \\
    &= \frac{\cos\theta}{2\pi}\int_{-\infty}^{a/\cos\theta}
    e^{-(x_2^2\cos^2\theta)/2}\int_{-\infty}^\infty
    e^{-(y_2-x_2\sin\theta)^2/2}dy_2dx_2 \\
    &= \frac{\cos\theta}{\sqrt{2\pi}}\int_{-\infty}^{a/\cos\theta}
    e^{-(x_2^2\cos^2\theta)/2}dx_2
  \end{align*}
  \(x_3 = x_2 \cos \theta\)とおけば
  \begin{align*}
    &= \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{a}e^{-x_3^2/2}dx_3
  \end{align*}
  となって\(V\)が標準正規確率変数であることがわかった。
  同じ計算を\(W\)でも行うと、
  \(x_4=-x\sin\theta+y\cos\)とおけば
  \begin{align*}
    \P(W \leq a) &= \frac{1}{2\pi}\iint_{-x\sin\theta+y\cos\theta \leq a}
    e^{-(x^2+y^2)/2}dxdy \\
    &= \frac{1}{2\pi}\int_{-\infty}^a\int_{-\infty}^\infty
    e^{-(y-x_4\cos\theta)^2/2\sin^2\theta - x_4^2/2}
    \frac{1}{\sin\theta}dydx_4 \\
    &= \frac{1}{\sqrt{2\pi}}\int_{-\infty}^ae^{-x_4^2/2}dydx_4
  \end{align*}
  となる。
  よって\(W\)も標準正規確率変数となる。

  \(V,W\)が独立であることを示す。
  \(V,W\)の同時累積分布関数を\(F_{V,W}\)と置く。
  \(a,b\in \R\)に対し、
  \[
  D \dfn \left\{ (x,y)\in \R^2 \middle| x\cos\theta +y\sin\theta \leq a
  \text{かつ} -x\sin\theta + y\cos\theta\leq b\right\}
  \]
  と置くと、\(u=x\cos\theta +y\sin\theta, v=-x\sin\theta + y\cos\theta\)
  の変数変換により、
  \begin{align*}
    F_{V,W}(a,b) &= \P((X,Y)\in D) \\
    &= \iint_D e^{-(x^2+y^2)/2}dxdy \\
    &= \frac{1}{2\pi}\int_{-\infty}^a \int_{-\infty}^b e^{-(u^2+v^2)/2}dudv \\
    &= F_V(a)F_W(b)
  \end{align*}
  となる。
  ここで\(F_V,F_W\)はそれぞれ\(V,W\)の累積分布関数である。
  従って定理2.2.7(iii)\(\Rightarrow\)(i)より\(V,W\)は独立である。

  \textbf{別解答.}
  積率母関数を計算すると、
  \(X,Y\)が独立であることから、定理2.2.7(iv)より、
  \[
  \E e^{uV} = \E e^{u\cos\theta X + u\sin\theta Y}
  = \E e^{u\cos\theta X}  \E e^{u\sin\theta Y}
  \]
  となるが、\(X,Y\)は標準正規確率変数であるから
  \[
  = e^{u^2\cos^2\theta}e^{u^2\sin^2\theta} = e^{u^2}
  \]
  となる。
  このような確率変数\(V\)は標準正規である。
  \(W\)も同じ計算をすれば標準正規であることがわかる。
  独立性も、定理2.2.7(iv)を用いると
  \begin{align*}
    \E e^{tV+uW}
    &= \E e^{(t\cos\theta-u\sin\theta)X + (t\sin\theta+u\cos\theta)Y}
    = \E e^{(t\cos\theta-u\sin\theta)X} \E e^{(t\sin\theta+u\cos\theta)Y} \\
    &= e^{(t\cos\theta-u\sin\theta)^2}e^{(t\sin\theta+u\cos\theta)^2}
    = e^{t^2+u^2}
    = \E e^{tV} \E e^{uW}
  \end{align*}
  と確認できる。
\end{proof}





\begin{prob}\label{prob: 2.4}
  記号は例題2.2.10の通りとする。
  \(X\)を標準正規確率変数とし、
  \(Z\)は次を満たす\(X\)と独立な確率変数とする：
  \[
  \P(Z=1) = \P(Z=-1) = \frac{1}{2}
  \]
  \(Y\dfn XZ\)と定義すると、\(Y\)は標準正規であり、
  \(X,Y\)は無相関であり、独立でない (例題2.2.10)。
  \begin{enumerate}
    \item \label{enumi: 2.4-1}
    \(X,Y\)の同時積率母関数が次であることを確かめよ：
    \[
    \E e^{uX+vY} = e^{(u^2+v^2)/2}\cdot \frac{e^{uv}+e^{-uv}}{2}
    \]
    \item \label{enumi: 2.4-2}
    \ref{enumi: 2.4-1}の式を使って\(\E e^{vY}=e^{v^2/2}\)であることを示せ。
    これは標準正規確率変数の積率母関数であり、
    したがって\(Y\)は標準正規確率変数である。
    \item \label{enumi: 2.4-3}
    \(X,Y\)は独立でないことを示せ。
  \end{enumerate}
\end{prob}

\begin{proof}
  はじめに、本書で「スタンダート・マシン」と呼ばれている証明方法により、
  独立な確率変数\(X,Y\)と\(a\in \R\)に対して
  \[
  \int_{X\leq a}Yd\P = \P(X\leq a)\int_{\Omega}Yd\P
  \]
  となることがわかる。
  \(f\)を任意の可測関数とすると、\(X,f(Y)\)は独立であるから (定理2.2.5)、
  同様にして
  \[
  \int_{X\leq a}f(Y)d\P = \P(X\leq a)\int_{\Omega}f(Y)d\P
  \]
  であることもわかる。

  \ref{enumi: 2.4-1}。
  上記の等式を用いて計算すると、
  \begin{align*}
    \E e^{uX+vY} &= \int_{\Omega}e^{(u+vZ)X}d\P \\
    &= \int_{Z=1}e^{(u+v)X}d\P + \int_{Z=-1}e^{(u-v)X}d\P \\
    &= \frac{1}{2}\int_{\Omega}e^{(u+v)X}d\P
    + \frac{1}{2}\int_{\Omega}e^{(u-v)X}d\P \\
    &= \frac{1}{2}(\E e^{(u+v)X} + \E e^{(u-v)X})
  \end{align*}
  となるが、\(X\)は標準正規確率変数であるから、
  \begin{align*}
    &= \frac{1}{2}(e^{(u+v)^2/2}+e^{(u-v)^2/2}) \\
    &= e^{(u^2+v^2)/2}\cdot \frac{e^{uv}+e^{-uv}}{2}
  \end{align*}
  となって所望の式を得る。

  \ref{enumi: 2.4-2}。
  \(u=0\)を\ref{enumi: 2.4-1}の等式に代入することで
  \(\E e^{vY} = e^{v^2/2}\)を得る。

  \ref{enumi: 2.4-3}。
  \(\E e^{uX}=e^{u^2/2}\)であるから、
  \(\E e^{uX} \E e^{vY} = e^{(u^2+v^2)/2}\)となるが、
  \(\frac{e^{uv}+e^{-uv}}{2}\neq 1\)であるから、
  以上より
  \(\E e^{uX} \E e^{vY} \neq \E e^{uX+vY}\)がわかる。
  ここで定理2.2.7(iv)を適用することで\(X,Y\)が独立でないことがわかる。
\end{proof}


\begin{prob}\label{prob: 2.5}
  \((X,Y)\)を次の同時密度関数を持つ\(1\)組の確率変数とする：
  \[
  f_{X,Y}(x,y) =
  \begin{cases}
    \frac{2|x| + y}{\sqrt{2\pi}}\exp(-\frac{(2|x|+y)^2}{2}) \
    , \ \text{\(y\geq -|x|\)の場合}, \\
    0 \ , \ \text{\(y<-|x|\)の場合}.
  \end{cases}
  \]
  \(X,Y\)はともに標準正規確率変数であり、
  互いに無相関であるが独立でないことを示せ。
\end{prob}

\begin{proof}
  同時密度関数が与えられたときに周辺密度関数を求める式 (cf. 定義2.2.6)
  を用いて計算する。
  \(f_X,f_Y\)をそれぞれ\(X,Y\)の密度関数とする。
  \(f_X\)を計算する。
  以下では\(t=2|x|+y, u=t^2/2\)と変数変換している：
  \begin{align*}
    f_X(x) &= \int_{-\infty}^\infty f_{X,Y}(x,y)dy \\
    &= \int_{-|x|}^\infty
    \frac{2|x| + y}{\sqrt{2\pi}}\exp(-\frac{(2|x|+y)^2}{2}) dy \\
    &= \int_{|x|}^\infty
    \frac{t}{\sqrt{2\pi}}e^{-\frac{t^2}{2}} dt \\
    &= \int_{x^2/2}^\infty \frac{1}{\sqrt{2\pi}}e^{-u} du \\
    &= \frac{1}{\sqrt{2\pi}}e^{-x^2/2}
  \end{align*}
  従って\(X\)は標準正規確率変数である。
  \(f_Y\)を計算する。
  \(y\)を定数と考える。
  \(y \geq 0\)のときはつねに\(y\geq -|x|\)であるから、
  \begin{align*}
    f_Y(y) &= \int_{-\infty}^\infty f_{X,Y}(x,y)dx \\
    &= \int_{-\infty}^\infty
    \frac{2|x| + y}{\sqrt{2\pi}}\exp(-\frac{(2|x|+y)^2}{2}) dx \\
    &= 2\int_0^\infty
    \frac{2x + y}{\sqrt{2\pi}}\exp(-\frac{(2x+y)^2}{2}) dx \\
    &= \int_y^\infty
    \frac{t}{\sqrt{2\pi}}\exp(-\frac{t^2}{2}) dt \\
    &= \int_{y^2/2}^\infty \frac{1}{\sqrt{2\pi}}e^{-u} du \\
    &= \frac{1}{\sqrt{2\pi}}e^{-y^2/2}
  \end{align*}
  となる。
  \(y \leq 0\)のときは
  \[
  y\geq -|x| \ \iff \ ``x \geq -y \text{または} x\leq y''
  \]
  である。
  \(-y \geq 0 \geq y\)に注意すれば絶対値が外れて、
  \begin{align*}
    f_Y(y) &= \int_{-\infty}^\infty f_{X,Y}(x,y)dx \\
    &= \int_{-\infty}^y
    \frac{-2x + y}{\sqrt{2\pi}}\exp(-\frac{(-2x+y)^2}{2}) dx \\
    + \int_{-y}^\infty
    \frac{2x + y}{\sqrt{2\pi}}\exp(-\frac{(2x+y)^2}{2}) dx \\
    &= 2\int_{-y}^\infty
    \frac{2x + y}{\sqrt{2\pi}}\exp(-\frac{(2x+y)^2}{2}) dx \\
    &= \int_{-y}^\infty
    \frac{t}{\sqrt{2\pi}}\exp(-\frac{t^2}{2}) dt \\
    &= \int_{y^2/2}^\infty \frac{1}{\sqrt{2\pi}}e^{-u} du \\
    &= \frac{1}{\sqrt{2\pi}}e^{-y^2/2}
  \end{align*}
  となる。
  以上で\(Y\)も標準正規確率変数であることがわかった。
  さらに\(f_{X,Y},f_X,f_Y\)の式の形を見ると、
  定理2.2.7(i)\(\Leftrightarrow\)(v)より明らかに\(X,Y\)は独立でない。

  定理2.2.7(i)\(\Leftarrow\)(iv)の証明中で用いられている等式
  \[
  \E h(X,Y) = \iint_{\R^2}h(x,y)d\mu_{X,Y}(x,y)
  \]
  を\(h=xy\)に対して用いることで
  \begin{align*}
    \E[XY] &= \iint_{\R^2}xyf_{X,Y}(x,y)dxdy \\
    &= \iint_{y\geq -|x|}xyf_{X,Y}(x,y)dxdy \\
    &= \int_{-\infty}^{\infty}x
    \left( \int_{-|x|}^\infty
    y\frac{2|x| + y}{\sqrt{2\pi}}\exp(-\frac{(2|x|+y)^2}{2})
    dy\right) dx
  \end{align*}
  となるが、ここで
  \[
  \int_{-|x|}^\infty
  y\frac{2|x| + y}{\sqrt{2\pi}}\exp(-\frac{(2|x|+y)^2}{2})
  dy
  \]
  は\(x\)の関数として偶関数であるため、
  それに\(x\)をかけたものは奇関数であり、
  従って積分の結果は\(0\)となる。
  以上より共分散が
  \[
  \E[XY]-\E X \E Y = 0 - 0 = 0
  \]
  と計算でき、\(X,Y\)は無相関である。
\end{proof}


\begin{prob}\label{prob: 2.6}
  \(\Omega \dfn \left\{ a,b,c,d\right\}\)を標本空間、
  \(\Omega\)のすべての部分集合のなす集合\(\mcF\)を\(\sigma\)-加法族とし、
  \[
  \P(a)=\frac{1}{6} \ , \
  \P(b)=\frac{1}{3} \ , \
  \P(c)=\frac{1}{4} \ , \
  \P(d)=\frac{1}{4}
  \]
  で確率測度を定める。
  確率変数\(X,Y\)を
  \begin{align*}
    & X(a) = 1 \ , \
    X(b) = 1 \ , \
    X(c) = -1 \ , \
    X(d) = -1, \\
    & Y(a) = 1 \ , \
    Y(b) = -1 \ , \
    Y(c) = 1 \ , \
    Y(d) = -1,
  \end{align*}
  で定め、\(Z\dfn X+Y\)とする。
  \begin{enumerate}
    \item \label{enumi: 2.6-1}
    \(\sigma(X)\)を明示的にかけ。
    \item \label{enumi: 2.6-2}
    \(\E[Y|X]\)を決定せよ。
    また、部分平均の性質が満たされていることを確認せよ。
    \item \label{enumi: 2.6-3}
    \(\E[Z|X]\)を決定せよ。
    また、部分平均の性質が満たされていることを確認せよ。
    \item \label{enumi: 2.6-4}
    \(\E[Z|X]-\E[Y|X]\)を計算せよ。
    これがなぜ\(X\)と一致するのかについて、
    条件つき期待値の適切な性質を定理2.3.2から引用して述べよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 2.6-1}。
  \(
  \sigma(X) = \left\{ \emptyset, \Omega,
  \left\{ a,b\right\}, \left\{ c,d\right\}\right\}
  \)

  \ref{enumi: 2.6-2}。
  与えられた条件からわかるのは\(X\)の値であり、
  つまり\(\sigma(X)\)のどの集合に属するか、
  というデータが条件つき期待値\(\E[Y|X]\)を考える上で条件から判明する部分である。
  従って\(\E[Y|X](a)=\E[Y|X](b) , \E[Y|X](c)=\E[Y|X](d)\)となる。
  それぞれ\(A,B\)と置く。
  また、\(X=1\)であると判明した場合には、
  そのもとでの\(Y\)の期待値は条件つき期待値の定義から\(A\)であるが、
  明示的に計算すると
  \[
  A = Y(a)\cdot \frac{1}{6}\cdot (\frac{1}{2})^{-1}
  + Y(b)\cdot \frac{1}{3}\cdot (\frac{1}{2})^{-1}
  = \frac{1}{3} - \frac{2}{3} = -\frac{1}{3}
  \]
  となる。
  同様に\(X=-1\)であると判明した場合には、
  \[
  B = Y(c)\cdot \frac{1}{4}\cdot (\frac{1}{2})^{-1}
  + Y(d)\cdot \frac{1}{4}\cdot (\frac{1}{2})^{-1}
  = \frac{1}{2} - \frac{1}{2} = 0
  \]
  となる。
  よって
  \[
  \E[Y|X](a) = \E[Y|X](b) = -\frac{1}{3} \ , \
  \E[Y|X](c) = \E[Y|X](d) = 0
  \]
  がわかる。
  部分平均の性質を満たしていることを確認する。
  \(\emptyset\)の場合は良い。\(\Omega\)の場合、
  \begin{align*}
    &\int_{\Omega}\E[Y|X]d\P
    = -\frac{1}{3}\cdot \frac{1}{6}
    -\frac{1}{3}\cdot \frac{1}{3} + 0 + 0
    = -\frac{1}{6} \\
    &\int_{\Omega}Yd\P
    = \frac{1}{6}
    - \frac{1}{3} + \frac{1}{4} - \frac{1}{4}
    = -\frac{1}{6} \\
  \end{align*}
  なのでこの場合は良い。
  \(\left\{a,b\right\}\)の場合、
  \begin{align*}
    &\int_{\left\{a,b\right\}}\E[Y|X]d\P
    = -\frac{1}{3}\cdot \frac{1}{6}
    -\frac{1}{3}\cdot \frac{1}{3}
    = -\frac{1}{6} \\
    &\int_{\left\{a,b\right\}}Yd\P
    = \frac{1}{6}
    - \frac{1}{3}
    = -\frac{1}{6} \\
  \end{align*}
  なのでこの場合は良い。
  \(\left\{c,d\right\}\)の場合、
  \begin{align*}
    &\int_{\left\{c,d\right\}}\E[Y|X]d\P
    = 0 \\
    &\int_{\left\{a,b\right\}}Yd\P
    = \frac{1}{4}
    - \frac{1}{4}
    = 0 \\
  \end{align*}
  なのでこの場合は良い。
  以上で全ての場合について確認できた。

  \ref{enumi: 2.6-3}。
  線形性 (定理2.3.2(i)) より
  \(\E[Z|X] = \E[(X+Y)|X] = \E[X|X] + \E[Y|X]\)である。
  また既知量の括り出し (定理2.3.2(ii)) より
  \(\E[X|X]=X\)である。
  以上より
  \[
  \begin{cases}
    \E[Z|X](a) = \E[Z|X](b)
    = X(a) + \E[Y|X](a) = 1 - \frac{1}{3} = \frac{2}{3} \\
    \E[Z|X](c) = \E[Z|X](d)
    = X(c) + \E[Y|X](c) = -1 + 0 = -1
  \end{cases}
  \]
  となる。

  部分平均の性質を満たしていることを確認する。
  \(\emptyset\)の場合は良い。\(\Omega\)の場合、
  \begin{align*}
    &\int_{\Omega}\E[Z|X]d\P
    = \frac{2}{3}\cdot \frac{1}{6}
    + \frac{2}{3}\cdot \frac{1}{3}
    - \frac{1}{4} - \frac{1}{4}
    = - \frac{1}{6} \\
    &\int_{\Omega}Zd\P
    = \frac{1}{6}\cdot (1+1)
    + \frac{1}{3}\cdot (1-1)
    + \frac{1}{4}\cdot (-1+1)
    + \frac{1}{4}\cdot (-1-1)
    = - \frac{1}{6} \\
  \end{align*}
  なのでこの場合は良い。
  \(\left\{a,b\right\}\)の場合、
  \begin{align*}
    &\int_{\left\{a,b\right\}}\E[Z|X]d\P
    = \frac{2}{3}\cdot \frac{1}{6}
    + \frac{2}{3}\cdot \frac{1}{3}
    = \frac{1}{3} \\
    &\int_{\left\{a,b\right\}}Zd\P
    = \frac{1}{6}\cdot (1+1)
    + \frac{1}{3}\cdot (1-1)
    = \frac{1}{3} \\
  \end{align*}
  なのでこの場合は良い。
  \(\left\{c,d\right\}\)の場合、
  \begin{align*}
    &\int_{\left\{c,d\right\}}\E[Z|X]d\P
    = -\frac{1}{4}
    -\frac{1}{4}
    = -\frac{1}{2} \\
    &\int_{\left\{c,d\right\}}Zd\P
    = \frac{1}{4}\cdot (-1+1)
    + \frac{1}{4}\cdot (-1-1)
    = -\frac{1}{2} \\
  \end{align*}
  なのでこの場合は良い。
  以上で全ての場合が確認できた。

  \ref{enumi: 2.6-4}。
  線形性 (定理2.3.2(i)) より
  \(\E[Z|X] - \E[Y|X] = \E[(X+Y)|X] - \E[Y|X] = \E[X|X]\)
  であるが、
  既知量の括り出し (定理2.3.2(ii)) より
  \(\E[X|X] = X\)である。
\end{proof}


\begin{prob}\label{prob: 2.7}
  \(Y\)を確率空間\((\Omega,\mcF,\P)\)上の可積分な確率変数、
  \(\mcG\)を\(\mcF\)の部分\(\sigma\)-加法族とする。
  \(\mathrm{Err} \dfn Y-\E[Y|\mcG]\)と定義する。
  これは\(Y\)を\(\mcG\)の情報に基づいて推定したもの\(\E[Y|\mcG]\)との誤差である。
  \(\mathrm{Err}\)は期待値が\(0\)で
  分散\(\Var(\mathrm{Err})\)がいくらかの確率変数である。

  \(X\)を別の\(\mcG\)-可測な確率変数とする。
  このとき
  \[
  \Var(\mathrm{Err}) \leq \Var(Y-X)
  \]
  を示せ。
  言い換えると、
  \(\E[Y|\mcG]\)は\(Y\)の推定のなかでもっとも誤差の分散が小さいものである。
\end{prob}

\begin{proof}
  ヒントに従う。
  \(Z\dfn \E[Y|\mcG]\)とおき、
  \(c\dfn \E[Y-X]\)と置く。
  \(c\)は定数で、\(Z\)は確率変数である。
  部分平均の性質から\(\E[\E[(-)|\mcG]] = \E[(-)]\)となることに注意すると、
  \(\E[Z]=\E[\E[Y|\mcG]] = \E[Y]\)であるから、
  \[
  \Var(Y-Z) = \E[(Y-Z)^2] - (\E[Y-Z])^2
  = \E[(Y-Z)^2] - (\E[Y]-\E[Z])^2
  = \E[(Y-Z)^2]
  \]
  となる。
  よって
  \begin{align*}
    \Var(Y-X) - \Var(Y-X)
    &= \E[ ((Y-Z)+(Z-X-c))^2 - (Y-Z)^2] \\
    &= \E[ (Z-X-c)^2 + 2(Y-Z)(Z-X-c)] \\
    &\geq 2\E[(Y-Z)(Z-X) - c(Y-Z)] \\
    &= 2\E[(Y-Z)(Z-X)]
  \end{align*}
  となる。
  \(\E[(Y-Z)(Z-X)]=0\)を示せばよい。
  \(Z-X\)を一つの\(\mcG\)-可測な確率変数とみることで、
  \(\E[(Y-Z)X]=0\)を示せば十分である。
  \(Z=\E[Y|\mcG]\)であるから、
  \begin{align*}
    \E[(Y-Z)X]
    &= \E[(Y-\E[Y|\mcG])X] \\
    &= \E[XY-X\E[Y|\mcG]] \\
    &\overset{\bigstar}{=} \E[XY-\E[XY|\mcG]] \\
    &= \E[XY]-\E[\E[XY|\mcG]] \\
    &\overset{\spadesuit}{=} \E[XY]-\E[XY] = 0 \\
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所で既知量の括り出し (定理2.3.2(ii)) を用い、
  \(\spadesuit\)の箇所で等式\(\E[\E[(-)|\mcG]]=\E[(-)]\)を用いた。
\end{proof}


\begin{prob}\label{prob: 2.8}
  \(X,Y\)を確率空間\((\Omega,\mcF,\P)\)上の可積分な確率変数とする。
  このとき\(Y-\E[Y|X]\)と\(X\)は無相関であることを示せ。
  より一般に、
  \(Y-\E[Y|X]\)は\(\sigma(X)\)-可測なすべての確率変数と無相関であることを示せ。
\end{prob}

\begin{proof}
  本書の記号のとおり、
  \(Y_2 \dfn Y-\E[Y|X]\)とおく。
  \(Z\)を\(\sigma(X)\)-可測な確率変数とする。
  \[\E[Y_2] = \E[Y-\E[Y|X]] = \E[Y]-\E[\E[Y|X]] = \E[Y]-\E[Y] = 0\]
  に注意して共分散を計算すると、
  \begin{align*}
    \Cov(Y_2,Z) &= \E[Y_2Z] - \E[Y_2]\E[Z] \\
    &= \E[(Y-\E[Y|X])Z] \\
    &= \E[YZ] - \E[Z\E[Y|X]]
  \end{align*}
  となる。
  ここで\(Z\)は\(\sigma(X)\)-可測であるから、
  既知量の括り出しより
  \(\E[Z\E[Y|X]] = \E[\E[YZ|X]] = \E[YZ]\)
  となり、
  以上より\(\Cov(Y_2,Z) = 0\)がわかる。
  すなわち\(Y_2\)は\(Z\)を無相関である。
\end{proof}


\begin{prob}\label{prob: 2.9}
  \((\Omega,\mcF,\P)\)を確率空間、\(X\)を確率変数、\(f:\R\to \R\)を関数とする。
  \begin{enumerate}
    \item \label{enumi: 2.9-1}
    \(f(X)\)で生成される\(\sigma\)-加法族\(\sigma(f(X))\)が
    \(X\)で生成される\(\sigma\)-加法族\(\sigma(X)\)より真に小さいが
    自明な\(\sigma\)-加法族
    (つまり\(\left\{\emptyset,\Omega\right\}\))
    とは異なるような例を挙げよ。
    \item \label{enumi: 2.9-2}
    \(\sigma(f(X))\)が\(\sigma(X)\)より大きくなることはあり得るか？
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 2.9-1}。
  \(\Omega=\R\)として\(\mcF\)としてボレル集合族\(\mcB\)をとる。
  確率変数\(X\)として\(X=\id_{\R}\)をとり、
  \(f\)として\(f(x) = 0 , (x < 0), 1 , (x \geq 0)\)
  と定めれば、
  \(f\)の生成する\(\sigma\)-加法族は
  \[
  \left\{ \emptyset , \Omega = \R , (-\infty,0) , [0,\infty)\right\}
  \]
  となってボレル集合族より真に小さいが自明ではない。

  \ref{enumi: 2.9-2}。
  \(\mcB\)を\(\R\)のボレル集合族とする。
  \(f\)が可測であれば、
  \(f^{-1}(\mcB)\subset \mcB\)であるから、
  \(\sigma(f\circ X) = X^{-1}(f^{-1}(\mcB))
  \subset X^{-1}(\mcB) = \sigma(X)\)となる。
  よって\(\sigma(f(X))\)が\(\sigma(X)\)より大きくなることはあり得ない。
  \(f\)が可測でない場合にはわからなかった。
\end{proof}



\begin{prob}\label{prob: 2.10}
  \((\Omega,\mcF,\P)\)を確率空間、
  \(X,Y\)を確率変数で同時密度\(f_{X,Y}(x,y)\)を持ち、
  \(\E|Y|<\infty\)であるとする。
  特に任意のボレル集合\(C\subset \R^2\)に対し
  \[
  \P((X,Y)\in C) = \iint_Cf_{X,Y}(x,y)dxdy
  \]
  となる。
  \(f_X\)を\(X\)の密度関数とし、
  \[f_{Y|X}(y|x) \dfn \frac{f_{X,Y}(x,y)}{f_X(x)}\]
  とする。
  \[
  g(x) \dfn \int_{-\infty}^\infty yf_{Y|X}(y|x)dy
  = \int_{-\infty}^\infty \frac{yf_{X,Y}(x,y)}{f_X(x)} dy
  \]
  とする。
  \(A\)を\(\sigma(X)\)に属する集合とするとき、
  \[
  \int_A g(X) d\P = \int_A Y d\P
  \]
  となることを示せ。
\end{prob}

\begin{proof}
  \(A\)として\(X \leq a\)となる集合の場合のみ考えれば良い。
  計算すると、
  \begin{align*}
    \int_{X\leq a}g(X)d\P &= \int_{-\infty}^a g(x)f_X(x) dx \\
    &= \int_{-\infty}^a\int_{-\infty}^\infty yf_{X,Y}(x,y) dydx
  \end{align*}
  となる。
  ここで関数\(h(x,y) = y , (x \leq a) , 0 , (x>0)\)に対して
  式(2.6.3)を適用すると、
  \[
  = \E h(X,Y) = \int_{\Omega}h(X(\omega),Y(\omega))d\P(\omega)
  = \int_A Y d\P
  \]
  となる。
\end{proof}







\begin{prob}\label{prob: 2.11}
  \((\Omega,\mcF,\P)\)を確率空間、\(X\)を確率変数とする。
  \begin{enumerate}
    \item \label{enumi: 2.11-1}
    \(W\)を非負の\(\sigma(X)\)-可測な確率変数とするとき、
    ある関数\(g\)が存在して\(W=g(X)\)を満たすことを示せ。
    \item \label{enumi: 2.11-2}
    \(Y\)を非負の確率変数とし、\(X,Y\)は同時密度を持つとは限らないとする。
    \(\E[Y|X] = g(X)\)となる\(g\)が存在することを示せ。
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 2.11-1}。
  ヒントに従う。
  \(W\)がある\(A\in \sigma(X)\)に対する定義関数\(\I_A\)であるとする。
  \(A\in \sigma(X)\)であることから、
  あるボレル集合\(B\subset \R\)が存在して
  \(A = (X\in B)\)である。
  \(g:\R\to \R\)を
  \(b\in B\)に対して\(g(b)=1\)、
  \(b\not\in B\)に対して\(g(b)=0\)と定義すると、
  \(g(X)(\omega) = g(X(\omega))\)であるから、
  \[\omega\in A \ \iff \ X(\omega)\in B \ \iff \ g(X)(\omega) = 1\]
  となって\(g(X) = W\)となる。

  次に\(W\)が単関数\(W=\sum_{i=1}^N \I_{A_i}\)の形であるとする。
  各\(A_i\)は互いに交わらないとしてよい。
  このとき各\(i\)に対して\(\I_{A_i}=g_i(X)\)となる\(g_i\)をとれば、
  \(g = \sum_{i=1}^Ng_i\)に対して\(W = g(X)\)となる。

  最後に一般の場合を考える。
  \(W\)は非負であるから、単関数の単調増加な列\(W_i\)が存在して
  \(W_i\to W , a.e.\)となる。
  各\(W_i\)に対して関数\(g_i\)を\(W_i = g_i(X)\)となるようにとれば、
  \(W_i\)が単調増加な列であることから\(g_i\)もそうである。
  \(g=\lim g_i\)とおけば\(g(X) = \lim g_i(X) = \lim W_i = W\)となる。
  以上で全て示された。


  \ref{enumi: 2.11-2}。
  \(\E[Y|X]\)は\(\sigma(X)\)-可測であり、
  また\(Y\)が非負であることから\(\E[Y|X]\)も非負である。
  よって\ref{enumi: 2.11-1}を用いればある\(g\)があって
  \(\E[Y|X] = g(X)\)となる。
\end{proof}










\newpage

\section{ブラウン運動}\label{section: 3}


\begin{prob}\label{prob: 3.1}
  \(W(t) , t\geq 0\)をブラウン運動、
  \(\mcF(t) , t\geq 0\)を\(W\)に対するfiltrationとするとき、
  任意の\(0\leq t < u_1 < u_2\)に対して
  増分\(W(u_2)-W(u_1)\)は\(\mcF(t)\)と独立であることを示せ。
\end{prob}

\begin{proof}
  任意にボレル集合\(B\)と\(A\in \mcF(t)\)をとる。
  \(B' = (W(u_2)-W(u_1)\in B)\subset \Omega\)とおく。
  \(A\in \mcF(u_1)\)でもあるので、
  \(W(u_2)-W(u_1)\)が\(\mcF(u_1)\)と独立であることから、
  \(\P(B'\cap A) = \P(B')\P(A)\)となる。
  これは\(W(u_2)-W(u_1)\)が\(\mcF(t)\)と独立であることを示している。
\end{proof}





\begin{prob}\label{prob: 3.2}
  \(W(t), t\geq 0\)をブラウン運動、
  \(\mcF(t) , t\geq 0\)を\(W\)に対するfiltrationとするとき、
  \(W^2(t) - t\)はマルチンゲールであることを示せ。
\end{prob}

\begin{proof}
  任意に\(0\leq s \leq t\)をとる。
  \(\E[W^2(t) - t|\mcF(s)] = W^2(s)-s\)を示さねばならない。
  ブラウン運動の定義から、
  \[
  \E[(W(t)-W(s))^2] = \E[(W(t)-W(s))^2] - \E[W(t)-W(s)]^2
  = \Var(W(t)-W(s)) = t-s
  \]
  であることに注意すると、
  \begin{align*}
    \E[W^2(t) - t|\mcF(s)]
    &= \E[(W(t)-W(s) + W(s))^2 - t | \mcF(s)] \\
    &= \E[(W(t)-W(s))^2 + 2W(s)(W(t)-W(s)) + W(s)^2 - t | \mcF(s)] \\
    &\overset{\bigstar}{=}
    \E[(W(t)-W(s))^2|\mcF(s)]
    + 2W(s)\E[W(t)-W(s)|\mcF(s)] + W(s)^2 - t \\
    &\overset{\spadesuit}{=} \E[(W(t)-W(s))^2]
    + 2W(s)\E[W(t)-W(s)] + W(s)^2 - t \\
    &\overset{\clubsuit}{=} (t-s) + W(s)^2 - t \\
    &= W(s)^2 - s
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は条件つき期待値の線形性と
  既知量の括り出しを用いていて、
  \(\spadesuit\)の部分は\(W(t)-W(s)\)が\(\mcF(s)\)と独立であることを用いていて、
  \(\clubsuit\)の部分は
  \(\E[W(t)-W(s)] = 0\) (ブラウン運動の定義) と
  \(\E[(W(t)-W(s))^2] = t-s\) (はじめの注意) を用いている。
  以上で示された。
\end{proof}


\begin{prob}\label{prob: 3.3}
  \(X\)を平均\(\mu\)で分散\(\sigma^2\)の正規確率変数とするとき、
  \(\E[(X-\mu)^4] = 3\sigma^4\)となることを示せ。
\end{prob}

\begin{proof}
  積率母関数\(\varphi(u) \dfn \E[e^{u(X-\mu)}] = e^{u^2\sigma^2/2}\)を
  \(u\)でいっぱい微分すると以下のようになる：
  \begin{align*}
    \varphi'(u) &= \E[(X-\mu)e^{u(X-\mu)}]
    = \sigma^2ue^{u^2\sigma^2/2}
    = \sigma^2u\varphi(u) \\
    \varphi''(u) &= \E[(X-\mu)^2e^{u(X-\mu)}]
    = \sigma^2(\varphi(u) + u\varphi'(u))
    = (\sigma^2 + u^2\sigma^4)\varphi(u) \\
    \varphi'''(u) &= \E[(X-\mu)^3e^{u(X-\mu)}]
    = 2u\sigma^4\varphi(u) + (\sigma^2 + u^2\sigma^4)\varphi'(u)
    = (3u\sigma^4 + u^3\sigma^6)\varphi(u) \\
    \varphi''''(u) &= \E[(X-\mu)^4e^{u(X-\mu)}]
    = (3\sigma^4 + 3u^2\sigma^6)\varphi(u)
    + (3u\sigma^4 + u^3\sigma^6)\varphi'(u)
    = (3\sigma^4 + 6u^2\sigma^6 + u^4\sigma^8)\varphi(u)
  \end{align*}
  よって\(\E[(X-\mu)^4] = \varphi''''(0) = 3\sigma^4\)となる。
\end{proof}


\begin{prob}\label{prob: 3.4}
  \(T > 0\)として\(\Pi\)を区間\([0,T]\)の分割
  \(0=t_0 < t_1 < \cdots < t_n = T\)とする。
  \(W(t)\)をブラウン運動とする。
  \begin{enumerate}
    \item \label{enumi: 3.4-1}
    \(n\to \infty\)かつ\(\| \Pi\| \to 0\)であるときに、
    標本の1次変分
    \[
    \sum_{j=0}^{n-1}|W(t_{j+1})-W(t_j)|
    \]
    は\(W\)のほとんど全ての経路で\(\infty\)に発散することを示せ。
    \item \label{enumi: 3.4-2}
    \(n\to \infty\)かつ\(\| \Pi\| \to 0\)であるときに、
    標本の3次変分
    \[
    \sum_{j=0}^{n-1}|W(t_{j+1})-W(t_j)|^3
    \]
    は\(W\)のほとんどすべての経路で\(0\)に収束することを示せ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 3.4-1}。
  ヒントの通り
  \[
  \sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j))^2
  \leq \max_{0\leq k \leq n-1}|W(t_{j+1}) - W(t_j)|\cdot
  \sum_{j=0}^{n-1}|W(t_{j+1}) - W(t_j)|
  \]
  であるが、\(W\)は各標本に対して連続関数であるから、
  各標本\(\omega\)に対してある\(\delta > 0\)があって
  \(\max_{0\leq k \leq n-1}|W(t_{j+1}) - W(t_j)| < \delta\|\Pi \|\)
  となる。
  よって
  \[
  \frac{1}{\delta\|\Pi \|}\sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j))^2
  < \sum_{j=0}^{n-1}|W(t_{j+1}) - W(t_j)|
  \]
  がわかるが、\(\|\Pi \|\to 0\)のもとで
  \[
  \sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j))^2  \to T\neq 0
  \]
  であるから、左辺は\(\to \infty\)となり、特に右辺も\(\infty\)に発散する。

  \ref{enumi: 3.4-2}。
  \ref{enumi: 3.4-1}と同じ記号を用いると
  \begin{align*}
    \sum_{j=0}^{n-1}|W(t_{j+1}) - W(t_j)|^3
    &\leq \max_{0\leq k \leq n-1}|W(t_{j+1}) - W(t_j)|\cdot
    \sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j))^2 \\
    &< \delta\|\Pi\|\sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j))^2 \\
    &\to 0 \ , \ (\|\Pi\| \to 0)
  \end{align*}
  となる。
\end{proof}





\begin{prob}\label{prob: 3.5}
  金利\(r\)とボラティリティ\(\sigma > 0\)を定数とする。
  \[
  S(t) \dfn S(0) \exp((r-\frac{1}{2}\sigma^2)t + \sigma W(t))
  \]
  を期待収益率\(r\)の幾何ブラウン運動
  (つまりブラウン運動\(W(t)\)から上の式で定まる確率変数の族)
  で当初の株価\(S(0)\)は正とする。
  \(K>0\)を定数とする。
  \(T>0\)に対して次の等式を示せ：
  \[
  \E\left[ e^{-rT}(S(T)-K)^+\right]
  = S(0)N(d_+(T,S(0))) - Ke^{-rT}N(d_-(T,S(0)))
  \]
  ただしここで\((S(T)-K)^+ = \max\left\{0,S(T)-K\right\}\)で、
  \[
  d_{\pm}(T,S(0)) \dfn \frac{1}{\sigma\sqrt{T}}
  \left[ \log\frac{S(0)}{K} + \left( r\pm\frac{\sigma^2}{2}\right)T\right]
  \]
  であり、\(N\)は累積標準正規分布、つまり
  \[
  N(y) \dfn \frac{1}{\sqrt{2\pi}}\int_{-\infty}^y\exp(-\frac{1}{2}x^2)dx
  \]
  である。
\end{prob}

\begin{proof}
  \(W(t) , t \geq 0\)はブラウン運動なので、
  \(W(T)\)は平均\(0\)で分散\(T\)の確率変数である。
  よって\(W(T)\)の分布関数は
  \(f_T(x) \dfn \frac{1}{\sqrt{2\pi T}}e^{-x^2/2T}\)である。
  ここで
  \begin{align*}
    g(x) &\dfn S(0)\exp\left( (r-\frac{1}{2}\sigma^2)T + \sigma x\right) \\
    h(x) &\dfn e^{-rT}(g(x) - K)^+
  \end{align*}
  と定義すれば、示すべき等式の左辺は\(\E[h(W(T))]\)である。
  \(d_{\pm} \dfn d_{\pm}(T,S(0))\)と略記する。
  \(g(x)\geq K\)となる\(x\)の範囲を求めると、
  \begin{align*}
    g(x)\geq K &\iff
    S(0)\exp\left( (r-\frac{1}{2}\sigma^2)T + \sigma x\right) \geq K \\
    &\iff (r-\frac{1}{2}\sigma^2)T + \sigma x
    \geq \log \frac{K}{S(0)} \\
    &\iff x \geq \frac{1}{\sigma}
    \left(\log \frac{K}{S(0)} - (r-\frac{1}{2}\sigma^2)T\right) \\
    &\iff x \geq -\frac{1}{\sigma}
    \left(\log \frac{S(0)}{K} + (r-\frac{1}{2}\sigma^2)T\right) \\
    = -d_-\sqrt{T}
  \end{align*}
  である。
  \(W(T)\)の分布関数が\(f_T\)であることから、次のように計算できる：
  \begin{align*}
    \E[h(W(T))] &= \int_{-\infty}^{\infty}h(x)f_T(x)dx \\
    &= \frac{1}{\sqrt{2\pi T}}\int_{-\infty}^{\infty}
    e^{-rT}(g(x) - K)^+e^{-x^2/2T}dx \\
    &= \frac{1}{\sqrt{2\pi T}}e^{-rT}\int_{-d_-\sqrt{T}}^{\infty}
    (g(x) - K)^+e^{-x^2/2T}dx \\
    &= \frac{1}{\sqrt{2\pi T}}e^{-rT}
    \left( \int_{-d_-\sqrt{T}}^{\infty}g(x)e^{-x^2/2T}dx
    - \int_{-d_-\sqrt{T}}^{\infty}Ke^{-x^2/2T}dx\right) \\
    &= \frac{1}{\sqrt{2\pi T}}e^{-rT}S(0)e^{(r-\sigma^2/2)T}
    \int_{-d_-\sqrt{T}}^{\infty}e^{\sigma x}e^{-x^2/2T}dx
    - \frac{1}{\sqrt{2\pi T}}e^{-rT}K
    \int_{-\infty}^{d_-\sqrt{T}}e^{-x^2/2T}dx \\
    &= \frac{1}{\sqrt{2\pi T}}S(0)
    \int_{-d_-\sqrt{T}}^{\infty}e^{-\sigma^2T/2 + \sigma x - x^2/2T}dx
    - \frac{1}{\sqrt{2\pi}}Ke^{-rT}
    \int_{-\infty}^{d_-}e^{-x^2/2}dx \\
    &= \frac{1}{\sqrt{2\pi T}}S(0)
    \int_{-d_-\sqrt{T}}^{\infty}e^{-(x - \sigma T)^2/2T}dx
    - Ke^{-rT}N(d_-) \\
    &= \frac{1}{\sqrt{2\pi T}}S(0)
    \int_{-\infty}^{d_-\sqrt{T}}e^{-(x + \sigma T)^2/2T}dx
    - Ke^{-rT}N(d_-) \\
  \end{align*}
  となる。
  ここで\(d_-\sqrt{T} + \sigma T = d_+\sqrt{T}\)であるから、
  \begin{align*}
    &= \frac{1}{\sqrt{2\pi T}}S(0)
    \int_{-\infty}^{d_+\sqrt{T}}e^{-x^2/2T}dx
    - Ke^{-rT}N(d_-) \\
    &= \frac{1}{\sqrt{2\pi T}}S(0) N(d_+) - Ke^{-rT}N(d_-) \\
  \end{align*}
  を得る。
  これは所望の結果である。
\end{proof}


\begin{prob}\label{prob: 3.6}
  \(W(t) , t\geq 0\)をブラウン運動、
  \(\mcF(t) , t\geq 0\)を関連するfiltrationとする。
  \begin{enumerate}
    \item \label{enumi: 3.6-1}
    \(\mu \in \R\)に対し
    \[
    X(t) \dfn \mu t + W(t)
    \]
    と置く (ドリフト\(\mu\)を持つブラウン運動)。
    \(0\leq s < t\)に対し\(\tau = t-s\)とおき、
    \[
    p(\tau,x,y) \dfn \frac{1}{\sqrt{2\pi\tau}}
    \exp\left( -\frac{(y-x-\mu\tau)^2}{2\tau}\right)
    \]
    とする。
    任意の可測関数\(f(x)\)に対し
    \[g(x) \dfn \int_{-\infty}^\infty f(y)p(\tau,x,y)dy\]
    と定めると\(\E[f(X(t))|\mcF(s)] = g(X(s))\)となることを示せ。
    とくに\(X\)はマルコフ性を持つ。
    \item \label{enumi: 3.6-2}
    \(\nu\in \R\)と\(\sigma > 0\)に対し、
    \[
    S(t) = S(0)e^{\sigma W(t) + \nu t}
    \]
    と置く (幾何的ブラウン運動)。
    \(\tau = t-s\)とおき、
    \[
    p(\tau,x,y) \dfn \frac{1}{\sigma y \sqrt{2\pi \tau}}
    \exp\left( -\frac{(\log(y/x) - \nu\tau)^2}{2\sigma^2\tau}\right)
    \]
    とする。
    任意の可測関数\(f(x)\)に対し
    \[g(x) \dfn \int_{-\infty}^\infty f(y)p(\tau,x,y)dy\]
    と定めると\(\E[f(S(t))|\mcF(s)] = S(s)\)となることを示せ。
    とくに\(S\)はマルコフ性を持つ。
  \end{enumerate}
\end{prob}


\begin{proof}
  任意に\(0\leq s < t\)をとる。
  \(W(t)-W(s)\)は平均\(0\)で分散\(t-s\)の正規確率変数であるから、
  その密度関数は
  \[\varphi(x) \dfn \frac{1}{\sqrt{2\pi\tau}}e^{-\frac{x^2}{2\tau}}\]
  である (\(\tau = t-s\)である)。
  以下において\(f\)は任意の可測関数である。

  \ref{enumi: 3.6-1}。
  \(f(X(t)) = f(\mu t + W(t)) = f(\mu\tau + (W(t)-W(s)) + X(s))\)
  と変形する。
  \(W(t)-W(s)\)は\(\mcF(s)\)と独立な密度関数\(\varphi\)の確率変数で、
  \(X(s)\)は\(\mcF(s)\)-可測であるから、
  \(X(s)\)を仮の変数\(\alpha\)で置き換えて
  \[
  g(\alpha) \dfn \int_{-\infty}^{\infty}f(\mu\tau +x+\alpha)\varphi(x)dx
  \]
  とおけば、独立性の補題から
  \[\E[f(X(t))|\mcF(s)] = g(X(s))\]
  となる。
  とくに\(X\)はマルコフ過程である。
  関数\(g(x)\)を計算すれば、
  \begin{align*}
    g(x)
    &= \int_{-\infty}^{\infty}f(\mu\tau +x+y)\varphi(y)dy \\
    &= \int_{-\infty}^{\infty}f(y)\varphi(y-x-\mu\tau)dy
  \end{align*}
  となるが、
  \[
  \varphi(y-x-\mu\tau) =
  \frac{1}{\sqrt{2\pi\tau}}\exp \left( -\frac{(y-x-\mu\tau)^2}{2\tau}\right)
  = p(\tau,x,y)
  \]
  であるから、\(p(\tau,x,y)\)が\(X\)の推移密度であることもわかる。

  \ref{enumi: 3.6-2}。
  次のように変形する：
  \[
  f(S(t)) = f(S(0)e^{\sigma W(t) + \nu t})
  = f(S(0)e^{\sigma W(s)+\nu s}e^{\sigma(W(t)-W(s)) + \nu\tau})
  = f(S(s)e^{\sigma(W(t)-W(s)) + \nu\tau}).
  \]
  \(W(t)-W(s)\)は\(\mcF(s)\)と独立な密度関数\(\varphi\)の確率変数で、
  \(S(s)\)は\(\mcF(s)\)-可測であるから、
  \(S(s)\)を仮の変数\(\alpha\)で置き換えて
  \[
  g(\alpha) \dfn
  \int_{-\infty}^{\infty}f(\alpha e^{\sigma x + \nu\tau})\varphi(x)dx
  \]
  とおけば、独立性の補題から
  \[
  \E[f(S(t))|\mcF(s)] = g(S(s))
  \]
  となる。
  とくに\(S\)はマルコフ過程である。
  関数\(g(x)\)を計算すれば、
  \begin{align*}
    g(x) &= \int_{-\infty}^{\infty}f(xe^{\sigma y + \nu\tau})\varphi(y)dy \\
    &= \int_{-\infty}^{\infty}
    f(xe^{y + \nu\tau})\frac{1}{\sigma}
    \varphi\left(\frac{y}{\sigma}\right)dy \\
    &= \int_{-\infty}^{\infty}
    f(xe^y)\frac{1}{\sigma}
    \varphi\left(\frac{y - \nu\tau}{\sigma}\right)dy \\
    &= \int_0^{\infty}f(xy)\frac{1}{\sigma y}
    \varphi\left(\frac{\log y - \nu\tau}{\sigma} \right)dy \\
    &= \int_0^{\infty}f(y)\frac{1}{\sigma y}
    \varphi\left(\frac{\log \frac{y}{x} - \nu\tau}{\sigma}
    \right)dy
  \end{align*}
  となるが、
  \begin{align*}
    \frac{1}{\sigma y}
    \varphi\left(\frac{\log \left(\frac{y}{x}\right) - \nu\tau}{\sigma}
    \right)
    &= \frac{1}{\sigma y\sqrt{2\pi\tau}}
    \exp\left( -\left(\frac{\log \left(\frac{y}{x}\right) - \nu\tau}{\sigma}
    \right)^2/2\tau \right) \\
    &= \frac{1}{\sigma y\sqrt{2\pi\tau}}
    \exp\left( -\frac{\left(\log \frac{y}{x} -
    \nu\tau\right)^2}{2\sigma^2\tau}\right) \\
    &= p(\tau,x,y)
  \end{align*}
  であるから、\(p(\tau,x,y)\)が\(S\)の推移密度であることもわかる。
\end{proof}




\begin{prob}\label{prob: 3.7}
  \(W\)をブラウン運動とし、
  \(m > 0, \mu\in \R\)を固定する。
  \(0\leq t < \infty\)に対し
  \begin{align*}
    X(t) &\dfn \mu t + W(t) , \\
    \tau_m &\dfn \min\left\{ t\geq 0 \middle| X(t) = m \right\}
  \end{align*}
  と定め、
  \(X(t)\)がどの時刻\(t\)でもレベル\(m\)に到達しない場合は\(\tau_m=\infty\)と定める。
  \(\sigma\)を正の整数とし、
  \[
  Z(t) \dfn \exp \left( \sigma X(t)
  - \left( \sigma\mu + \frac{1}{2}\sigma^2\right) t\right)
  \]
  とする。
  \begin{enumerate}
    \item \label{enumi: 3.7-1}
    \(Z(t) , t\geq 0\)がマルチンゲールであることを示せ。
    \item \label{enumi: 3.7-2}
    \ref{enumi: 3.7-1}を用いて次を示せ：
    \[
    \E\left[ \exp\left(
    \sigma X(t\wedge\tau_m) - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)
    (t\wedge\tau_m)
    \right)\right] = 1 \ , \ (t\geq 0).
    \]
    ただしここで\(t\wedge \tau_m \dfn \min \left\{ t,\tau_m\right\}\)
    である。
    \item \label{enumi: 3.7-3}
    \(\mu \geq 0\)とする。\(\sigma > 0\)に対して次を示せ：
    \[
    \E\left[ \exp\left(
    \sigma m - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
    \right) \I_{\tau_m < \infty}\right] = 1.
    \]
    これを用いて\(\P(\tau_m<\infty) = 1\)を示せ。
    また次のラプラス変換を求めよ：
    \[
    \E e^{-\alpha\tau_m} = e^{m\mu - m\sqrt{2\alpha+\mu^2}} \
    , \ \alpha > 0.
    \]
    \item \label{enumi: 3.7-4}
    \(\mu > 0\)であれば\(\E\tau_m < \infty\)となることを示せ。
    \(\E\tau_m\)の公式を求めよ。
    \item \label{enumi: 3.7-5}
    \(\mu < 0\)とする。
    \(\sigma > -2\mu\)に対して次を示せ：
    \[
    \E\left[ \exp\left(
    \sigma m - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
    \right) \I_{\tau_m < \infty}\right] = 1.
    \]
    これを用いて\(\P(\tau_m<\infty) = e^{-2m|\mu|}\)を示せ。
    これは真に\(1\)より小さい。
    また次のラプラス変換を求めよ：
    \[
    \E e^{-\alpha\tau_m} = e^{m\mu - m\sqrt{2\alpha+\mu^2}} \
    , \ \alpha > 0.
    \]
  \end{enumerate}
\end{prob}


\begin{proof}
  以下では\(\mcF(t) , t\geq 0\)を\(W\)に関するfiltrationとし、
  \(0\leq s < t\)に対して\(\tau \dfn t-s\)とおく。

  \ref{enumi: 3.7-1}。
  \(0\leq s < t\)をとって
  \(\E[Z(t)|\mcF(s)] = Z(s)\)を確認する。
  \begin{align*}
    Z(t) &= \exp \left( \sigma X(t)
    - \left( \sigma\mu + \frac{1}{2}\sigma^2\right) t\right) \\
    &= \exp \left( \sigma (X(t)-X(s)) + \sigma X(s)
    - \left( \sigma\mu + \frac{1}{2}\sigma^2\right) \tau
    + \left( \sigma\mu + \frac{1}{2}\sigma^2\right) s \right) \\
    &= Z(s)\exp \left( \sigma (W(t)-W(s)) + \mu\sigma\tau
    - \left( \sigma\mu + \frac{1}{2}\sigma^2\right) \tau \right) \\
    &= Z(s)\exp \left( \sigma (W(t)-W(s)) - \frac{1}{2}\sigma^2\tau \right)
  \end{align*}
  と変形する。
  \(Z(s)\)は\(\mcF(s)\)-可測であるから、
  既知量の括り出しによって
  \begin{align*}
    \E[Z(t)|\mcF(s)] &=
    \E\left[Z(s)\exp \left( \sigma (W(t)-W(s))
    - \frac{1}{2}\sigma^2\tau \right) \middle| \mcF(s)\right] \\
    &= Z(s)\E\left[\exp \left( \sigma (W(t)-W(s))
    - \frac{1}{2}\sigma^2\tau \right) \middle| \mcF(s)\right]
  \end{align*}
  となる。
  \(W(t)-W(s)\)は\(\mcF(s)\)と独立な確率変数なので、さらに
  \[
  = Z(s)\E\left[\exp \left( \sigma (W(t)-W(s))
  - \frac{1}{2}\sigma^2\tau \right)\right]
  \]
  となる。
  また、\(W(t)-W(s)\)は平均\(0\)で分散\(\tau = t-s\)の
  正規確率変数であるから、その密度関数は
  \[\varphi(x) \dfn \frac{1}{\sqrt{2\pi\tau}}e^{-\frac{x^2}{2\tau}}\]
  であり、
  従って
  \begin{align*}
    \E\left[\exp \left( \sigma (W(t)-W(s))
    - \frac{1}{2}\sigma^2\tau \right)\right]
    &= \frac{1}{\sqrt{2\pi\tau}} \int_{-\infty}^\infty
    \exp\left( \sigma x - \frac{1}{2}\sigma^2\tau
    - \frac{x^2}{2\tau}\right) dx \\
    &= \frac{1}{\sqrt{2\pi\tau}} \int_{-\infty}^\infty
    \exp\left( -\frac{1}{2}
    \left( x^2 - 2\tau\sigma x + \sigma^2\tau^2 \right)\right) dx \\
    &= \frac{1}{\sqrt{2\pi\tau}} \int_{-\infty}^\infty
    \exp\left( -\frac{1}{2}( x - \tau\sigma)^2\right) dx \\
    &= 1
  \end{align*}
  となる。
  以上より
  \begin{align*}
    \E[Z(t)|\mcF(s)]
    &= Z(s)\E\left[\exp \left( \sigma (W(t)-W(s))
    - \frac{1}{2}\sigma^2\tau \right)\right] \\
    &= Z(s)
  \end{align*}
  となる。
  以上で\(Z\)はマルチンゲールである。

  \ref{enumi: 3.7-2}。
  示すべきことは各\(t\)に対して
  \(\E[Z(t\wedge \tau_m)] = 1\)となることである。
  \(t\wedge\tau_m \leq 0\)であるので、
  \(Z\)がマルチンゲールであることと
  \(Z(t\wedge\tau_m)\)が\(\mcF(0)\)と独立であることから
  \[
  \E[Z(t\wedge \tau_m)] = \E[Z(t\wedge\tau_m)\mid \mcF(0)] = Z(0) = 1
  \]
  となる。

  \ref{enumi: 3.7-3}。
  はじめに期待値についての等式を示す。
  \(\tau_m < \infty\)であれば、
  十分大きな\(t\)に対して\(t > \tau_m\)となるので、
  十分大きな\(t\)に対して\(X(t\wedge\tau_m) = m\)である。
  \(\tau_m = \infty\)であればつねに\(X(t) < m\)であり、
  従って
  \[
  0 \leq Z(t\wedge \tau_m) < \exp \left(
  \sigma m - \left( \sigma\mu + \frac{1}{2}\sigma^2\right) t\right)
  \to 0 \ , \ (t\to \infty)
  \]
  である
  (\(\sigma > 0, \mu \geq 0\)であることから
  \(- \left( \sigma\mu + \frac{1}{2}\sigma^2\right) t \to -\infty\)
  となることに注意)。
  よって
  \[
  \exp\left(
  \sigma m - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right) \I_{\tau_m < \infty}
  = \lim_{t\to \infty} Z(t\wedge \tau_m)
  \]
  である。
  従って示すべきことは
  \(\E\left[ \lim_{t\to \infty} Z(t\wedge \tau_m)\right] = 1\)である。
  ここで、\(Z(t\wedge \tau_m)\)は上から可積分関数 (定数関数)
  \(e^{\sigma\mu}\)で抑えることができるので、
  とくに優収束定理から期待値と極限は交換でき、
  \[
  \E\left[ \lim_{t\to \infty} Z(t\wedge \tau_m)\right]
  = \lim_{t\to \infty} \E\left[ Z(t\wedge \tau_m)\right] = \lim 1 = 1
  \]
  となる。

  次に\(\P(\tau_m<\infty) = 1\)を示す。
  今示した期待値に関する等式から、
  \[
  \E \left[ \exp \left( - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right) \I_{\tau_m < \infty}\right] = e^{-\sigma m}
  \]
  となることがわかる。
  これはすべての\(\sigma > 0\)で成り立つ。
  また左辺の期待値の中身はどんな\(\sigma > 0\)に対しても\(\I_{\tau_m < \infty}\)
  という可積分関数で上から抑えられていることに注意すれば、
  両辺で\(\sigma \to 0\)の極限を取れば優級数定理を用いて
  \[
  \E \left[ \I_{\tau_m < \infty}\right] = 1
  \]
  を得る。
  この等式の左辺は\(\P(\tau_m < \infty)\)に他ならない。

  最後に\(\E e^{-\alpha\tau_m} = e^{m\mu - m\sqrt{2\alpha+\mu^2}}\)を示す。
  \(\P(\tau_m<\infty)=1\)であるから、すでに示した期待値に関する等式において
  定義関数\(\I_{\tau_m<\infty}\)は\(1\)であるとしてよく、
  従って
  \[
  \E \left[ \exp \left(
  - \left( \sigma\mu + \frac{1}{2}\sigma^2
  \right)\tau_m\right) \right] = e^{-\sigma m}
  \]
  となる。
  任意の\(\alpha > 0\)に対して
  \(\alpha = \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\)
  となる\(\sigma > 0\)は一意的に存在する。
  二次方程式をとけば、その\(\sigma\)は (\(\sigma > 0\)であることから)
  \[
  \sigma = - \mu + \sqrt{2\alpha + \mu^2}
  \]
  と求めることができる。
  代入して、各\(\alpha > 0\)に対して
  \[
  \E e^{-\alpha\tau_m} = e^{-\sigma m} = e^{m\mu - m\sqrt{2\alpha + \mu^2}}
  \]
  となることがわかる。
  以上で全て示された。

  \ref{enumi: 3.7-4}。
  \(\E e^{-\alpha\tau_m} = e^{m\mu-m\sqrt{2\alpha+\mu^2}}\)
  を\(\alpha\)で微分すると、
  左辺は\(\E\left[ -\tau_me^{-\alpha\tau_m}\right]\)となる。
  右辺は、\(\beta = \sqrt{2\alpha+\mu^2}\)とおけば、
  \(\frac{d\beta}{d\alpha} = 2\frac{1}{2\beta}\)であるから、
  \[
  \frac{de^{m\mu-m\sqrt{2\alpha+\mu^2}}}{d\alpha}
  = e^{m\mu}\frac{de^{-m\beta}}{d\beta}\frac{d\beta}{d\alpha}
  = -me^{m\mu-m\beta}\cdot 2\frac{1}{2\beta}
  = -\frac{me^{m\mu-m\beta}}{\beta}
  \]
  となる。
  よって
  \[
  \E\left[ \tau_me^{-\alpha\tau_m}\right]
  = \frac{me^{m\mu-m\beta}}{\beta}
  \]
  を得る。
  ここで\(\alpha\to 0\)とすると、\(\beta \to \mu > 0\)であるから、
  \(\E[\tau_m] = \frac{m}{\mu} < \infty\)を得る。

  \ref{enumi: 3.7-5}。
  \(\sigma > -2\mu\) (これは正) であるから
  \(\sigma\mu + \frac{1}{2}\sigma^2
  = \frac{\sigma}{2}( 2\mu + \sigma) > 0\)であり、
  従って\ref{enumi: 3.7-3}と同様にして
  \[
  \exp\left(
  \sigma m - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right) \I_{\tau_m < \infty}
  = \lim_{t\to \infty} Z(t\wedge \tau_m)
  \]
  となることがわかる。
  この場合でも\(0 < Z(t\wedge \tau_m) < e^{\sigma m}\)であるから、
  優収束定理から
  \[
  \E \left[ \lim_{t\to \infty} Z(t\wedge \tau_m) \right]
  = \lim_{t\to \infty} \E [Z(t\wedge \tau_m)] = 1
  \]
  となる。
  以上で所望の期待値の等式が示された。
  また、この期待値の等式から
  \[
  \E \left[ \exp\left( - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right) \I_{\tau_m < \infty} \right] = e^{-\sigma m}
  \]
  がすべての\(\sigma > -2\mu\)で成立する。
  ここで\(\sigma \to -2\mu\)とすれば、同じく優収束定理より、
  \[
  \E \left[ \I_{\tau_m < \infty} \right] = e^{2m\mu}
  \]
  を得る。
  左辺は\(=\P(\tau_m < \infty)\)である。
  \(\mu < 0\)なので\(\mu = -|\mu|\)である。
  以上より\(\P(\tau_m < \infty) = e^{2m\mu}\)となる。
  最後に、\(\tau_m = \infty\)であるときも
  \(\exp\left( - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right) = 0\)となっていることに注意すれば、
  \[
  \E \left[ \exp\left( - \left( \sigma\mu + \frac{1}{2}\sigma^2\right)\tau_m
  \right)\right] = e^{-\sigma m}
  \]
  であることがわかるので、
  ここで\(\alpha = \sigma\mu + \frac{1}{2}\sigma^2 > 0\)とおけばやはり
  \(\sigma = -\mu + \sqrt{2\alpha + \mu^2}\)となって
  (\(\sigma > -2\mu\)となる符号は\(+\)側)、
  \[
  \E e^{-\alpha \tau_m} = e^{m\mu - m\sqrt{2\alpha + \mu^2}}
  \]
  がわかる。
\end{proof}




\begin{prob}\label{prob: 3.8}
  \(\sigma > 0, \tau \geq 0\)を定数、
  \(n\)を正の整数とする。
  単位時間あたり\(n\)回コイン投げを行うモデルを考える。
  \begin{align*}
    \tilde{p}_n &\dfn
    \frac{\frac{r}{n} + 1 - e^{-\sigma/\sqrt{n}}}
    {e^{\sigma/\sqrt{n}}-e^{-\sigma/\sqrt{n}}} \\
    \tilde{q}_n &\dfn
    \frac{e^{-\sigma/\sqrt{n}} - \frac{r}{n} - 1}
    {e^{\sigma/\sqrt{n}}-e^{-\sigma/\sqrt{n}}} \\
  \end{align*}
  とおく。
  \(t\)を正の有理数とする。
  \(nt\)が整数となる各\(n\)に対して
  確率変数\(X_{1,n}, \cdots ,X_{nt,n}\)を互いに独立で同一の分布に従い
  確率
  \[
  \tilde{\P}(X_{k,n} = 1) = \tilde{p}_n \ , \
  \tilde{\P}(X_{k,n} = -1) = \tilde{q}_n \ , \
  (k=1,\cdots ,nt)
  \]
  を持つものとし、
  \[M_{nt,n} \dfn \sum_{k=1}^{nt} X_{k,n}\]
  と定める。
  時刻\(t\)での株価 (確率変数) を
  \[
  S_n(t) \dfn S(0)\exp\left( \frac{\sigma}{\sqrt{n}}M_{nt,n} \right)
  \]
  と定める。
  \begin{enumerate}
    \item \label{enumi: 3.8-1}
    \(\frac{1}{\sqrt{n}}M_{nt,n}\)の
    積率母関数\(\varphi_n(u)\)は次であることを示せ：
    \[
    \varphi_n(u) =
    \left[
    e^{\frac{u}{\sqrt{n}}}
    \left(
    \frac{\frac{r}{n} + 1 - e^{-\sigma/\sqrt{n}}}
    {e^{\sigma/\sqrt{n}} - e^{-\sigma/\sqrt{n}}}
    \right)
    - e^{-\frac{u}{\sqrt{n}}}
    \left(
    \frac{\frac{r}{n} + 1 - e^{-\sigma/\sqrt{n}}}
    {e^{\sigma/\sqrt{n}} - e^{-\sigma/\sqrt{n}}}
    \right)
    \right] ^{nt}.
    \]
    \item \label{enumi: 3.8-2}
    \(x = 1/\sqrt{n}\)とおく。
    \(\log \varphi_{1/x^2}(u)\)を計算せよ。
    次を示せ：
    \[
    \log\varphi_{1/x^2}(u) =
    \frac{t}{x^2}\log \left[
    \frac{(rx^2+1)\sinh ux + \sinh(\sigma-u) x}
    {\sinh \sigma x}
    \right].
    \]
    また、これを次のように書き換えよ：
    \[
    \log\varphi_{1/x^2}(u) =
    \frac{t}{x^2}\log \left[ \cosh ux +
    \frac{(rx^2+1 - \cosh \sigma x)\sinh ux}
    {\sinh \sigma x}
    \right].
    \]
    \item \label{enumi: 3.8-3}
    次を示せ：
    \[
    \cosh ux + \frac{(rx^2+1 - \cosh\sigma x)\sinh ux}{\sinh\sigma x}
    = 1 + \frac{1}{2}u^2x^2 + \frac{rux^2}{\sigma} - \frac{1}{2}ux^2\sigma
    + 0(x^4).
    \]
    \item \label{enumi: 3.8-4}
    \(\lim_{x\to +0}\log_{1/x^2}(u)\)を計算せよ。
    \(\frac{\sigma}{\sqrt{n}}M_{nt,n}\)の極限分布が
    平均\((r-\frac{1}{2}\sigma^2)t\)で
    分散\(\sigma^2t\)の正規分布となることを説明せよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 3.8-1}。
  各\(X_{k,n}\)は互いに独立であるから、
  \[
  \varphi_n(u) = \E\left[ e^{u\cdot \frac{1}{\sqrt{n}}M_{nt,n}}\right]
  = \E\left[ e^{\frac{u}{\sqrt{n}}\sum_{k=1}^{nt}X_{k,n}}\right]
  = \prod_{k=1}^{nt}\E\left[ e^{\frac{u}{\sqrt{n}}X_{k,n}}\right]
  \]
  となる。
  ここで\(X_{k,n}\)は\(1\)か\(-1\)であるから、
  \[
  \E\left[ e^{\frac{u}{\sqrt{n}}X_{k,n}}\right]
  = e^{\frac{u}{\sqrt{n}}}\P(X_{k,n}=1)
  + e^{-\frac{u}{\sqrt{n}}}\P(X_{k,n}=-1)
  = e^{\frac{u}{\sqrt{n}}}\tilde{p}_n
  + e^{-\frac{u}{\sqrt{n}}}\tilde{q}_n
  \]
  となる。
  以上より、
  \[
  \varphi_n(u)
  = \prod_{k=1}^{nt}\E\left[ e^{\frac{u}{\sqrt{n}}X_{k,n}}\right]
  = \left(e^{\frac{u}{\sqrt{n}}}\tilde{p}_n
  + e^{-\frac{u}{\sqrt{n}}}\tilde{q}_n \right)^{nt}
  \]
  である。
  \(\tilde{p}_n, \tilde{q}_n\)の定義より、
  これは所望の結果であることがわかる。

  \ref{enumi: 3.8-2}。
  まず\(x=1/\sqrt{n}\)であるから、
  \begin{align*}
    &\tilde{p}_{1/x^2}
    = \frac{rx^2+1-e^{-\sigma x}}{e^{\sigma x}-e^{-\sigma x}}
    = \frac{rx^2+1-e^{-\sigma x}}{2\sinh \sigma x} \\
    &\tilde{q}_{1/x^2}
    = \frac{e^{\sigma x}-rx^2-1}{e^{\sigma x}-e^{-\sigma x}}
    = \frac{e^{\sigma x}-rx^2-1}{2\sinh \sigma x}
  \end{align*}
  である。
  従って、
  \begin{align*}
    \log \varphi_{1/x^2}(u)
    &= \log \left(e^{ux}\tilde{p}_{1/x^2}
    + e^{-ux}\tilde{q}_{1/x^2} \right)^{t/x^2} \\
    &= \frac{t}{x^2}\log \left(
    \frac{
    e^{ux}(rx^2+1-e^{-\sigma x}) + e^{-ux}(e^{\sigma x}-rx^2-1)
    }{2\sinh \sigma x}
    \right) \\
    &= \frac{t}{x^2}\log \left(
    \frac{
    (rx^2+1)(e^{ux}-e^{-ux})
    - e^{ux-\sigma x} + e^{-ux + \sigma x}
    }{2\sinh \sigma x}
    \right) \\
    &= \frac{t}{x^2}\log \left(
    \frac{
    2(rx^2+1)\sinh ux + 2\sinh (\sigma -u)x
    }{2\sinh \sigma x}
    \right) \\
    &= \frac{t}{x^2}\log \left(
    \frac{(rx^2+1)\sinh ux + \sinh (\sigma -u)x}{\sinh \sigma x}\right)
  \end{align*}
  となる。これは所望の結果である。
  また、\(\log\)の中身は
  \begin{align*}
    \frac{(rx^2+1)\sinh ux + \sinh (\sigma -u)x}{\sinh \sigma x}
    &= \frac{
    (rx^2+1)\sinh ux + \sinh \sigma x \cosh ux - \cosh \sigma x \sinh ux
    }{\sinh \sigma x} \\
    &= \cosh ux + \frac{
    (rx^2+1)\sinh ux - \cosh \sigma x \sinh ux
    }{\sinh \sigma x} \\
    &= \cosh ux + \frac{
    ((rx^2+1)- \cosh \sigma x )\sinh ux
    }{\sinh \sigma x}
  \end{align*}
  と変形できる。

  \ref{enumi: 3.8-3}。
  テイラー展開
  \[
  \cosh z = 1 + \frac{1}{2}z^2 + O(z^4) \ , \
  \sinh z = z + O(z^3)
  \]
  を用いれば
  \begin{align*}
    &\cosh ux + \frac{
    ((rx^2+1)- \cosh \sigma x )\sinh ux
    }{\sinh \sigma x} \\
    &= 1 + \frac{1}{2}u^2x^2 + O(x^4)
    + \frac{
    \left((rx^2+1) - 1 - \frac{1}{2}\sigma^2x^2 + O(x^4)\right)(ux + O(x^3))
    }{\sigma x ( 1 + O(x^4))} \\
    &= 1 + \frac{1}{2}u^2x^2
    + x^2\left( r - \frac{1}{2}\sigma^2 + O(x^2)\right)
    \left( \frac{u}{\sigma} + O(x^2)\right) \\
    &= 1 + \frac{1}{2}u^2x^2
    + \frac{ru}{\sigma}x^2 - \frac{1}{2}u\sigma x^2 + O(x^4)
  \end{align*}
  となる。
  これは所望の等式である。

  \ref{enumi: 3.8-4}。
  テイラー展開\(\log(1+x) = x + O(x^3)\)を用いて計算すれば、
  \begin{align*}
    \varphi_{1/x^2}(u)
    &= \frac{t}{x^2}\log \left(
    \cosh ux + \frac{
    ((rx^2+1)- \cosh \sigma x )\sinh ux
    }{\sinh \sigma x}\right) \\
    &= \frac{t}{x^2}\log \left(
    1 + \frac{1}{2}u^2x^2
    + \frac{ru}{\sigma}x^2 - \frac{1}{2}u\sigma x^2 + O(x^4)
    \right) \\
    &= \frac{t}{x^2}\left(
    \frac{1}{2}u^2x^2
    + u\left( \frac{r}{\sigma}x^2 - \frac{1}{2}\sigma x^2\right) + O(x^6)
    \right) \\
    &= t\left(
    \frac{1}{2}u^2
    + u\left( \frac{r}{\sigma} - \frac{1}{2}\sigma \right) + O(x^4)
    \right) \\
    &\to \frac{1}{2}u^2t + ut \left(
    \frac{r}{\sigma} - \frac{1}{2}\sigma
    \right)
    \ , \ (x\to +0)
  \end{align*}
  となる。
  よって\(\frac{1}{\sqrt{n}}M_{nt,n}\)の極限分布の積率母関数は
  \[
  \exp \left( \frac{1}{2}u^2t + ut \left(
  \frac{r}{\sigma} - \frac{1}{2}\sigma
  \right)\right)
  \]
  であり、
  このことは\(\frac{1}{\sqrt{n}}M_{nt,n}\)の極限が
  平均\( \left(\frac{r}{\sigma} - \frac{1}{2}\sigma\right) t\)で
  分散\(t\)の正規確率変数であることを意味する。
  これに\(\sigma\)をかければ、
  \(\frac{\sigma}{\sqrt{n}}M_{nt,n}\)の極限が
  平均\(\left( r - \frac{1}{2}\sigma^2\right) t\)で
  分散\(\sigma^2t\)の正規確率変数であることがわかる。
\end{proof}


\begin{prob}\label{prob: 3.9}
  \(m > 0\)を定数とし、
  \[
  f(t) \dfn \frac{m}{t\sqrt{2\pi t}}\exp \left( -\frac{m^2}{2t} \right)
  \]
  とする。
  \[
  g(\alpha) \dfn \int_0^\infty e^{-\alpha t}f(t)dt, \ \alpha > 0
  \]
  を\(f(t)\)のラプラス変換とする。
  \begin{enumerate}
    \item \label{enumi: 3.9-1}
    \(a,b > 0\)に対し
    \[
    I(a,b) \dfn \int_0^\infty \exp \left(
    -a^2x^2-\frac{b^2}{x^2}
    \right) dx
    \]
    とおく。
    次を示せ：
    \[
    I(a,b) = \frac{b}{a} \int_0^\infty \frac{1}{y^2}\exp \left(
    -a^2y^2-\frac{b^2}{y^2}
    \right) dy.
    \]
    \item \label{enumi: 3.9-2}
    次を示せ：
    \[
    I(a,b) = \frac{1}{2a} \int_0^\infty \left(
    -a+\frac{b}{x^2}\right) \exp \left(
    -a^2x^2-\frac{b^2}{x^2}
    \right) dx.
    \]
    さらに次を示せ：
    \[
    I(a,b) = \frac{\sqrt{\pi}}{2a}e^{-2ab}.
    \]
    \item \label{enumi: 3.9-3}
    次を示せ：
    \[
    g(\alpha) = \frac{2m}{\sqrt{2\pi}}I(m/\sqrt{2},\sqrt{\alpha})
    = e^{-m\sqrt{2\alpha}}.
    \]
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 3.9-1}。
  変数変換\(y=b/ax\)を行うと、\(ax = b/y , b/x = ay, dx=-bdy/ay^2\)であるから、
  \begin{align*}
    I(a,b) &= \int_0^\infty \exp \left(
    -a^2x^2-\frac{b^2}{x^2}
    \right) dx \\
    &= - \int_\infty^0 \frac{b}{ay^2}\exp \left(
    -\frac{b^2}{y^2}-a^2y^2
    \right) dy \\
    &= \frac{b}{a}\int_0^\infty \frac{1}{y^2}\exp \left(
    -a^2y^2-\frac{b^2}{y^2}
    \right) dy
  \end{align*}
  となる。

  \ref{enumi: 3.9-2}。
  計算すれば
  \begin{align*}
    I(a,b) &= \frac{1}{2}I(a,b) + \frac{1}{2}I(a,b) \\
    &= \frac{1}{2} \int_0^\infty
    \exp \left(-a^2x^2-\frac{b^2}{x^2}\right) dx \\
    &\ \ \ + \frac{1}{2}\cdot\frac{b}{a}\int_0^\infty \frac{1}{x^2}
    \exp \left(-a^2x^2-\frac{b^2}{x^2}\right) dx \\
    &= \frac{1}{2} \int_0^\infty \left( 1+ \frac{b}{ax^2}\right)
    \exp \left( -a^2x^2-\frac{b^2}{x^2}\right) dx \\
    &= \frac{1}{2a} \int_0^\infty \left( a + \frac{b}{x^2}\right)
    \exp \left( -a^2x^2-\frac{b^2}{x^2}\right) dx
  \end{align*}
  となる。
  ここで\(t=ax-b/x\)と変数変換すれば、
  \(-a^2x^2-\frac{b^2}{x^2} = -t^2 - 2ab,
  dt = (a+b/x^2)dx\)であるから、
  \begin{align*}
    &= \frac{1}{2a} \int_{-\infty}^\infty
    \exp \left( -t^2 - 2ab\right) dt \\
    &= \frac{e^{-2ab}}{2a} \int_{-\infty}^\infty e^{-t^2}dt
    = \frac{\sqrt{\pi}}{2a}e^{-2ab}
  \end{align*}
  となる。

  \ref{enumi: 3.9-3}。
  \(x=\sqrt{t}\)の変数変換を行うと、
  \begin{align*}
    g(\alpha)
    &= \int_0^\infty e^{-\alpha t}f(t) dt \\
    &= 2\int_0^\infty e^{-\alpha x^2}f(x^2) xdx \\
    &= 2\int_0^\infty e^{-\alpha x^2}\cdot
    \frac{m}{x^2\sqrt{2\pi}}e^{-m^2/2x^2} dx \\
    &= \frac{2m}{\sqrt{2\pi}}\int_0^\infty \frac{1}{x^2}
    \exp \left( -\alpha x^2-\frac{m^2}{2x^2}\right) dx \\
    &= \frac{2m}{\sqrt{2\pi}}\int_{\infty}^0 t^2
    \exp \left( -\alpha \frac{1}{t^2}-m^2t^2/2\right) \frac{-dt}{t^2} \\
    &= \frac{2m}{\sqrt{2\pi}}\int_0^{\infty}
    \exp \left( -m^2t^2/2-\alpha \frac{1}{t^2}\right) dt \\
    &= \frac{2m}{\sqrt{2\pi}} I(m/\sqrt{2},\sqrt{\alpha}) \\
    &= \frac{2m}{\sqrt{2\pi}} \cdot
    \frac{\sqrt{\pi}}{2m/\sqrt{2}}e^{-2m\sqrt{\alpha}/\sqrt{2}} \\
    &= e^{-m\sqrt{2\alpha}}
  \end{align*}
  となる。
\end{proof}











\newpage

\section{確率解析}\label{section: 4}


\begin{prob}\label{prob: 4.1}
  \(M(t), 0\leq t\leq T\)をあるfiltration \(\mcF(t), 0\leq t\leq T\)
  に関するマルチンゲールな確率過程、
  \(\Delta(t)\)を\(\mcF(t)\)と適合する単過程とする。
  各\(t\in [t_k,t_{k+1})\)に対して
  \[
  I(t) \dfn
  \sum_{j=0}^{k-1}\Delta(t_j)\left( M(t_{j+1})-M(t_j)\right)
  + \Delta(t_k)\left( M(t)-M(t_k)\right)
  \]
  と定義する (確率積分)。
  このとき\(I(t)\)はマルチンゲールであることを示せ。
\end{prob}

\begin{proof}
  \(0\leq s < t\)を任意にとる。
  \(t_l \leq s < t_{l+1}\)となる\(l\)を取れば、
  \begin{align*}
    \E\left[I(t)\middle| \mcF(s)\right]
    &= \sum_{j=0}^{k-1} \E\left[
    \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(s) \right]
    + \E\left[ \Delta(t_k)\left( M(t)-M(t_k)\right) \middle| \mcF(s)\right] \\
    &= \sum_{j=0}^{l-1} \E\left[
    \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(s) \right]
    + \E\left[
    \Delta(t_l)\left( M(t_{l+1})-M(t_l)\right) \middle| \mcF(s)\right] \\
    &\ \ + \sum_{j=l}^{k-1} \E\left[
    \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(s) \right]
    + \E\left[
    \Delta(t_k)\left( M(t)-M(t_k)\right) \middle| \mcF(s)\right]
  \end{align*}
  となる。
  各項を計算する。

  第一項は、\(t_j \leq s\)であることから
  各\(\Delta(t_j)\left( M(t_{j+1})-M(t_j)\right)\)は\(\mcF(s)\)-可測となり、
  既知量の括り出しによって
  \[
  \sum_{j=0}^{l-1} \E\left[
  \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(s) \right]
  = \sum_{j=0}^{l-1} \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right)
  \]
  となる。

  第二項を計算する。
  線形性より
  \[
  \E\left[
  \Delta(t_l)\left( M(t_{l+1})-M(t_l)\right) \middle| \mcF(s)\right]
  = \E\left[ \Delta(t_l)M(t_{l+1}) \middle| \mcF(s)\right]
  - \E\left[ \Delta(t_l)M(t_l) \middle| \mcF(s)\right]
  \]
  となるが、\(t_l \leq s\)であることから
  \(\Delta(t_l), M(t_l)\)はどちらも\(\mcF(s)\)-可測で、
  従って既知量の括り出しによって
  \[
  = \Delta(t_l)\E\left[M(t_{l+1}) \middle| \mcF(s)\right]
  - \Delta(t_l)M(t_l)
  \]
  となる。
  また\(M\)がマルチンゲールであることから
  \[
  = \Delta(t_l)M(s) - \Delta(t_l)M(t_l)
  = \Delta(t_l)(M(s) - M(t_l))
  \]
  となる。

  第三項を計算する。
  \(l < j\)であるとする。
  \(s \leq t_j\)なので
  \(\mcF(s) \subset \mcF(t_j)\)であり、
  従って反復条件つき確率の計算から
  \[
  \E\left[
  \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(s) \right]
  = \E\left[ \E\left[
  \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right) \middle| \mcF(t_j)\right]
  \middle| \mcF(s) \right]
  \]
  となる。
  ここで\(\Delta(t_j),M(t_j)\)は\(\mcF(t_j)\)-可測であるから、
  線形性と既知量の括り出しによって
  \[
  = \E\left[ \Delta(t_j)\E[M(t_{j+1})\middle| \mcF(t_j)] - \Delta(t_j)M(t_j)
  \middle| \mcF(s) \right]
  \]
  となる。
  \(M\)がマルチンゲールであることから
  \(\E\left[M(t_{j+1})\middle| \mcF(t_j)\right]=M(t_j)\)なので、
  以上より第三項は\(0\)となる。
  全く同様の計算により第四項も\(0\)となる。

  以上を足し合わせると
  \[
  \E[I(t)|\mcF(s)]
  = \sum_{j=1}^l \Delta(t_j)\left( M(t_{j+1})-M(t_j)\right)
  + \Delta(t_l)\left( M(s) - M(t_l)\right)
  = I(s)
  \]
  となり、\(I\)がマルチンゲールであることがわかった。
\end{proof}


\begin{prob}\label{prob: 4.2}
  \(W(t), 0\leq t \leq T\)をブラウン運動、
  \(\mcF(t)\)を\(W(t)\)に関するfiltration、
  \(\Delta(t)\)を\textbf{確定的な単過程}、
  つまりある分割
  \(0 = t_0 \leq t_1 \leq \cdots \leq t_n = T\)
  があって、各\(j=1,\cdots, n\)について
  \(\Delta\)は\(\Omega\times [t_{j-1},t_j)\)上の定数関数である
  とする。
  各\(t\in [t_k,t_{k+1}]\)に対して
  \[
  I(t) \dfn \sum_{j=0}^{k-1}\Delta(t_j)\left( W(t_{j+1}) - W(t_j) \right)
  + \Delta(t_k) \left( W(t) - W(t_k) \right)
  \]
  と定義する。
  \begin{enumerate}
    \item \label{enumi: 4.2-1}
    \(0\leq s < t \leq T\)に対して
    増分\(I(t)-I(s)\)は\(\mcF(s)\)と独立であることを示せ。
    \item \label{enumi: 4.2-2}
    \(0\leq s < t \leq T\)に対して
    増分\(I(t)-I(s)\)は平均\(0\)で分散\(\int_s^t\Delta^2(u)du\)の
    正規分布に従う確率変数であることを示せ。
    \item \label{enumi: 4.2-3}
    \ref{enumi: 4.2-1}と\ref{enumi: 4.2-2}を用いて
    \(I(t)\)がマルチンゲールであることを示せ。
    \item \label{enumi: 4.2-4}
    \(I^2(t) - \int_0^t\Delta^2(u)du\)がマルチンゲールであることを示せ。
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 4.2-1}。
  \(t_l\leq s < t_{l+1}\)となる\(l\)をとる。
  \begin{align*}
    I(t)-I(s)
    &= \sum_{j=l+1}^{k-1}\Delta(t_j)\left( W(t_{j+1}) - W(t_j) \right)
    + \Delta(t_k)\left( W(t) - W(t_k)\right) \\
    & \ \ \ \ \ \ \ \ \ + \Delta(t_l)\left( W(t_{l+1}) - W(t_l) \right)
    - \Delta(t_l)\left( W(s) - W(t_l)\right) \\
    &= \sum_{j=l+1}^{k-1}\Delta(t_j)\left( W(t_{j+1}) - W(t_j) \right)
    + \Delta(t_k)\left( W(t) - W(t_k)\right)
    + \Delta(t_l)\left( W(t_{l+1}) - W(s) \right)
  \end{align*}
  である。
  ここで\(W\)はブラウン運動であることと、
  \(\Delta(t)\)が各\(0\leq t\leq T\)について定数であることから、
  各\(j=l+1,\cdots,k-1\)に対して
  \(\Delta(t_j)\left( W(t_{j+1}) - W(t_j) \right)\)は\(\mcF(t_j)\)と独立であり、
  従ってとくに\(\mcF(s)\)とも独立である。
  \(\Delta(t_k)\left( W(t) - W(t_k)\right)\)も\(\mcF(t_k)\)と独立であり、
  特に\(\mcF(s)\)とも独立である。
  \(\Delta(t_l)\left( W(t_{l+1}) - W(s) \right)\)も\(\mcF(s)\)と独立である。
  以上ですべての項が\(\mcF(s)\)と独立であることが示された。

  \ref{enumi: 4.2-2}。
  \(\Delta(t)\)は区間\([t_l,t_{l+1})\)で一定の値をとる定数であるから、
  \(s\in [t_l,t_{l+1})\)であることから、\(\Delta(t_l) = \Delta(s)\)である。
  従って分割
  \( 0= u_0 < u_1=s < u_2=t_{l+1} \leq \cdots
  \leq u_{n+1-l} = t_n \leq u_{n+2-l}=t \leq T\)
  に対して、\(m=n+2-l\)とおけば、
  \[
  I(t) - I(s) = \sum_{j=1}^{m-1}\Delta(u_j)\left( W(u_{j+1})-W(u_j) \right)
  \]
  となる。
  \(W\)はブラウン運動であるから、
  各\(W(u_{j-1}) - W(u_j)\)たちは互いに独立な正規確率変数であり、
  その平均は\(0\)で分散は\(u_{j-1}-u_j\)である。
  また\(\Delta(t)\)は定数であるから、従って各
  \(\Delta(u_j)\left( W(u_{j+1}) - W(u_j)\right) , j=1,\cdots, m-1\)
  は互いに独立で、平均はどれも\(0\)、
  分散は\(\Delta(u_j)^2(u_{j+1}-u_j) , j=2,\cdots, m-1\)である。
  従ってこれらの和である\(I(t)-I(s)\)は平均\(0\)で分散が
  \[
  \sum_{j=1}^{m-1}\Delta(u_j)^2(u_{j+1}-u_j)
  = \int_s^t\Delta^2(u)du
  \]
  の正規確率変数である。

  \ref{enumi: 4.2-3}。
  \(0\leq s < t\leq T\)をとる。
  \(u_j\)は\ref{enumi: 4.2-2}の解答のとおりとする。
  各\(j > 1\)に対して\(W(u_{j+1})-W(u_j)\)は\(W(u_j)-W(0) = W(u_j)\)、
  つまり\(\mcF(u_j)\)と独立であり、
  \(s < u_j\)であるから、
  従ってとくに\(\mcF(s)\)とも独立である。
  以上より\(I(t)-I(s)\)は\(\mcF(s)\)と独立であり、
  従って
  \begin{align*}
    \E\left[ I(t) \middle| \mcF(s)\right]
    &= \E \left[ I(t)-I(s) \middle| \mcF(s)\right]
    + \E \left[ I(s) \middle| \mcF(s)\right]  \\
    &= \E \left[ I(t)-I(s) \right] + I(s)
  \end{align*}
  となる。
  ここで\ref{enumi: 4.2-2}より\(\E \left[ I(t)-I(s) \right]=0\)であるから、
  \(\E\left[ I(t) \middle| \mcF(s)\right]=I(s)\)がわかる。
  つまり\(I\)はマルチンゲールである。

  \ref{enumi: 4.2-4}。
  \(I(t)-I(s)\)は平均\(0\)で分散\(\int_s^t\Delta^2(u)du\)の確率変数であるから、
  \(\E[(I(t)-I(s))^2] = \int_s^t\Delta^2(u)du\)である。
  よって既知量の括り出しと線形性から
  \begin{align*}
    \E \left[ I^2(t) - \int_0^t\Delta^2(u)du \middle| \mcF(s)\right]
    &= \E \left[ (I(t)-I(s))^2 + 2I(s)I(t) - I^2(s) - \int_0^t\Delta^2(u)du \middle| \mcF(s)\right] \\
    &= \E \left[ (I(t)-I(s))^2 \middle| \mcF(s)\right]
    + 2I(s) \E \left[I(t)\middle| \mcF(s)\right] \\
    &\ \ \ \ \ \ \ \ \ \ \ - I^2(s) - \int_0^t\Delta^2(u)du
  \end{align*}
  となるが、\ref{enumi: 4.2-1}より\(I(t)-I(s)\)は\(\mcF(s)\)と独立であり、
  また\ref{enumi: 4.2-3}より\(I\)はマルチンゲールであるから、
  \begin{align*}
    &= \E \left[ (I(t)-I(s))^2\right]
    + 2I(s)^2 - I^2(s) - \int_0^t\Delta^2(u)du \\
    &= \int_s^t\Delta^2(u)du + I(s)^2 - \int_0^t\Delta^2(u)du \\
    &= I^2(s) - \int_0^s\Delta^2(u)du
  \end{align*}
  となる。
  以上で\(I^2(t)-\int_0^t\Delta^2(u)du\)はマルチンゲールである。
\end{proof}




\begin{prob}\label{prob: 4.3}
  \ref{prob: 4.2}における\(\Delta(t)\)が確定的でない (普通の) 単関数であるとする。
  \(t_0=0,t_1=s,t_2=t\)とする (\(t\)は定数！)。
  \(\Delta(0)\)は定数である。
  \(\Delta(s) = W(s)\)とする。
  次のうち正しいのはどれか？理由も述べよ：
  \begin{enumerate}
    \item \label{enumi: 4.3-1}
    \(I(t)-I(s)\)は\(\mcF(s)\)と独立である。
    \item \label{enumi: 4.3-2}
    \(I(t)-I(s)\)は正規分布に従う。
    \item \label{enumi: 4.3-3}
    \(\E\left[I(t)\middle| \mcF(s)\right] = I(s)\)である。
    \item \label{enumi: 4.3-4}
    \(\E\left[ I^2(t) - \int_0^t\Delta^2(u)du \middle| \mcF(s)\right]
    = I^2(s) - \int_0^s\Delta^2(u)du\)である。
  \end{enumerate}
\end{prob}

\begin{proof}
  まず\(I(t)-I(s)\)の\(n\)-次モーメント
  (\((I(t)-I(s))^n\)の期待値)
  を計算する。
  \(\Delta(0)\)は定数なのでこれを\(c\)と置く。
  定義に基づいて計算すると
  \begin{align*}
    &I(s) = \Delta(0) W(s) = cW(s) \\
    &I(t) - I(s) = W(s)\left( W(t)-W(s) \right) \\
    &I(t) = W(s)\left( W(t)-W(s) \right) + c W(s)
  \end{align*}
  となる。
  \(W\)はブラウン運動なので、
  \(W(s)\)と\(W(t)-W(s)\)は独立であり、
  それぞれ平均\(0\)で分散が\(s\)と\(t-s\)の正規確率変数である。
  よって、
  \begin{align*}
    \E[(I(t)-I(s))^n]
    &= \E[W(s)^n] \E[(W(t)-W(s))^n] \\
    &= \frac{1}{\sqrt{2\pi s}}\int_{-\infty}^\infty x^ne^{-x^2/2s}dx
    \frac{1}{\sqrt{2\pi(t-s)}}\int_{-\infty}^\infty y^ne^{-y^2/2(t-s)}dy \\
    &= \frac{1}{2\pi \sqrt{s(t-s)}}\iint_{\R^2}
    (xy)^ne^{-x^2/2s-y^2/2(t-s)}dxdy \\
    &= \frac{\sqrt{s^n(t-s)^n}}{2\pi}\iint_{\R^2}
    (xy)^ne^{-x^2/2-y^2/2}dxdy \\
    &= \frac{\sqrt{s^n(t-s)^n}}{2\pi}\int_0^\infty\int_0^{2\pi}
    r^{2n+1}\cos^n\theta \sin^n\theta e^{-r^2/2}d\theta dr \\
    &= \frac{\sqrt{s^n(t-s)^n}}{2\pi}
    \int_0^\infty r^{2n+1}e^{-r^2/2}dr
    \int_0^{2\pi}\cos^n\theta \sin^n\theta d\theta \\
    &= \frac{\sqrt{s^n(t-s)^n}}{2\pi}
    \int_0^\infty r_1^ne^{-r_1}dr_1
    \int_0^{2\pi}\sin^n(\theta) d\theta
  \end{align*}
  となる。
  ここで\(u\)に関する関数の等式
  \[
  \int_0^\infty e^{-ru}dr = \frac{1}{u}
  \]
  を\(n\)回微分して\(u=1\)を代入することで
  \[
  \int_0^\infty r^ne^{-r}dr = (-1)^n n!
  \]
  を得る。
  また\(n\)が奇数であれば\(\int_0^{2\pi}\sin^n\theta d\theta = 0\)であるが、
  偶数であれば
  \begin{align*}
    \int_0^{2\pi}\sin^n\theta d\theta
    &= [-\cos \theta \sin^{n-1}\theta]_0^{2\pi}
    - (n-1)\int_0^{2\pi}\cos^2\theta \sin^{n-2}\theta d\theta \\
    &= -(n-1) \int_0^{2\pi}\sin^n\theta d\theta
    + (n-1) \int_0^{2\pi}\sin^{n-2}\theta d\theta
  \end{align*}
  であるから、\(n\)について帰納的に、
  \[
  \int_0^{2\pi}\sin^n(\theta) d\theta
  = \frac{(n-1)(n-3)\cdots 1}{n(n-2)\cdots 2}
  \int_0^{2\pi}\sin^0\theta d\theta
  = 2\pi \frac{(n-1)(n-3)\cdots 1}{n(n-2)\cdots 2}
  \]
  となる。
  よって\(n\)が奇数のときは\(\E[(I(t)-I(s))^n] = 0\)で、
  偶数のときには
  \[
  \E[(I(t)-I(s))^n] = (n-1)^2(n-3)^2\cdots 1^2\cdot \sqrt{s^n(t-s)^n}
  \]
  となる。
  この計算結果を用いる。

  \ref{enumi: 4.3-1}は偽である。
  もし\(I(t)-I(s)\)と\(\mcF(s)\)が独立であれば、
  \(W(s)\)が\(\mcF(s)\)-可測であることから、
  \((I(t)-I(s))^2\)と\(W^2(s)\)も独立でなければならず、
  従って
  \[\E[W^2(s)(I(t)-I(s))^2] = \E[W^2(s)]\E[(I(t)-I(s))^2] = s^2(t-s)\]
  となるはずであるが、一方で\(W(s)\)と\(W(t)-W(s)\)は独立なので、
  \[
  \E[W^2(s)(I(t)-I(s))^2] = \E[W^4(s)(W(t)-W(s))^2]
  = \E[W^4(s)]\E[(W(t)-(s))^2] = 3s^2(t-s)
  \]
  となり、これは矛盾である。

  \ref{enumi: 4.3-2}は偽である。
  もし\(I(t)-I(s)\)が正規分布であるならば、
  \(\E[I(t)-I(s)] = 0\)であることから
  分散が\(\E[(I(t)-I(s))^2] = t-s\)となり、
  このことと\(I(t)-I(s)\)の正規性から
  \(4\)次モーメントが
  \(\E[(I(t)-I(s))^4] = 3(t-s)^2\)となるはずであるが、
  実際には\(\E[(I(t)-I(s))^4] = 9s^2(t-s)^2\)である。

  \ref{enumi: 4.3-3}は真である。
  \(\E\left[I(t)\middle| \mcF(s)\right]\)を計算すれば、
  \begin{align*}
    \E\left[I(t)\middle| \mcF(s)\right]
    &= \E\left[I(t)-I(s) \middle| \mcF(s)\right] + I(s) \\
    &= \E\left[ W(s)\left( W(t)-W(s) \right) \middle| \mcF(s)\right] + I(s) \\
    &= W(s)\E\left[ W(t)-W(s)\right] + I(s) \\
    &= I(s)
  \end{align*}
  となる。

  \ref{enumi: 4.3-4}は真である。
  \(\E\left[ I^2(t) - \int_0^t\Delta^2(u)du \middle| \mcF(s)\right]\)
  を計算すれば、
  \begin{align*}
    \E\left[ I^2(t) - \int_0^t\Delta^2(u)du \middle| \mcF(s)\right]
    &= \E[ I^2(s) + 2I(s)W(s)(W(t)-W(s)) + W^2(s)(W(t)-W(s))^2 \\
    & \ \ \ \ \ \ \ \ \ \
    - \Delta^2(0)s - W^2(s)(t-s) \mid \mcF(s)] \\
    &\overset{\bigstar}{=}
    I^2(s) + 2I(s)W(s)\E\left[W(t)-W(s)\middle| \mcF(s)\right] \\
    & \ \ \ \ \ \ \ \ \ \
    + W^2(s)\E\left[(W(t)-W(s))^2 \middle| \mcF(s)\right]
    - \Delta^2(0)s - W^2(s)(t-s) \\
    &\overset{\spadesuit}{=}
    I^2(s) + 2I(s)W(s)\E[W(t)-W(s)]
    + W^2(s)\E[(W(t)-W(s))^2] \\
    & \ \ \ \ \ \ \ \ \ \
    - \Delta^2(0)s - W^2(s)(t-s) \\
    &\overset{\clubsuit}{=}
    I^2(s) + W^2(s)(t-s)
    - \Delta^2(0)s - W^2(s)(t-s) \\
    &= I^2(s) - \Delta^2(0)s \\
    &= I^2(s) - \int_0^s\Delta^2(u)du
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所で既知量の括り出しを行い、
  \(\spadesuit\)の箇所で\(W(t)-W(s)\)が\(\mcF(s)\)と独立であることを用い、
  \(\clubsuit\)の箇所で\(W(t)-W(s)\)が
  平均\(0\)で分散\(t-s\)の正規確率変数であることを用いた。
\end{proof}






\begin{prob}\label{prob: 4.4}
  [ストラノヴィッチ積分]
  \(W(t), t\geq 0\)をブラウン運動、
  \(T > 0\)を定数、
  \(\Pi = (0 = t_0 < t_1 < \cdots < t_n = T)\)を\([0,T]\)の分割、
  \(t_j^* \dfn (t_j+t_{j+1})/2 , (j=0,\cdots, n-1)\)とする。
  \begin{enumerate}
    \item \label{enumi: 4.4-1}
    \[
    Q_{\Pi/2} \dfn \sum_{j=0}^{n-1}(W(t_j^*) - W(t_j))^2
    \]
    と定める。
    \(\|\Pi\| \to 0\)のもとで\(Q_{\Pi/2}\to T/2\)であることを示せ。
    \item \label{enumi: 4.4-2}
    \(W(t)\)に関する\(W(t)\)の\textbf{ストラノヴィッチ積分}を次で定義する：
    \[
    \int_0^TW(t)\circ dW(t)
    \dfn \lim_{\|\Pi\| \to 0}\sum_{j=0}^{n-1}W(t_j^*)
    \left( W(t_{j+1}) - W(t_j)\right).
    \]
    次を示せ：
    \[\int_0^TW(t)\circ dW(t) = \frac{1}{2}W^2(T).\]
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 4.4-1}。
  示すべきことは\(\E[Q_{\Pi/2}] = T/2\)と
  \[
  0 \leq \E[Q_{\Pi/2}^2 - \E[Q_{\Pi/2}]^2] = \Var(Q_{\Pi/2}) \to 0
  \ , \ (\|\Pi\| \to 0)
  \]
  の2つである。
  期待値の方は、
  \(W(t_j^*) - W(t_j)\)が平均\(0\)で分散\(t_j^*-t_j = (t_{j+1}-t_j)/2\)の
  正規確率変数であることから、線形性を用いて
  \begin{align*}
    \E[Q_{\Pi/2}]
    &= \E\left[ \sum_{j=0}^{n-1}(W(t_j^*) - W(t_j))^2 \right] \\
    &= \sum_{j=0}^{n-1}\E\left[ (W(t_j^*) - W(t_j))^2 \right] \\
    &= \frac{1}{2}\sum_{j=0}^{n-1}(t_{j+1}-t_j) \\
    &= \frac{1}{2}T
  \end{align*}
  となる。
  分散の方を計算する。
  \(W(t_j^*)-W(t_j)\)らは互いに独立であるから、
  \[
  \Var(Q_{\Pi/2})
  = \sum_{j=0}^{n-1}\Var\left(\left(W(t_j^*)-W(t_j)\right)^2 \right)
  \]
  である。
  各\(j\)に対する\(\Var\left(\left(W(t_j^*)-W(t_j)\right)^2 \right)\)
  を計算する。
  \[
  \Var\left(\left(W(t_j^*)-W(t_j)\right)^2 \right)
  = \E\left[ \left(W(t_j^*)-W(t_j)\right)^4 \right]
  -\E\left[ \left(W(t_j^*)-W(t_j)\right)^2 \right]^2
  \]
  であるが、\(W(t_j^*)-W(t_j)\)は
  平均\(0\)で分散\(t_j^*-t_j = (t_{j+1}-t_j)/2\)
  の正規確率変数であるから、
  \(\E\left[ \left(W(t_j^*)-W(t_j)\right)^2 \right] = (t_{j+1}-t_j)/2\)
  と
  \(\E\left[ \left(W(t_j^*)-W(t_j)\right)^4 \right] = 3(t_{j+1}-t_j)^2/4\)
  がわかる。
  以上より
  \[
  \Var(Q_{\Pi/2})
  = \frac{3}{4}\sum_{j=0}^{n-1} (t_{j+1}-t_j)^2
  - \frac{1}{4}\sum_{j=0}^{n-1} (t_{j+1}-t_j)^2
  = \frac{1}{2}\sum_{j=0}^{n-1} (t_{j+1}-t_j)^2
  \]
  がわかる。
  ここで\(\|\Pi\|\)が最大の区間の長さであることから、
  \[
  \Var(Q_{\Pi/2})
  \leq \frac{\Pi}{2}\sum_{j=0}^{n-1} (t_{j+1}-t_j) = \frac{\Pi T}{2}
  \to 0
  \]
  がわかる。
  以上で示された。

  \ref{enumi: 4.4-2}。
  \[
  R_{\Pi/2} \dfn \sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j^*))^2
  \]
  と定めると、\ref{enumi: 4.4-1}と
  ブラウン運動の二次変分の公式 (定理3.4.3) より
  \[R_{\Pi/2} \to \frac{1}{2}T \ , \ (\|\Pi\| \to 0)\]
  となる。
  \[
  W^2(T) = \sum_{j=0}^{n-1}\left( W^2(t_{j+1}) - W^2(t_j) \right)
  \]
  と考えると、
  \begin{align*}
    &\sum_{j=0}^{n-1}W(t_j^*)\left( W(t_{j+1}) - W(t_j)\right)
    - \sum_{j=0}^{n-1}\left( W^2(t_{j+1}) - W^2(t_j) \right) \\
    &= 2\sum_{j=0}^{n-1}\left( W(t_{j+1}) - W(t_j)\right)
    \left( W(t_{j+1}) + W(t_j) - 2W(t_j^*)\right) \\
    &= 2\sum_{j=0}^{n-1}
    \left( \left( W(t_{j+1}) - W(t_j^*) \right)
    + \left( W(t_j^*) - W(t_j)\right)\right)
    \left(\left( W(t_{j+1}) - W(t_j^*)\right)
    - \left(W(t_j^*) - W(t_j)\right) \right) \\
    &= 2\sum_{j=0}^{n-1}
    \left( \left( W(t_{j+1}) - W(t_j^*) \right) ^2
    - \left( W(t_j^*) - W(t_j)\right)^2\right) \\
    &= 2Q_{\Pi/2} - 2R_{\Pi/2} \\
    &\to T - T = 0 \ , \ (\|\Pi\| \to 0)
  \end{align*}
  となる。
  よって所望の等式を得る。
\end{proof}





\begin{prob}\label{prob: 4.5}
  \(W(t)\)をブラウン運動、
  \(\alpha(t),\sigma(t)\)を\(W(t)\)に関するfiltration \(\mcF(t), t\geq 0\)
  に適合する確率過程とする。
  \(S(t)\)を確率過程であって、さらに以下の方程式を満たすとする：
  \[
  dS(t) = \alpha(t)S(t)dt + \sigma(t)S(t)dW(t).
  \]
  \begin{enumerate}
    \item \label{enumi: 4.5-1}
    \(d\log S(t)\)を計算せよ。
    \item \label{enumi: 4.5-2}
    以下の等式を示せ：
    \[
    S(t) = S(0) \exp \left(
    \int_0^t\sigma(s)dW(s)
    + \int_0^t\left( \alpha(s)-\frac{1}{2}\sigma^2(s)\right) ds
    \right).
    \]
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.5-1}。
  伊藤の公式と\(dtdt = dtdW(t) = 0, dW(t)dW(t) = dt\)と
  \(S(t)\)の満たす微分方程式を用いれば
  \begin{align*}
    d\log S(t) &= \frac{1}{S(t)}dS(t) - \frac{1}{2S^2(t)}dS(t)dS(t) \\
    &= \frac{1}{S(t)}\left(\alpha(t)S(t)dt + \sigma(t)S(t)dW(t)\right)
    -\frac{1}{2S^2(t)}\left(\alpha(t)S(t)dt + \sigma(t)S(t)dW(t)\right)^2 \\
    &= \alpha(t)dt + \sigma(t)dW(t)
    - \frac{1}{2}\left(\alpha(t)dt + \sigma(t)dW(t)\right)^2 \\
    &= \alpha(t)dt + \sigma(t)dW(t) - \frac{1}{2}\sigma^2(t)dt \\
    &= \sigma(t)dW(t) + \left( \alpha(t) - \frac{1}{2}\sigma^2(t)\right)dt
  \end{align*}
  となる。

  \ref{enumi: 4.5-2}。
  \(d\log S(t)\)を\([0,t]\)で積分することで
  \begin{align*}
    \log \left( \frac{S(t)}{S(0)}\right)
    &= \int_0^t \sigma(s)dW(s) + \int_0^t \left( \alpha(s) - \frac{1}{2}\sigma^2(s)\right)ds
  \end{align*}
  となるので整理すれば所望の式を得る。
\end{proof}



\begin{prob}\label{prob: 4.6}
  \(W\)をブラウン運動として
  \[
  S(t) \dfn S(0)\exp\left(
  \sigma W(t) + \left( \alpha - \frac{1}{2}\sigma^2\right)t\right)
  \]
  を幾何ブラウン運動とし、
  \(p>0\)を定数とする。
  \(S(t)\)の\(p\)乗の微分\(dS^p(t)\)を計算せよ。
\end{prob}

\begin{proof}
  \(p>0\)より\(p-1 \neq -1\)である。
  \[
  f(t,x) \dfn S(0)^p\exp\left(
  p\sigma x + p\left( \alpha - \frac{1}{2}\sigma^2\right)t\right)
  \]
  とおく。
  すると\(S^p(t) = f(t,W(t))\)である。
  また、
  \begin{align*}
    & f_t(t,x) = pS^p(0)\left( \alpha - \frac{1}{2}\sigma^2\right)
    \exp\left(p\sigma x + p\left( \alpha - \frac{1}{2}\sigma^2\right)t\right)
    = p\left( \alpha - \frac{1}{2}\sigma^2\right)f(t,x) \\
    & f_x(t,x) = pS^p(0)\sigma
    \exp\left(p\sigma x + p\left( \alpha - \frac{1}{2}\sigma^2\right)t\right)
    = p\sigma f(t,x) \\
    & f_{x,x}(t,x) = (p\sigma f(t,x))_x = p^2\sigma^2f(t,x)
  \end{align*}
  となる。
  従って伊藤の公式より
  \begin{align*}
    dS^p(t)
    &= df(t,W(t)) \\
    &= f_t(t,W(t)) dt + f_x(t,W(t)) dW(t)
    + \frac{1}{2}f_{x,x}(t,W(t)) dW(t)dW(t) \\
    &= p\left( \alpha - \frac{1}{2}\sigma^2\right)S^p(t) dt
    + p\sigma S^p(t) dW(t)
    + \frac{1}{2}p^2\sigma^2 S^p(t) dt \\
    &= p\left( \alpha + \frac{p-1}{2}\sigma^2 \right)S^p(t)dt
    + p\sigma S^p(t) dW(t)
  \end{align*}
  となる。

  \textbf{別解答.}
  \(g(t,x) \dfn S(0)\exp\left(
  \sigma x + \left( \alpha - \frac{1}{2}\sigma^2\right)t\right)\)
  と置いて伊藤の公式を用い、
  \begin{align*}
    dS(t)
    &= \left( \alpha - \frac{1}{2}\sigma^2\right)S(t)dt
    + \sigma S(t) dW(t) + \frac{1}{2}\sigma^2 S(t) dW(t)dW(t) \\
    &= \left( \alpha + \frac{1}{2}\sigma^2\right)S(t)dt
    + \sigma S(t) dW(t)
  \end{align*}
  と計算してから
  \begin{align*}
    dS(t)dS(t)
    &= \left( \left( \alpha + \frac{1}{2}\sigma^2\right)S(t)dt
    + \sigma S(t) dW(t) \right) ^2  \\
    &= \sigma^2 S^2(t) dW(t)dW(t)  \\
    &= \sigma^2 S^2(t) dt  \\
  \end{align*}
  と計算したのち
  \begin{align*}
    dS^p(t)
    &= pS^{p-1}(t)dS(t) + \frac{1}{2}p(p-1)S^{p-2}dS(t)dS(t) \\
    &= p\left( \alpha + \frac{1}{2}\sigma^2\right)S^p(t)dt
    + p\sigma S^p(t) dW(t) + \frac{1}{2}p(p-1)\sigma^2S^p(t)dt \\
    &= p\left( \alpha + \frac{p-1}{2}\sigma^2\right)S^p(t)dt
    + p\sigma S^p(t) dW(t)
  \end{align*}
  としても同じ結果が得られる。
\end{proof}






\begin{prob}\label{prob: 4.7}
  \(W\)をブラウン運動とする
  \begin{enumerate}
    \item \label{enumi: 4.7-1}
    \(dW^4(t)\)を計算して\(W^4(t)\)を求めよ。
    \item \label{enumi: 4.7-2}
    \(\E[W^4(T)] = 3T^2\)を示せ。
    \item \label{enumi: 4.7-3}
    \(\E[W^6(T)]\)を求めよ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.7-1}。
  伊藤の公式から
  \[
  dW^4(t) = 4W^3(t)dW(t) + \frac{1}{2} 4\cdot 3 W^2(t) dW(t)dW(t)
  = 4W^3(t)dW(t) + 6W^2(t)dt
  \]
  であるから、積分すれば
  \[
  W^4(T) = 4\int_0^T W^3(t)dW(t) + 6\int_0^T W^2(t)dt
  \]
  を得る。

  \ref{enumi: 4.7-2}。
  伊藤積分はマルチンゲールであるから期待値は\(I(0)=0\)である。
  従って
  \[
  \E \int_0^T W^3(t)dW(t) = 0
  \]
  である。
  また、等長性から
  \[
  \E \int_0^T W^2(t)dt
  = \E \left[ \left(\int_0^T W(t)dW(t) \right)^2 \right]
  = \frac{1}{4}\E \left[ \left( W^2(T)-T \right)^2 \right]
  = \frac{1}{4}\E [W^4(T)] - \frac{1}{2}T\E[W^2(T)] + \frac{1}{4}T^2
  \]
  となる。
  \(W^2(T)\)は平均\(0\)で分散\(T\)の正規分布であるから、
  以上より
  \[
  \E [W^4(T)] = \frac{6}{4}\E[W^4(T)] - \frac{6}{2}T^2 + \frac{6}{4}T^2
  \]
  となって所望の式\(\E[W^4(T)] = 3T^2\)を得る。

  \ref{enumi: 4.7-3}。
  伊藤の公式から
  \[
  dW^6(t) = 6W^5(t)dW(t) + 15W^4(t)dt
  \]
  であるから、積分して
  \[
  W^6(T) = 6\int_0^T W^5(t) dW(t) + 15\int_0^T W^4(t)dt
  \]
  を得る。
  期待値をとれば、伊藤積分の部分は\(0\)となって、
  \[
  \E[W^6(T)] = 15\E \int_0^TW^4(t)dt
  \]
  となる。
  ここで
  \[
  \E \int_0^TW^4(t)dt = \int_{\Omega}\int_0^TW^4(t)dtd\P
  = \int_0^T\int_{\Omega}W^4(t)d\P dt
  = \int_0^T\E [W^4(t)]dt
  = \int_0^T 3t^2 dt
  = T^3
  \]
  なので求める期待値は\(\E[W^6(T)] = 15T^3\)となる。
\end{proof}



\begin{prob}\label{prob: 4.8}
  \(\alpha,\beta,\sigma >0 \)を定数とし、
  ブラウン運動\(W\)に対して確率過程\(R\)は以下の確率微分方程式を満たすとする：
  \[
  dR(t) = \left( \alpha-\beta R(t) \right) dt + \sigma dW(t).
  \]
  \begin{enumerate}
    \item \label{enumi: 4.8-1}
    \(d\left( e^{\beta t}R(t)\right)\)を計算せよ。
    これを\(R(t)\)を含まない式に整理せよ。
    \item \label{enumi: 4.8-2}
    上の確率微分方程式を解け (式(4.4.33)を得よ)。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.8-1}。
  \(f(t,x) = e^{\beta t}x\)とおく。
  \begin{align*}
    &f_t(t,x) = \beta e^{\beta t}x \\
    &f_x(t,x) = e^{\beta t} \\
    &f_{x,x}(t,x) = 0
  \end{align*}
  である。
  伊藤の公式と与えられた微分方程式を用いて
  \begin{align*}
    d\left( e^{\beta t}R(t)\right)
    &= \beta e^{\beta t}R(t)dt + e^{\beta t}dR(t) \\
    &= \beta e^{\beta t}R(t)dt
    + \left( \alpha-\beta R(t) \right) e^{\beta t}dt
    + \sigma e^{\beta t} dW(t) \\
    &= \alpha e^{\beta t}dt
    + \sigma e^{\beta t} dW(t)
  \end{align*}
  となる。

  \ref{enumi: 4.8-2}。
  積分すれば
  \[
  e^{\beta t}R(t) - R(0)
  = \alpha \int_0^t e^{\beta u}du
  + \sigma \int_0^t e^{\beta u} dW(u)
  = \frac{\alpha}{\beta} (e^{\beta t} - 1)
  + \sigma \int_0^t e^{\beta u} dW(u)
  \]
  となるから、整理して
  \[
  R(t) = R(0)e^{-\beta t} + \frac{\alpha}{\beta} (1 - e^{-\beta t})
  + \sigma e^{-\beta t}\int_0^te^{\beta u}dW(u)
  \]
  を得る。
\end{proof}





\begin{prob}\label{prob: 4.9}
  \( T, K, \sigma, r\in \R\)を定数、
  \(0\leq t < T\)とし、
  \(N(y) \dfn \frac{1}{\sqrt{2\pi}} \int_{-\infty}^ye^{-x^2/2}dx\)
  を標準正規の分布関数、
  \begin{align*}
    &d_+(\tau,x) \dfn
    \frac{1}{\sigma\sqrt{\tau}} \left(
    \log \frac{x}{K} + \left( r + \frac{1}{2}\sigma^2\right) \tau
    \right), \\
    &d_-(\tau,x) \dfn
    d_+(\tau,x) - \sigma\sqrt{\tau}, \\
    &d_{\pm} \dfn d_{\pm}(T-t,x),
  \end{align*}
  と定義する。
  さらに
  \[
  c = c(t,x) \dfn xN(d_+) - Ke^{-r(T-t)}N(d_-)
  \]
  とする。
  \begin{enumerate}
    \item \label{enumi: 4.9-1}
    次を示せ：
    \[
    Ke^{-r(T-t)}N'(d_-) = xN'(d_+).
    \]
    \item \label{enumi: 4.9-2}
    \(c_x = N(d_+)\)を示せ。
    \item \label{enumi: 4.9-3}
    次を示せ：
    \[
    c_t = -rKe^{-r(T-t)}N(d_-) - \frac{\sigma x}{2\sqrt{T-t}}N'(d_+).
    \]
    \item \label{enumi: 4.9-4}
    \(c\)が式(4.10.3)を満たすこと、つまり
    \[
    c_t(t,x) + rxc_x(t,x) + \frac{1}{2}\sigma^2x^2c_{x,x}(t,x)
    = rc(t,x) \ , \ (0\leq t < T , x > 0)
    \]
    を満たすことを示せ。
    \item \label{enumi: 4.9-5}
    \(x > K\)のとき\(\lim_{t\to T^-}d_{\pm} = \infty\)であり、
    \(0 < x < K\)のとき\(\lim_{t\to T^-}d_{\pm} = -\infty\)
    であることを示せ。
    また、
    \[
    \lim_{t\to T^-} c(t,x) = (x-K)^+ \ , \ (x>0, x\neq K)
    \]
    を示せ。
    \item \label{enumi: 4.9-6}
    \(0\leq t < T\)に対し、
    \(\lim_{x\to 0^+}d_{\pm} = -\infty\)
    と\(\lim_{x\to 0^+}c(t,x) = 0\)を示せ。
    \item \label{enumi: 4.9-7}
    \(0\leq t < T\)に対し
    \(\lim_{x\to \infty}d_{\pm} = \infty\)
    と
    \[
    \lim_{x\to \infty}\left( c(t,x) - \left(
    x-e^{-r(T-t)}K\right)\right) = 0
    \]
    を示せ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.9-1}。
  計算する。
  \(\tau = T-t\)とおく。
  \(N'(y) = \frac{1}{\sqrt{2\pi}}e^{-y^2/2}\)であるから、
  \[
  Ke^{-r\tau-d_-^2/2} = xe^{d_+^2/2}
  \]
  を示せば十分である。
  また\(d_- = d_+ + \sigma\sqrt{\tau}\)であるから、
  \[
  Ke^{-r\tau + \sigma\sqrt{\tau}d_+ - \sigma^2\tau/2} = x
  \]
  を示せば十分である。
  ここで
  \[
  -r\tau + \sigma\sqrt{\tau}d_+ - \frac{1}{2}\sigma^2\tau
  = -r\tau +
  \log \frac{x}{K} + \left( r + \frac{1}{2}\sigma^2\right) \tau
  - \sigma^2\tau
  = \log \frac{x}{K}\]
  であるから、
  \[
  Ke^{\log(x/K)} = x
  \]
  を示せば十分であるが、これは\(\log\)の定義から明らかである。

  \ref{enumi: 4.9-2}。
  \(T-t=\tau\)とおく。
  \[
  c_x = N(d_+(\tau,x)) + x\frac{d(N(d_+(\tau,x))}{dx}
  -Ke^{-r\tau}\frac{d(N(d_-(\tau,x)))}{dx}
  \]
  であるから、
  \[
  x\frac{d(N(d_+(\tau,x))}{dx}
  -Ke^{-r\tau}\frac{d(N(d_-(\tau,x)))}{dx} = 0
  \]
  を示せば良い。
  \begin{align*}
    &\frac{d(N(d_+(\tau,x))}{dx} = N'(d_+)\frac{d(d_+)}{dx} \\
    &\frac{d(N(d_-(\tau,x))}{dx} = N'(d_-)\frac{d(d_-)}{dx}
  \end{align*}
  であるが、ここで\(d_- = d_+ - \sigma\sqrt{\tau}\)であるから
  \[
  \frac{d(d_+)}{dx} = \frac{d(d_-)}{dx}
  \]
  である。
  以上より示すべき等式は
  \[
  xN'(d_+) = Ke^{-r\tau}N'(d_-)
  \]
  に帰着され、これは\ref{enumi: 4.9-1}より正しい。

  \ref{enumi: 4.9-3}。
  \[
  c_t = xN'(d_+)\frac{dd_+}{dt} -
  rKe^{-r(T-t)}N(d_-) - Ke^{-r(T-t)}N'(d_-)\frac{dd_-}{dt}
  \]
  であるが、
  ここで\(dd_+/dt = dd_-/dt - \sigma/2\sqrt{T-t}\)
  に注意すると、\ref{enumi: 4.9-1}より
  \[
  c_t = - rKe^{-r(T-t)}N(d_-) - \frac{\sigma x}{2\sqrt{T-t}}N'(d_+)
  \]
  を得る。
  これは所望の等式である。

  \ref{enumi: 4.9-4}。
  \(\tau = T-t\)とおく。
  示すべき式にこれまでに得られた計算結果を代入すれば、
  \begin{align*}
    &c_t + rxc_x
    + \frac{1}{2}\sigma^2x^2c_{x,x} - rc \\
    &= - rKe^{-r\tau}N(d_-) - \frac{\sigma x}{2\sqrt{\tau}}N'(d_+) \\
    &\ \ \ \ \ \ \ \
    rxN(d_+) - r\left(xN(d_+) - Ke^{-r\tau}N(d_-)\right)
    + \frac{1}{2}\sigma^2x^2c_{x,x} \\
    &= - \frac{\sigma x}{2\sqrt{\tau}}N'(d_+)
    + \frac{1}{2}\sigma^2x^2c_{x,x}
  \end{align*}
  となるので、示すべき等式は
  \[
  \sigma xc_{x,x} = \frac{1}{\sqrt{\tau}}N'(d_+)
  \]
  に帰着される。
  また、\(c_x = N(d_+)\)であるから、
  \(c_{x,x} = N'(d_+)\frac{dd_+}{dx}\)であり、
  従って示すべき等式は
  \[
  \sigma x\frac{dd_+}{dx} = \frac{1}{\sqrt{\tau}}
  \]
  である。
  \begin{align*}
    &\frac{d}{dx}\left(\frac{1}{\sigma\sqrt{\tau}} \left(
    \log \frac{x}{K} + \left( r + \frac{1}{2}\sigma^2\right) \tau
    \right) \right) \\
    &= \frac{1}{\sigma\sqrt{\tau}} \frac{d}{dx} \left(
    \log \frac{x}{K} \right) \\
    &= \frac{1}{\sigma\sqrt{\tau}} K \frac{1}{x/K} \\
    &= \frac{1}{\sigma x \sqrt{\tau}}
  \end{align*}
  となるので、よってとくに
  \[
  \sigma x\frac{dd_+}{dx} = \frac{1}{\sqrt{\tau}}
  \]
  である。以上で示された。

  \ref{enumi: 4.9-5}。
  \(t\to T^-\)のとき\(\tau = T-t \to 0\)であるから、
  極限に影響する項は\(\frac{1}{\sigma\sqrt{T-t}}\log(x/K)\)である。
  \(x > K\)なら\(\log(x/K) > 0\)であるから
  \(d_{\pm} \to \infty\)である。
  またこのとき\(N(d_\pm) \to 1\)であるから、
  \(c\to x - K\)となる。
  \(0 < x < K\)なら\(\log(x/K) < 0\)であるから
  \(d_{\pm} \to - \infty\)である。
  またこのとき\(N(d_{\pm}) \to 0\)であるから
  \(c\to 0\)となる。

  \ref{enumi: 4.9-6}。
  極限に影響する項は\(\frac{1}{\sigma\sqrt{T-t}}\log(x/K)\)である。
  これは\(x\to 0^+\)とすると
  \(d_{\pm}\to -\infty\)となる。
  さらにこのとき\(N(d_{\pm})\to 0\)であるから、
  \(c\to 0\)となる。

  \ref{enumi: 4.9-7}。
  \(\tau = T-t\)とおく。
  極限に影響する項は\(\frac{1}{\sigma\sqrt{\tau}}\log(x/K)\)である。
  これは\(x\to \infty\)とすると
  \(d_{\pm}\to \infty\)となる。
  またこのとき\(N(d_{\pm})\to 1\)である。
  \(c-x\)を計算する。
  \[
  c - x = x(N(d_+)-1) - Ke^{-r(\tau)}N(d_-)
  \]
  であるから、最後の極限を計算するには
  \[
  \lim _{x\to \infty}x(N(d_+)-1) = 0
  \]
  を示せば十分である。
  ここで\(x=e^s\)とおきかえれば
  \[d_+(\tau,e^s) = (\text{定数})s + (\text{定数})\]
  となり、従って示すべきことは
  \[
  \lim _{s\to \infty} e^s(1 - N(s)) = 0
  \]
  となる。
  \[
  1 - N(s) = \frac{1}{\sqrt{2\pi}}\int_s^{\infty}e^{-u^2/2}du
  \]
  であるから、
  \[
  e^s(1-N(s)) = \frac{1}{\sqrt{2\pi}}\int_s^{\infty}e^{s-u^2/2}du
  \]
  となるが、\(s < u\)のときには
  \(e^s < e^u\)であるから、
  \[
  0 \leq e^s(1-N(s))
  < \frac{1}{\sqrt{2\pi}}\int_s^{\infty}e^{u-u^2/2}du
  = \frac{e^{1/2}}{\sqrt{2\pi}}\int_s^{\infty}e^{-(u+1)^2/2}du
  \to 0
  \]
  となる。
  以上で示された。
\end{proof}



\begin{prob}\label{prob: 4.10}
  \
  \begin{enumerate}
    \item \label{enumi: 4.10-1}
    連続時間において、
    \(M(t) \dfn e^{rt}\)をマネー・マーケット・アカウントの
    \(1\)保有単位ごとの時刻\(t\)での価値、
    \(\Delta(t)\)を時刻\(t\)での株式保有数、
    \(\Gamma(t)\)を時刻\(t\)でのマネー・マーケット・アカウントの保有数、
    \(S(t)\)を時刻\(t\)での株価、
    \(X(t)\)を株価とマネー・マーケット・アカウントの取引における
    ポートフォリオとする。
    つまり
    \[
    X(t) \dfn \Delta(t)S(t) + \Gamma(t)M(t)
    \]
    である。
    利益は各時刻\(t\)における株価\(S(t)\)の変動\(dS\)と
    マネー・マーケット・アカウントの単位あたりの
    価値\(M(t)=e^{rt}\)の変動\(dM\)によって決まるので、
    \[
    dX = \Delta dS + \Gamma dM
    \]
    であることに注意せよ。
    これを用いて自己資金調達条件
    \[
    S(t)d\Delta(t) + dS(t)d\Delta(t) + M(t)d\Gamma(t) + dM(t)d\Gamma(t)
    = 0
    \]
    を導け。
    \item \label{enumi: 4.10-2}
    時刻\(t\)での株価\(S(t)\)の株式 (確率過程) に対する
    コール・オプションを考える。
    コール価格は時刻\(t\)で株価\(S(t)=x\)であるときに
    \(c(t,x)\)であるとする。
    コールを買って\(\Delta(t)\)単位の株を得るポートフォリオを
    \[N(t) \dfn c(t,S(t)) - \Delta(t)S(t)\]
    とおく。
    ただし\(\Delta(t)\)もまた確率的であることに注意。
    \(N(t)\)を調達するのに必要なだけの資金を
    マネー・マーケットから運用・調達するとすると、
    各時刻\(t\)での価値が
    \(X(t) \dfn c(t,S(t))\)の、
    株とマネー・マーケット・アカウントからなるポートフォリオ
    を保有することになる。
    マネー・マーケット・アカウントの
    \(1\)保有単位ごとの時刻\(t\)での価値を\(M(t)\)、
    保有数を\(\Gamma(t)\)とおく。
    \[
    X = \Delta S + \Gamma M
    \]
    である。
    マネー・マーケットは瞬間的に無リスク、
    つまり\(dM(t) = rM(t)dt\)とする。
    各時刻で\(\Delta(t) = c_x(t,S(t))\)株保有するとき
    \[
    rN(t)dt = \left( c_t(t,S(t))
    + \frac{1}{2}\sigma^2S^2(t)c_{x,x}(t,S(t))\right) dt
    \]
    であることを示せ。
    結果的に、ブラック-ショールズの偏微分方程式
    \[
    c_t\left((t,S(t)\right) + rS(t)c_x\left(t,S(t)\right)
    + \frac{1}{2}\sigma^2S^2(t)c_{x,x}\left(t,S(t)\right)
    =rc\left(t,S(t)\right)
    \]
    を得る。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.10-1}。
  \(X = \Delta S + \Gamma M\)
  であるから、
  \begin{align*}
    dX &= d (\Delta S + \Gamma M) \\
    &\overset{\bigstar}{=} \Delta dS + Sd\Delta + d\Delta dS
    + \Gamma dM + Md\Gamma + dM d\Gamma \\
    &= dX + Sd\Delta + dSd\Delta + Md\Gamma + dMd\Gamma
  \end{align*}
  となって両辺から\(dX\)を引けば所望の式を得る。
  ただしここで\(\bigstar\)の箇所に伊藤の積の公式を用いた。

  \ref{enumi: 4.10-2}。
  自己資金調達条件 (と同値な式)
  \[
  dX = \Delta dS + \Gamma dM
  \]
  と伊藤の公式と積の公式を用いて、
  \(c_x = \Delta\)と\(\Gamma M = N\)に注意すると、
  \begin{align*}
    dN &= c_tdt + c_xdS + \frac{1}{2}c_{x,x}dSdS
    - d(\Delta S) \\
    &= \left( c_t+\frac{1}{2}c_{x,x}\right)dt
    + c_xdS - d(X-\Gamma M) \\
    &= \left( c_t+\frac{1}{2}c_{x,x}\right)dt
    + \Delta dS - dX + d(\Gamma M) \\
    &= \left( c_t+\frac{1}{2}c_{x,x}\right)dt
    - \Gamma dM + dN
  \end{align*}
  となる。
  両辺から\(dN\)を引き、瞬間的に無リスクであること
   (つまり\(dM(t)=rM(t)dt\))
  に注意すると、
  \[
  \left( c_t+\frac{1}{2}c_{x,x}\right)dt
  = \Gamma dM = r\Gamma Mdt = rNdt
  \]
  がわかる。
\end{proof}



\begin{prob}\label{prob: 4.11}

\end{prob}


\begin{proof}
  \(d(e^{-rt}X(t))\)を計算すると、
  \begin{align*}
    d(e^{-rt}X)
    &= -re^{-rt}Xdt + e^{-rt}dX \\
    &= e^{-rt}\left( -rXdt + dX \right)
  \end{align*}
  となる。
  ここで\(dX\)に条件を代入すれば、
  \begin{align*}
    -rXdt + dX &= dc - c_xdS + r \left(
    - c + Sc_x\right)dt \\
    & \ \ \ \ \ \ \ \
    - \frac{1}{2}(\sigma_2^2-\sigma_1^2)S^2c_{x,x}dt \\
    &= c_tdt + c_xdS + \frac{1}{2}c_{x,x}dSdS - c_xdS
    + r \left( - c + Sc_x\right)dt \\
    &\ \ \ \ \ \ \ \ \
    - \frac{1}{2}(\sigma_2^2-\sigma_1^2)S^2c_{x,x}dt \\
    &= c_tdt + \frac{1}{2}c_{x,x}dSdS
    + r \left( - c + Sc_x\right)dt \\
    &\ \ \ \ \ \ \ \ \
    - \frac{1}{2}(\sigma_2^2-\sigma_1^2)S^2c_{x,x}dt \\
  \end{align*}
  となる。
  ここで\(dSdS = \sigma_2^2S^2dWdW = \sigma_2^2S^2dt\)に注意すると、
  \begin{align*}
    &= c_tdt + \frac{1}{2}c_{x,x}\sigma_2^2S^2dt
    + r \left( - c + Sc_x\right)dt \\
    &\ \ \ \ \ \ \ \ \
    - \frac{1}{2}(\sigma_2^2-\sigma_1^2)S^2c_{x,x}dt \\
    &= c_tdt + r \left( - c + Sc_x\right)dt
    + \frac{1}{2}\sigma_1^2S^2c_{x,x}dt \\
    &= \left( -rc + c_t + rSc +
    \frac{1}{2}\sigma_1^2S^2c_{x,x}\right)dt
  \end{align*}
  となる。
  また、\(c\)は原資産がボラティリティ\(\sigma_1\)の幾何ブラウン運動に従う場合の
  ヨーロピアン・コール・オプションの市場価格であるから、
  以下のブラック-ショールズ方程式を満たす：
  \[
  c_t + rxc_x + \frac{1}{2}\sigma_1^2x^2c_{x,x}= rc.
  \]
  特に\(x=S(t)\)を代入することで
  \[
  c_t + rSc_x + \frac{1}{2}\sigma_1^2S^2c_{x,x}= rc
  \]
  を得る。
  以上より
  \[
  \left( -rc + c_t + rSc +
  \frac{1}{2}\sigma_1^2S^2c_{x,x}\right)dt = 0
  \]
  となって\(d(e^{-rt}X)=0\)がわかった。
  \(X(0)=0\)なのでこれは\(X=0\)を示している。
\end{proof}


\begin{prob}\label{prob: 4.12}
  \begin{enumerate}
    \item \label{enumi: 4.12-1}
    \item \label{enumi: 4.12-2}
    プットの売りポジションをヘッジするには、
    原資産株式を売りポジションにして、
    マネー・マーケット・アカウントを買いポジションにしなければならないことを示せ。
    \item \label{enumi: 4.12-3}
    \(f,p\)は\(c\)が満たすものとおなじブラック-ショールズ方程式を満たすことを示せ。
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.12-1}。
  \(p(t,x) = c(t,x) - f(t,x) = c(t,x) - x + e^{-r(T-t)}K\)であるから、
  \autoref{prob: 4.9}の結果を用いると、
  \begin{align*}
    &p_x(t,x) = c_x(t,x) - 1 = N(d_+) - 1 \\
    &p_{x,x}(t,x) = c_{x,x}(t,x)
    = \frac{1}{\sigma x\sqrt{T-t}}N'(d_+) \\
    &p_t(t,x) = re^{-r(T-t)}K + c_t(t,x)
    = re^{-r(T-t)}K\left( 1-N(d_-)\right)
    - \frac{\sigma x}{2\sqrt{T-t}} N'(d_+)  \\
    &\ \ \ \ \ \ \ \ \
    = re^{-r(T-t)}K N(-d_-) - \frac{\sigma x}{2\sqrt{T-t}} N'(d_+)
  \end{align*}
  となる。

  \ref{enumi: 4.12-2}。
  オプションの売りのヘッジのために保有する原資産株式の枚数は
  \(p_x(t,x)\)である (本書4.5.3節 式(4.5.11)直後の文章)
  から、\(p_x(t,x) = N(d_+) - 1 < 0\)ことからこの場合には
  原資産株式は売りポジションでなければならない。
  マネー・マーケット・アカウントは逆に買いポジションである。

  \ref{enumi: 4.12-3}。
  \(f=c-p\)なので\(f\)について確認すれば十分である。
  \begin{align*}
    &f_x(t,x) = 1, \\
    &f_{x,x}(t,x) = 0, \\
    &f_t(t,x) = -rKe^{-r(T-t)}
  \end{align*}
  であるから、
  \[
  f_t(t,x) + rxf_x(t,x) \frac{1}{2}\sigma^2x^2f_{x,x}(t,x)
  = -rKe^{-r(T-t)} + rx = rf(t,x)
  \]
  となって確認できた。
\end{proof}


\begin{prob}\label{prob: 4.13}

\end{prob}

\begin{proof}
  \(B_1=W_1\)だから\(W_1\)はブラウン運動である。
  \(B_1\)はブラウン運動なので\(dB_1dB_1 = dt\)であり、
  \begin{align*}
    dB_1dB_2 &= dB_1 \left( \rho dB_1 + \sqrt{1-\rho^2}dW_2\right) \\
    &= \rho dB_1dB_1 + \sqrt{1-\rho}dB_1dW_2 \\
    &= \rho dt + \sqrt{1-\rho}dB_1dW_2
  \end{align*}
  となる。
  ここで\(dB_1dB_2 = \rho dt\)であることから、
  \(\sqrt{1-\rho}dB_1dW_2 = 0\)を得る。
  \(-1 < \rho < 1\)と\(B_1=W_1\)から\(dW_1dW_2 = 0\)を得る。
  また、
  \begin{align*}
    dB_2dB_2 &= \rho^2dW_1dW_1
    + 2\rho\sqrt{1-\rho^2}dW_1dW_2 + (1-\rho^2) dW_2dW_2 \\
    &= \rho^2 dt + (1-\rho^2) dW_2dW_2
  \end{align*}
  であるが、\(B_2\)もブラウン運動なので\(dB_2dB_2 = dt\)であり、
  従って\((1-\rho^2)dW_2dW_2 = (1-\rho^2)dt\)、
  つまり\(dW_2dW_2 = dt\)を得る。
  以上の計算結果とレヴィの定理 (4.6.5) を用いれば、
  \(W_1,W_2\)が独立なブラウン運動であることがわかる。
\end{proof}


\begin{prob}\label{prob: 4.14}
  \begin{enumerate}
    \item \label{enumi: 4.14-1}
    \item \label{enumi: 4.14-2}
    \item \label{enumi: 4.14-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.14-1}。
  \(f''\)が可測であることと\(\mcF\)が\(W\)に関するfiltrationであることから
  \(Z_j\)は\(\mcF(t_{j+1})\)-可測である。
  期待値を計算する。
  線形性と既知量の括り出し、
  \(W\)がブラウン運動であるから
  \(W(t_{j+1})-W(t_j)\)が\(\mcF(t_j)\)と独立であることを用いて、
  \begin{align*}
    \E\left[ Z_j \middle| \mcF(t_j)\right]
    &= \E\left[ f''(W(t_j))\left( \left(W(t_{j+1}) - W(t_j)\right)^2
    - (t_{j+1}-t_j)\right) \middle| \mcF(t_j)\right] \\
    &= f''(W(t_j))\left( \E\left[ \left( W(t_{j+1}) - W(t_j)\right)^2
    \middle| \mcF(t_j)\right] - (t_{j+1}-t_j)\right) \\
    &= f''(W(t_j))\left(
    \E\left[ \left( W(t_{j+1}) - W(t_j)\right)^2\right]
    - (t_{j+1}-t_j)\right)
  \end{align*}
  となる。
  \(W\)はブラウン運動なので
  \(W(t_{j+1})-W(t)\)は平均\(0\)で分散\(t_{j+1}-t_j\)の正規確率変数であり、
  従って
  \[
  \E\left[ \left( W(t_{j+1}) - W(t_j)\right)^2\right]
  - (t_{j+1}-t_j) = 0
  \]
  である。
  以上より\(\E\left[ Z_j \middle| \mcF(t_j)\right] = 0\)である。

  \(4\)次モーメントが\(\E[\left( W(t_{j+1}) - W(t_j)\right)^4]
  =3(t_{j+1}-t_j)^2\)であることを思い出すと、
  \begin{align*}
    &\E\left[ Z_j^2 \middle| \mcF(t_j)\right] \\
    &= \E\left[ f''(W(t_j))^2\left( \left(W(t_{j+1}) - W(t_j)\right)^4
    - 2(t_{j+1}-t_j) \left(W(t_{j+1}) - W(t_j)\right)^2
    + (t_{j+1}-t_j)^2\right) \middle| \mcF(t_j)\right] \\
    &= f''(W(t_j))^2 \left( \E\left[ \left(W(t_{j+1}) - W(t_j)\right)^4\right]
    - 2(t_{j+1}-t_j)\E \left[ \left(W(t_{j+1}) - W(t_j)\right)^2\right]
    + (t_{j+1}-t_j)^2 \right) \\
    &= f''(W(t_j))^2 \left( 3(t_{j+1}-t_j)^2
    - 2 (t_{j+1}-t_j)^2 + (t_{j+1}-t_j)^2 \right) \\
    &= 2f''(W(t_j))^2(t_{j+1}-t_j)^2
  \end{align*}
  となる。

  \ref{enumi: 4.14-2}。
  \(f''(W(t_j))\)と\((W(t_{j+1})-W(t_j))^2\)は独立なので
  \begin{align*}
    \E [\sum_{j=0}^{n-1}Z_j] \\
    &= \E \left[ \sum_{j=0}^{n-1} f''(W(t_j))
    \left( (W(t_{j+1})-W(t_j))^2 - (t_{j+1}-t_j)\right) \right] \\
    &= \sum_{j=0}^{n-1} \E [f''(W(t_j))] \left(
    \E [(W(t_{j+1})-W(t_j))^2] - (t_{j+1}-t_j)\right)  \\
    &= \sum_{j=0}^{n-1} \E [f''(W(t_j))] \left(
    (t_{j+1}-t_j) - (t_{j+1}-t_j)\right) = 0
  \end{align*}
  である。
  \textbf{別解答.}
  \ref{enumi: 4.14-1}より
  \[
  \E [\sum_{j=0}^{n-1}Z_j]
  = \sum_{j=0}^{n-1}\E [\E[Z_j\mid \mcF(t_j)] = 0.
  \]

  \ref{enumi: 4.14-3}。
  \(j < k\)とすると\(Z_j\)は\(\mcF(t_k)\)-可測であるから
  \[
  \E[Z_jZ_k] = \E[\E[Z_jZ_k\mid \mcF(t_k)]]
  = \E[Z_j\E[Z_k\mid \mcF(t_k)]] = \E[0] = 0
  \]
  となる。
  よって
  \begin{align*}
    \Var(\sum_{j=0}^{n-1}Z_j)
    &= \E \left[ \left( \sum_{j=0}^{n-1}Z_j\right)^2 \right] \\
    &= \sum_{j=0}^{n-1} \E [ Z_j^2 ]
    + \sum_{j\neq k}\E [Z_jZ_k] \\
    &= 2\sum_{j=0}^{n-1} \E [ f''(W(t_j))^2 ] (t_{j+1}-t_j)^2 \\
    &< 2 \|\Pi\| \sum_{j=0}^{n-1} \E [ f''(W(t_j))^2 ] (t_{j+1}-t_j) \\
    &\to 0\cdot \E \int_0^T f''(W(t_j))^2 dt = 0 \ , \ (\|\Pi\| \to 0)
  \end{align*}
  となる。
\end{proof}



\begin{prob}\label{prob: 4.15}
  \begin{enumerate}
    \item \label{enumi: 4.15-1}
    \item \label{enumi: 4.15-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.15-1}。
  \(dB_i = \sum_j \frac{\sigma_{ij}}{\sigma_i} dW_j\)であることと、
  \(\sum_j \sigma_{ij}^2 = \sigma_i^2\)と
  \(W_j\)らが違いに独立なブラウン運動であることから、
  \begin{align*}
    dB_idB_i
    &= \left( \sum_j\frac{\sigma_{ij}}{\sigma_i} dW_j \right)^2 \\
    &= \sum_{j_1,j_2}\frac{\sigma_{ij_1}\sigma_{ij_2}}{\sigma_i^2}
     dW_{j_1}dW_{j_2}
    &= \sum_j\frac{\sigma_{ij}^2}{\sigma_i^2}(dW_j)^2 \\
    &= \frac{1}{\sigma_i^2}\sum_{j=1}^d\sigma_{ij}^2dt
    &= dt
  \end{align*}
  である。よって\(B_i\)はブラウン運動である。

  \ref{enumi: 4.15-2}。
  \begin{align*}
    dB_idB_k
    &= \left( \sum_j\frac{\sigma_{ij}}{\sigma_i} dW_j \right)
    \left( \sum_j\frac{\sigma_{ik}}{\sigma_k} dW_j \right) \\
    &= \sum_{j_1,j_2}
    \frac{\sigma_{ij_1}\sigma_{kj_2}}{\sigma_i\sigma_k}
    dW_{j_1}dW_{j_2} \\
    &= \sum_{j=0}^d
    \frac{\sigma_{ij}\sigma_{kj}}{\sigma_i\sigma_k} (dW_j)^2 \\
    &= \sum_{j=0}^d
    \frac{\sigma_{ij}\sigma_{kj}}{\sigma_i\sigma_k} dt \\
    &= \rho_{ik}(t)dt
  \end{align*}
  である。
\end{proof}






\begin{prob}\label{prob: 4.16}

\end{prob}

\begin{proof}
  \(W_i(t) \dfn \sum_{j=1}^m\int_0^t\alpha_{ij}(u)dB(u)\)とおく。
  まず
  \(dW_j = \sum_{k=1}^m\alpha_{jk}dB_k\)であるから、
  \begin{align*}
    \sum_{j=1}^m\int_0^t a_{ij}(u)dW_j(u)
    &= \sum_{j=1}^m\int_0^t a_{ij}(u)
    \left( \sum_{k=1}^m\alpha_{jk}dB_k(u)\right) \\
    &= \sum_{j=1}^m\sum_{k=1}^m\int_0^t
    a_{ij}(u)\alpha_{jk}dB_k(u) \\
    &= \sum_{k=1}^m\int_0^t
    \sum_{j=1}^m a_{ij}(u)\alpha_{jk}dB_k(u) \\
    &= \int_0^tdB_i(u) = B(t)
  \end{align*}
  となるので\(W_j\)らは条件式(4.10.27)を満たす。
  あとは\(W_j\)たちが独立なブラウン運動であることを示せば良い。
  \begin{align*}
    dW_idW_k
    &= \left( \sum_{j=1}^m\alpha_{ij}dB_j\right)
    \left( \sum_{j=1}^m\alpha_{kj}dB_j\right) \\
    &= \sum_{j_1=1}^m\sum_{j_2=1}^m
    \alpha_{ij_1}\alpha_{kj_2}dB_{j_1}dB_{j_2} \\
    &= \sum_{j_1=1}^m\sum_{j_2=1}^m
    \alpha_{ij_1}\alpha_{kj_2}\rho_{j_1j_2}dt \\
    &= \sum_{j_1=1}^m\sum_{j_2=1}^m
    \alpha_{ij_1}\alpha_{kj_2}\sum_{l=1}^m a_{j_1l}a_{j_2l} dt \\
    &= \sum_{l=1}^m
    \left(\sum_{j_1=1}^m\alpha_{ij_1}a_{j_1l}\right)
    \left(\sum_{j_2=1}^m\alpha_{kj_2}a_{j_2l}\right) dt \\
    &= \sum_{l=1}^m \delta_{il}\delta{kl} dt \\
    &= \delta_{ik} dt
  \end{align*}
  であるから、とくに\(i=k\)なら\((dW_i)^2=dt\)であり、
  \(i\neq k\)であれば\(dW_idW_k=0\)である。
  以上で示された。
\end{proof}


\begin{prob}\label{prob: 4.17}
  \begin{enumerate}
    \item \label{enumi: 4.17-1}
    \item \label{enumi: 4.17-2}
    \item \label{enumi: 4.17-3}
    \item \label{enumi: 4.17-4}
    \item \label{enumi: 4.17-5}
    \item \label{enumi: 4.17-6}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.17-1}。
  既知量の括り出しより
  \begin{align*}
    &\E[(B_1(t_0+\ep)-B_1(t_0))(B_2(t_0+\ep)-B_2(t_0)) \mid \mcF(t_0)] \\
    &= \E[B_1(t_0+\ep)(B_2(t_0+\ep) \mid \mcF(t_0)]
    - B_1(t_0)\E[B_2(t_0+\ep)\mid \mcF(t_0)] \\
    &\ \ \ \ \ \ \
    - B_2(t_0)\E[B_1(t_0+\ep)\mid \mcF(t_0)]
    + B_1(t_0)B_2(t_0)
  \end{align*}
  となるが、\(B_1,B_2\)はブラウン運動なのでマルチンゲールであり、従って
  \[
  = \E[B_1(t_0+\ep)(B_2(t_0+\ep) \mid \mcF(t_0)] - B_1(t_0)B_2(t_0)
  \]
  となる。
  伊藤の積の公式より
  \[
  d(B_1B_2) = B_1dB_2 + B_2dB_1 + dB_1dB_2
  = B_1dB_2 + B_2dB_1 + \rho dt
  \]
  なので、これを\(\int_0^{t_0+\ep}\)と\(\int_0^{t_0}\)で積分すれば、
  \begin{align*}
    B_1(t_0+\ep)B_2(t_0+\ep)
    &= \int_0^{t_0+\ep} (B_1dB_2 + B_2dB_1) + \rho(t_0+\ep) \\
    B_1(t_0)B_2(t_0)
    &= \int_0^{t_0} (B_1dB_2 + B_2dB_1) + \rho(t_0)
  \end{align*}
  となる。
  一つ目で\(\E[(-)\mid \mcF(t_0)]\)をとれば、
  伊藤積分のマルチンゲール性と二つ目の式から
  \[
  \E[B_1(t_0+\ep)(B_2(t_0+\ep) \mid \mcF(t_0)]
  = \int_0^{t_0} (B_1dB_2 + B_2dB_1) + \rho(t_0+\ep)
  = B_1(t_0)B_2(t_0) + \rho\ep
  \]
  がわかる。
  以上より
  \[
  \E[(B_1(t_0+\ep)-B_1(t_0))(B_2(t_0+\ep)-B_2(t_0)) \mid \mcF(t_0)]
  = \E[B_1(t_0+\ep)(B_2(t_0+\ep) \mid \mcF(t_0)] - B_1(t_0)B_2(t_0)
  = \rho\ep
  \]
  となる。
  これは所望の結果である。

  \ref{enumi: 4.17-2}。
  \(B_i'\dfn B_i(t_0+\ep)-B_i(t_0)\)とおく。
  \begin{align*}
    &X_i(t_0 + \ep) - X_i(t_0) = \ep\Theta_i + \sigma_iB_i' \\
    &(X_i(t_0 + \ep) - X_i(t_0))^2
    = \ep^2\Theta_i^2 + \sigma_i^2(B_i')^2
    + 2\ep\Theta_i\sigma_i B_i' \\
    &(X_1(t_0 + \ep) - X_1(t_0))(X_2(t_0 + \ep) - X_2(t_0))
    = \ep^2\Theta_1\Theta_2 + \sigma_1\sigma_2B_1'B_2'
    + \ep(\Theta_1\sigma_2 B_2 + \Theta_2\sigma_1B_1)
  \end{align*}
  である
  また\(B_i\)はブラウン運動なので
  \(B_i' = B_i(t_0+\ep)-B_i(t_0)\)は\(\mcF(t_0)\)と独立な
  平均\(0\)分散\(\ep\)の正規確率変数であることに注意すると、
  \[
  \E[B_i'\mid \mcF(t_0)] = \E[B_i'] = 0,
  \E[(B_i')^2\mid\mcF] = \E[(B_i')^2] = \ep
  \]
  であり、さらに\ref{enumi: 4.17-1}より
  \(\E[B_1'B_2'\mid \mcF(t_0)] = \rho\ep\)であるから、
  \begin{align*}
    &\E[X_i(t_0 + \ep) - X_i(t_0)\mid \mcF(t_0)]
    = \E[\ep\Theta_i + \sigma_iB_i'\mid \mcF(t_0)]
    = \ep\Theta_i, \\
    &\E[(X_i(t_0 + \ep) - X_i(t_0))^2\mid \mcF(t_0)]
    = \E[\ep^2\Theta_i^2 + \sigma_i^2(B_i')^2
    + 2\ep\Theta_i\sigma_i B_i']
    = \ep^2\Theta_i^2 + \sigma_i^2\ep, \\
    &\E[(X_1(t_0 + \ep) - X_1(t_0))(X_2(t_0 + \ep) - X_2(t_0))] \\
    &= \E[\ep^2\Theta_1\Theta_2 + \sigma_1\sigma_2B_1'B_2'
    + \ep(\Theta_1\sigma_2 B_2 + \Theta_2\sigma_1B_1)]
    = \ep^2\Theta_1\Theta_2 + \rho\sigma_1\sigma_2\ep
  \end{align*}
  となる。これらは所望の結果である。
  また相関が\(\rho\)であることも上の結果を適用して単純計算によって示される。

  \ref{enumi: 4.17-3}。
  \[
  X_i(t_0+\ep) - X_i(t_0)
  = \int_{t_0}^{t_0 + \ep}\Theta_i du
  + \int_0^{t_0+\ep}\sigma_i dB_i - \int_0^{t_0}\sigma dB_i
  \]
  であるが、伊藤積分はマルチンゲールであるから、
  条件つき期待値\(\E [(-)\mid \mcF(t_0)]\)を取れば
  右辺の第二項と第三項が相殺して
  \[
  M_i(\ep) \dfn \E [X_i(t_0+\ep) - X_i(t_0) \mid \mcF(t_0)]
  = \E\left[ \int_{t_0}^{t_0 + \ep}\Theta_i(u) du
  \middle| \mcF(t_0)\right]
  \]
  となる。
  また、
  \[
  \frac{1}{\ep}\int_{t_0}^{t_0 + \ep}\Theta_i(u) du
  \to \Theta_i(t_0) \ , \ (\ep \to 0^+)
  \]
  であるから、従って
  \begin{align*}
    \lim _{\ep\to 0^+}\frac{1}{\ep}M_i(\ep)
    &= \lim _{\ep\to 0^+}
    \E\left[ \frac{1}{\ep}\int_{t_0}^{t_0 + \ep}\Theta_i(u) du
    \middle| \mcF(t_0)\right] \\
    &= \E\left[ \Theta_i(t_0)\middle| \mcF(t_0)\right] \\
    &= \Theta_i(t_0)
  \end{align*}
  である。

  \ref{enumi: 4.17-4}。
  \(dY_i = \sigma_idB_i\)とおき、
  \(Y_i' = Y_i(t_0 + \ep) - Y_i(t_0)\)とおく。
  伊藤積分\(Y_i\)はマルチンゲールなので\(\E[Y_i'\mid\mcF(t_0)]=0\)である。
  \[
  X_i(t_0+\ep) - X_i(t_0) = \int_{t_0}^{t_0+\ep}\Theta_idu + Y_i'
  = \ep\Theta_i(t_0) + Y_i' + o(\ep)
  \]
  であるから、
  \begin{align*}
    &\E[(X_1(t_0+\ep) - X_1(t_0))(X_2(t_0+\ep) - X_2(t_0))
    \mid \mcF(t_0)]\\
    &= \E[\ep^2\Theta_1(t_0)\Theta_2(t_0) + o(\ep) \mid \mcF(t_0)]
    + \E[\ep Y_1'\Theta_2(t_0) + \ep Y_2'\Theta_1(t_0) + o(\ep)
    \mid \mcF(t_0)]
    + \E[Y_1'Y_2'\mid\mcF(t_0)] \\
    &= \ep \left( \Theta_2(t_0)\E[Y_1'\mid \mcF(t_0)]
    + \Theta_1(t_0)\E[Y_2'\mid \mcF(t_0)]\right) + o(\ep)
    + \E[Y_1'Y_2'\mid\mcF(t_0)] \\
    &= \E[Y_1'Y_2'\mid\mcF(t_0)] + o(\ep) \\
    &= \E[
    (Y_1(t_0 + \ep) - Y_1(t_0))(Y_2(t_0 + \ep) - Y_2(t_0))
    \mid\mcF(t_0)] + o(\ep) \\
    &= \E[Y_1(t_0 + \ep) Y_2(t_0 + \ep) \mid \mcF(t_0)]
    + Y_1(t_0)Y_2(t_0) \\
    &\ \ \ \ \ \ \ \ \ \
    - Y_1(t_0)\E[Y_2(t_0 + \ep)\mid\mcF(t_0)]
    - Y_2(t_0)\E[Y_1(t_0 + \ep)\mid\mcF(t_0)]
     + o(\ep) \\
     &= \E[Y_1(t_0 + \ep) Y_2(t_0 + \ep) \mid \mcF(t_0)]
     - Y_1(t_0)Y_2(t_0) + o(\ep)
  \end{align*}
  となる。
  さて、ここで伊藤の積の公式と
  \(dY_i = \sigma_idB_i, dB_1dB_2 = \rho dt\)から、
  \begin{align*}
    d(Y_1Y_2)
    &= Y_1dY_2 + Y_2dY_1 + dY_1dY_2 \\
    &= \sigma_2Y_1dB_2 + \sigma_1Y_2dB_1 + \sigma_1\sigma_2dB_1dB_2 \\
    &= \sigma_2Y_1dB_2 + \sigma_1Y_2dB_1 + \rho\sigma_1\sigma_2dt
  \end{align*}
  となる。
  これを\(\int_0^{t_0+\ep}\)と\(\int_0^{t_0}\)で積分して、
  \begin{align*}
    &Y_1(t_0+\ep)Y_2(t_0+\ep)
    = \int_0^{t_0+\ep} (\sigma_2Y_1dB_2 + \sigma_1Y_2dB_1)
    + \int_0^{t_0+\ep} \rho\sigma_1\sigma_2dt \\
    &Y_1(t_0)Y_2(t_0)
    = \int_0^{t_0} (\sigma_2Y_1dB_2 + \sigma_1Y_2dB_1)
    + \int_0^{t_0} \rho\sigma_1\sigma_2dt
  \end{align*}
  を得る。
  一つ目の式で\(\E[(-)\mid \mcF(t_0)]\)をとって、
  伊藤積分のマルチンゲール性と二つ目の式を使えば、
  \begin{align*}
    &\E[Y_1(t_0 + \ep) Y_2(t_0 + \ep) \mid \mcF(t_0)] \\
    &= \E\left[
    \int_0^{t_0+\ep} (\sigma_2Y_1dB_2 + \sigma_1Y_2dB_1)
    + \int_0^{t_0+\ep} \rho\sigma_1\sigma_2dt
    \middle| \mcF(t_0)\right] \\
    &= \int_0^{t_0} (\sigma_2Y_1dB_2 + \sigma_1Y_2dB_1)
    + \E\left[ \int_0^{t_0+\ep} \rho\sigma_1\sigma_2dt
    \middle| \mcF(t_0)\right] \\
    &= \int_0^{t_0} (\sigma_2Y_1dB_2 + \sigma_1Y_2dB_1)
    + \int_0^{t_0}\rho\sigma_1\sigma_2dt
    + \E\left[ \int_{t_0}^{t_0+\ep} \rho\sigma_1\sigma_2dt
    \middle| \mcF(t_0)\right] \\
    &= Y_1(t_0)Y_2(t_0)
    + \E\left[ \int_{t_0}^{t_0+\ep} \rho\sigma_1\sigma_2dt
    \middle| \mcF(t_0)\right]
  \end{align*}
  となる。
  以上より
  \begin{align*}
    &\E[(X_1(t_0+\ep) - X_1(t_0))(X_2(t_0+\ep) - X_2(t_0))
    \mid \mcF(t_0)]\\
    &= \E[Y_1(t_0 + \ep) Y_2(t_0 + \ep) \mid \mcF(t_0)]
    - Y_1(t_0)Y_2(t_0) + o(\ep) \\
    &= \E\left[ \int_{t_0}^{t_0+\ep} \rho\sigma_1\sigma_2dt
    \middle| \mcF(t_0)\right] + o(\ep) \\
    &= \E\left[ \rho(t_0)\sigma_1(t_0)\sigma_2(t_0) + o(\ep)
    \middle| \mcF(t_0)\right] + o(\ep) \\
    &= \rho(t_0)\sigma_1(t_0)\sigma_2(t_0) + o(\ep)
  \end{align*}
  となって所望の式が得られた。

  \textbf{疑問：}そもそも
  \(M_1(\ep)M_2(\ep)
  = \ep^2\Theta_1(t_0)\Theta_2(t_0) + o(\ep) = o(\ep)\)なのでは？
  まあ単純なケースとの比較と思えばこの項がある方が自然だけれど。

  \ref{enumi: 4.17-5}。
  共分散の方は\ref{enumi: 4.17-4}の計算結果そのままだから分散の方を求める。
  今までに定めた記号などはそのまま流用する。
  計算すれば
  \begin{align*}
    &\E[(X_i(t_0+\ep) - X_i(t_0))^2\mid \mcF(t_0)] \\
    &= \E\left[ \left(\ep \Theta(t_0) + Y_i' + o(\ep)\right)^2
    \middle| \mcF(t_0)\right] \\
    &= \E\left[ 2\ep \Theta(t_0) Y_i' + (Y_i')^2 + o(\ep)
    \middle| \mcF(t_0)\right] \\
    &= 2\ep \Theta(t_0) \E\left[ Y_i' \middle| \mcF(t_0)\right]
    + \E\left[ (Y_i')^2 \middle| \right] + o(\ep) \\
    &= \E\left[ (Y_i')^2 \middle| \right] + o(\ep) \\
    &= \E\left[ (Y_i(t_0+\ep) - Y_i(t_0))^2 \middle| \right] + o(\ep) \\
    &= \E\left[ Y_i^2(t_0+\ep) \middle| \right]
    - 2Y_i(t_0)\E \left[ Y_i(t_0+\ep) \middle| \right]
    + Y_i^2(t_0) + o(\ep) \\
    &= \E\left[ Y_i^2(t_0+\ep) \middle| \right] - Y_i^2(t_0) + o(\ep)
  \end{align*}
  となる (最後の方は伊藤積分のマルチンゲール性などを使っている)。
  ここで伊藤の公式より
  \[
  d(Y_i^2) = 2Y_idY_i + (dY_i)^2
  = 2\sigma_iY_idY_i + \sigma_i^2(dB_i)^2
  = 2\sigma_iY_idY_i + \sigma_i^2dt
  \]
  である (\(B_i\)はブラウン運動であるから\((dB_i)^2 = dt\)である)。
  これを\(\int_0^{t_0+\ep}\)と\(\int_0^{t_0}\)で積分して、
  \begin{align*}
    &Y_i^2(t_0+\ep)
    = \int_0^{t_0+\ep}2\sigma_iY_idY_i + \int_0^{t_0+\ep}\sigma_i^2dt, \\
    &Y_i^2(t_0)
    = \int_0^{t_0}2\sigma_iY_idY_i + \int_0^{t_0}\sigma_i^2dt
  \end{align*}
  を得る。
  一つ目の式で条件付き期待値\(\E[(-)\mid\mcF(t_0)]\)をとって
  伊藤積分のマルチンゲール性と二つ目の式を用いると、
  \begin{align*}
    \E[Y_i^2(t_0+\ep) \mid \mcF(t_0)]
    &= \E \left[ \int_0^{t_0+\ep}2\sigma_iY_idY_i
    \middle| \mcF(t_0) \right] +
    \E \left[ \int_0^{t_0+\ep}\sigma_i^2dt \middle| \mcF(t_0)\right] \\
    &= \int_0^{t_0}2\sigma_iY_idY_i
    + \int_0^{t_0}\sigma_i^2dt +
    \E \left[ \int_{t_0}^{t_0+\ep}\sigma_i^2dt
    \middle| \mcF(t_0)\right] \\
    &= Y_i^2(t_0) +
    \E \left[ \sigma_i^2(t_0)\ep + o(\ep) \middle| \mcF(t_0)\right] \\
    &= Y_i^2(t_0) + \sigma_i^2(t_0)\ep + o(\ep)
  \end{align*}
  となる。
  以上より、
  \begin{align*}
    \E[(X_i(t_0+\ep) - X_i(t_0))^2\mid \mcF(t_0)]
    &= \E\left[ Y_i^2(t_0+\ep) \middle| \right] - Y_i^2(t_0) + o(\ep) \\
    &= \sigma_i^2(t_0)\ep + o(\ep)
  \end{align*}
  を得る。

  \ref{enumi: 4.17-6}。
  計算すると、
  \begin{align*}
    \frac{C(\ep)}{\sqrt{V_1(\ep)V_2(\ep)}}
    &= \frac{\rho(t_0)\sigma_1(t_0)\sigma_2(t_0)\ep + o(\ep)}
    {\sqrt{\sigma_1^2(t_0)\sigma_2^2(t_0)\ep^2 + o(\ep^2)}} \\
    &= \frac{\rho(t_0)\sigma_1(t_0)\sigma_2(t_0) + \frac{1}{\ep}o(\ep)}
    {\sqrt{\sigma_1^2(t_0)\sigma_2^2(t_0) + \frac{1}{\ep^2}o(\ep^2)}} \\
    &\to \frac{\rho(t_0)\sigma_1(t_0)\sigma_2(t_0)}
    {\sqrt{\sigma_1^2(t_0)\sigma_2^2(t_0)}} \ , \ (\ep \to 0^+) \\
    &\to \rho(t_0)
  \end{align*}
  となる。
\end{proof}




\begin{prob}\label{prob: 4.18}
  \begin{enumerate}
    \item \label{enumi : 4.18-1}
    \item \label{enumi : 4.18-2}
    \item \label{enumi : 4.18-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi : 4.18-1}。
  \(f(t,x) = \exp \left(
  -\theta x - \left( r + \frac{1}{2}\theta^2\right) t \right)\)
  と定めると、\(\zeta(t) = f(t,W(t))\)である。
  また、
  \begin{align*}
    &f_t(t,x) = - \left( r + \frac{1}{2}\theta^2\right) f(t,x) \\
    &f_x(t,x) = - \theta f(t,x) \\
    &f_x(t,x) = \theta ^2 f(t,x)
  \end{align*}
  となる。
  以上の結果と伊藤の公式を用いて計算すると、
  \begin{align*}
    d\zeta &= f_tdt + f_xdW + \frac{1}{2}f_{x,x}(dW)^2 \\
    &= - \left( r + \frac{1}{2}\theta^2\right) f(t,W)dt
    - \theta f(t,W)dW + \frac{1}{2}\theta ^2 f(t,W) dt \\
    &= - r\zeta dt - \theta \zeta dW
  \end{align*}
  となる。
  これは所望の結果である。

  \ref{enumi : 4.18-2}。
  ヒント通り微分を計算する。
  以下では断りなく伊藤の公式や積の公式などを用いる。
  リスクの市場価値\(\theta\)の定義から
  \(\theta \sigma = \alpha - r\)であることに注意すると、
  \begin{align*}
    d(\zeta X) &= \zeta dX + X d\zeta + d\zeta dX \\
    &= \zeta \left( rXdt + (\alpha-r)\Delta S dt + \Delta\sigma SdW
    \right) \\
    &\ \ \ \ \ \ \
    - rX\zeta dt - X \theta \zeta dW \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    + \left( rXdt + (\alpha-r)\Delta S dt + \Delta\sigma SdW \right)
    \left( - r\zeta dt - \theta \zeta dW \right) \\
    &= (\alpha-r)\zeta \Delta S dt + \Delta\zeta \sigma SdW
    - X \theta \zeta dW \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    - \Delta\sigma S \theta \zeta (dW)^2 \\
    &= (\alpha-r)\zeta \Delta S dt + \Delta\zeta \sigma SdW
    - X \theta \zeta dW
    - \Delta\sigma S \theta \zeta dt \\
    &= ( \alpha - r - \theta \sigma )\zeta \Delta S dt
    + \Delta\zeta \sigma SdW - X \theta \zeta dW \\
    &= (\Delta\zeta \sigma S - X \theta \zeta )dW
  \end{align*}
  となる。
  以上より、\(\zeta X\)は
  \(\zeta X = \int_0^t(\Delta\zeta \sigma S - X \theta \zeta )dW\)
  と伊藤積分を用いて表すことができ、特にこれはマルチンゲールである。

  \ref{enumi : 4.18-3}。
  \(\zeta X\)はマルチンゲールなので、
  \(\E[\zeta(T)X(T)] = \zeta(0)X(0) = X(0)\)である。
  \(X(t)\)は時刻\(t\)におけるポートフォリオの価値であるから、
  \(X(0)\)は初期費用で\(X(T) = V(T)\)は時刻\(T\)での価値である。
  これらから、時刻\(T\)において価値\(V(T)\)のポートフォリオを保有したいなら、
  初期資金\(X(0) = \E[\zeta(T)X(T)]\)ではじめるべきであるとわかる。
\end{proof}




\begin{prob}\label{prob: 4.19}
  \begin{enumerate}
    \item \label{enumi: 4.19-1}
    \item \label{enumi: 4.19-2}
    \item \label{enumi: 4.19-3}
    \item \label{enumi: 4.19-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.19-1}。
  \((dB(t))^2 = \mathrm{sign}^2(W(t))(dW(t))^2 = (dW(t))^2 = dt\)
  なのでレヴィの定理より\(B\)はブラウン運動である。

  \ref{enumi: 4.19-2}。
  \begin{align*}
    d(B(t)W(t)) &= B(t)dW(t) + W(t)dB(t) + dB(t)dW(t) \\
    &= B(t)dW(t) + \mathrm{sign}(W(t))W(t)dW(t)
    + \mathrm{sign}(W(t))(dW)^2 \\
    &= (B(t) + \mathrm{sign}(W(t)))W(t)dW(t) + \mathrm{sign}(W(t))dt
  \end{align*}
  であるから、積分して期待値をとれば
  \begin{align*}
    \E[B(t)W(t)]
    &= \E \left[ \int_0^t (B(u) + \mathrm{sign}(W(u))W(u))dW(u)
    + \int_0^t\mathrm{sign}(W(u))du \right] \\
    &= \E \left[ \int_0^t\mathrm{sign}(W(u))du \right] \\
    &= \int_0^t \E \left[ \mathrm{sign}(W(u)) \right] du \\
    &= \int_0^t \left( - \P(W(u)<0) + \P(W(u)\geq 0) \right) du
  \end{align*}
  となる。
  ここで\(W(u)\)は平均\(0\)分散\(u\)の正規確率変数であるから、
  \[
  \P(W(u) \leq 0) = \P(W(u) < 0)
  = \frac{1}{\sqrt{2\pi u}}\int_{-\infty}^0e^{-x^2/2u}dx
  = \frac{1}{\sqrt{2\pi u}}\int_0^\infty e^{-x^2/2u}dx
  = \P(W(u) \geq 0)
  \]
  となる。
  以上より\(\E[B(t)W(t)] = 0\)である。

  \ref{enumi: 4.19-3}。
  伊藤の公式より
  \[
  d(W^2) = 2WdW + (dW)^2 = 2WdW + dt
  \]
  となる。

  \ref{enumi: 4.19-4}。
  まず、\(B(t)\)はブラウン運動であるから、\(\E[B(t)] = 0\)である。
  従って\(\E [B(t)] \E[W^2(t)] = 0\)となる。
  次に\(d(BW^2)\)を計算すると、
  \begin{align*}
    d(BW^2)
    &= W^2dB + Bd(W^2) + dBd(W^2) \\
    &= W^2(\mathrm{sign}(W)dW) + B(2WdW + dt)
    + \mathrm{sign}(W)dW(2WdW + dt)\\
    &= W^2\mathrm{sign}(W)dW + 2WBdW + Bdt)
    + 2W\mathrm{sign}(W)(dW)^2\\
    &= (W^2\mathrm{sign}(W) + 2WB)dW
    + (2W\mathrm{sign}(W) + B)dt
  \end{align*}
  となる。積分して期待値をとれば、
  伊藤積分の期待値が\(0\)であることから、
  \begin{align*}
    \E[B(t)W^2(t)]
    &= \E \left[ \int_0^t (2W(u)\mathrm{sign}(W(u)) + B(u))du \right] \\
    &= \int_0^t \E \left[2W(u)\mathrm{sign}(W(u)) + B(u) \right] du \\
    &= 2 \int_0^t \E \left[ W(u)\mathrm{sign}(W(u))\right] du \\
    &= 2 \int_0^t \frac{1}{\sqrt{2\pi u}}\int_{-\infty}^\infty
    x\mathrm{sign}(x)e^{-x^2/2u}dxdu \\
    &= 4 \int_0^t \frac{1}{\sqrt{2\pi}}\int_0^\infty
    xe^{-x^2/2}dxdu \\
    &>0
  \end{align*}
  となる。とくに\(\E[B(t)W^2(t)] \neq \E [B(t)] \E[W^2(t)]\)となって
  \(B(t)\)と\(W(t)\)は独立でない
  (もし独立なら\(B(t)\)と\(W^2(t)\)も独立のはずで、
  そうすると積の期待値は分解するはずである)。
\end{proof}



\begin{prob}\label{prob: 4.20}
  \begin{enumerate}
    \item \label{enumi: 4.20-1}
    \item \label{enumi: 4.20-2}
    \item \label{enumi: 4.20-3}
    \item \label{enumi: 4.20-4}
    \item \label{enumi: 4.20-5}
    \item \label{enumi: 4.20-6}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 4.20-1}。
  \(f'(x) = 1 , ( x > 0), f'(x) = 0 , (x<0)\)であり、
  \(x=0\)では\(f'(x)\)は定義されない。
  \(f''(x) = 0 , (x\neq 0)\)であり、
  \(x=0\)では\(f''(x)\)は定義されない。

  \ref{enumi: 4.20-2}。
  \(f'(W(t)) = \mathrm{sign}(W(t))\)であるから、
  \autoref{prob: 4.19}の記号を用いれば
  \(\int_0^Tf'(W(t))dW(t) = B(T)\)であり、
  これはブラウン運動である。
  よって式(4.10.42)が正しければ
  \[
  \E[(W(T)-K)^+] = \E[B(T)] = 0
  \]
  となるはずであるが、左辺は
  \[
  \E[(W(T)-K)^+]
  = \frac{1}{\sqrt{2\pi T}}\int_{-\infty}^{\infty}(x-K)^+e^{-x^2/2T}dx
  = \frac{1}{\sqrt{2\pi T}}\int_K^{\infty}(x-K)e^{-x^2/2T}dx
  > 0
  \]
  となるのでこれは矛盾である。

  \ref{enumi: 4.20-3}。
  多項式の微分をするだけ。

  \ref{enumi: 4.20-4}。
  \(f_n(x)\)は連続であり、
  \(n\)が大きくなれば二次関数の部分の幅が小さくなるので、
  \(x\neq K\)に対して
  \(\lim _{n\to \infty}f_n(x) = (x-K)^+\)であることがわかる。
  \(x=K\)のときは\(f_n(K) = 1/8n \to 0\)である。
  これは所望の結果である。
  同じく\(f_n'(x) = 0, (x < K), 1, (x > K)\)もわかる。
  \(x=K\)のときは\(f_n'(K) = 1/2 \to 1/2 , (n\to \infty )\)である。
  これも所望の結果である。

  \ref{enumi: 4.20-5}。
  仮定から任意の\(t\)に対して\(W(t) < K\)であるから、
  十分大きな\(n\)を選べば\(W(t) < K - 1/2n\)となって、
  このとき\(\int_0^T\I_{[K - 1/2n,K + 1/2n]}(W(t))dt = 0\)である。
  よって\(L_K(T)=0\)がわかる。

  \ref{enumi: 4.20-6}。
  英語版を持ってないからわからないけど、
  これは後の「言い換えると」の部分を
  (「同値であるが」と) 読めば
  \begin{center}
    「ほとんど確実に\(L_K(T)=0\)となる、は偽であることを示せ」
  \end{center}
  という問題だと思う。
  そう思って解くと、伊藤積分の期待値が\(0\)であることから
  \[
  \E[L_K(T)] = \E[(W(T)-K)^+] > 0
  \]
  となることが所望の結論を導く。
\end{proof}


\begin{prob}\label{prob: 4.21}
  \begin{enumerate}
    \item \label{enumi: 4.21-1}
    \item \label{enumi: 4.21-2}
  \end{enumerate}
\end{prob}


\begin{proof}
  \ref{enumi: 4.21-1}。
  実際の取引を「ちょうど時刻\(t\)」に行うことって可能なのか
  (取引は瞬間的に行われるものではないのでは)、とか、
  たとえば\(S(t)\)がめちゃくちゃ短時間で大量の回数\(K\)の周りを行き来した場合
  とかって大丈夫なのか？とかがちょっと現実的でないかもしれない？

  \ref{enumi: 4.21-2}
  \(X(t)\)は伊藤積分で定義されているからマルチンゲールであり、
  \(\E[X(T)] = X(0) = 0\)となるが、
  \(\E[(S(T)-K)^+] > 0\)であるから\(X(T) \neq (S(T)-K)^+\)となる。
  この問題で行われている推論がダメなところって、
  やっぱり (上の\ref{enumi: 4.21-1}の解答でも述べたみたいに)
  \(S(t)\)が\(K\)の周りを無限に行き来することがあるかもしれない、
  とかそういうところにあるのかな？
\end{proof}









\newpage

\section{リスク中立価格評価法}\label{section: 5}





\begin{prob}\label{prob: 5.1}
  \begin{enumerate}
    \item \label{enumi: 5.1-1}
    \item \label{enumi: 5.1-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.1-1}。
  式(5.2.16)と式(5.2.17)をかけあわせると\(DS = f(X)\)となることがわかる。
  \(X\)の定義から、
  \[
  dX = \sigma dW + \left(\alpha - R - \frac{1}{2}\sigma^2\right) ds
  \]
  であるから、\((dX)^2 = \sigma^2 (dW)^2 = \sigma^2 dt\)となる。
  よって伊藤の公式より
  \begin{align*}
    d(f(X)) &= f'(X)dX + \frac{1}{2}f''(X)(dX)^2 \\
    &= f(X)dX + \frac{1}{2}f(X) \sigma^2 dt \\
    &= f(X) \left( dX + \frac{1}{2} \sigma^2 ds\right) \\
    &= DS \left( \sigma dW +
    \left(\alpha - R - \frac{1}{2}\sigma^2\right) ds
    + \frac{1}{2} \sigma^2 ds\right) \\
    &= DS \left( \sigma dW + \left(\alpha - R\right) ds \right) \\
    &= \sigma DS \left( dW + \frac{\alpha - R}{\sigma} ds \right) \\
    &= \sigma DS \left( dW + \Theta ds \right)
  \end{align*}
  となる。
  ただし\(\Theta = (\alpha - R)/\sigma\)はリスクの市場価格である。
  \(d(f(X))=d(DS)\)であるから、これは式(5.2.20)と一致している。

  \ref{enumi: 5.1-2}。
  \begin{align*}
    d(DS) &= SdD + DdS + dDdS \\
    &= S(-RDdt) + D(\alpha S dt + \sigma SdW)
    + (-RD dt)(\alpha S dt + \sigma SdW) \\
    &= S\left( -RDdt + D\alpha dt + D\sigma dW)\right) \\
    &= \sigma DS\left( \frac{\alpha - R}{\sigma} dt + dW)\right) \\
    &= \sigma DS\left( \Theta dt + dW)\right)
  \end{align*}
  であり、これは式(5.2.20)と一致している。
\end{proof}






\begin{prob}\label{prob: 5.2}

\end{prob}

\begin{proof}
  式(5.2.30)、つまり
  \[D(t)V(t) = \tilde{\E}[D(T)V(T) \mid \mcF(t)]\]
  の右辺に補題(5.2.2)を用いれば
  \[=\E[D(T)V(T)Z(T)\mid \mcF(t)]/Z(t)\]
  となって、両辺を\(Z(t)\)倍すれば所望の等式を得る。
\end{proof}









\begin{prob}\label{prob: 5.3}
  \begin{enumerate}
    \item \label{enumi: 5.3-1}
    \item \label{enumi: 5.3-2}
    \item \label{enumi: 5.3-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.3-1}。
  \[
  f(x)
  = S(T) = x\exp \left( \sigma\tilde{W}(T)
  + \left( r-\frac{1}{2}\sigma^2\right) T\right)
  = K\exp \left(\sigma \sqrt{T} d_-(T,x) + \sigma \tilde{W}(T)\right)
  \]
  とおけば、式(5.9.2)より
  \(c(0,x) = \tilde{\E}\left[ e^{-rT}h(f(x))\right]\)
  である。
  \(x\)で微分すれば、
  \[
  f'(x) = f(1) \ , \
  h'(x) =
  \begin{cases}
    0, \ (x < K), \\
    1, \ (x > K),
  \end{cases}
  \]
  であることから
  \begin{align*}
    c_x(0,x) &= \tilde{\E}\left[ \left( e^{-rT}h(f(x))\right) '\right] \\
    &= \tilde{\E}\left[ e^{-rT}f'(x)h'(f(x)) \right] \\
    &= e^{-rT}\tilde{\E}\left[
    \exp \left( \sigma\tilde{W}(T)
    + \left( r-\frac{1}{2}\sigma^2\right) T\right)h'(f(x))
    \right] \\
    &= e^{-\frac{1}{2}\sigma^2T} \tilde{\E}\left[
    e^{\sigma\tilde{W}(T)} h'(f(x)) \right] \\
    &= e^{-\frac{1}{2}\sigma^2T} \tilde{\E}\left[
    e^{\sigma\tilde{W}(T)} \I_{f(x) > K} \right] \\
  \end{align*}
  となる。
  ここで
  \begin{itemize}
    \item[ \ ] \(f(x) > K\)
    \item[\(\iff\)]
    \(K\exp \left(\sigma \sqrt{T} d_-(T,x) + \sigma \tilde{W}(T)\right) > K\)
    \item[\(\iff\)]
    \(e^{\sigma \tilde{W}(T)} > e^{-\sigma \sqrt{T} d_-(T,x)}\)
    \item[\(\iff\)]
    \(\sigma \tilde{W}(T) > - \sigma \sqrt{T} d_-(T,x)\)
    \item[\(\iff\)]
    \( \tilde{W}(T) > - \sqrt{T} d_-(T,x)\)
    \ \ (ボラティリティ\(\sigma\)は今の仮定では正である)
  \end{itemize}
  であることに注意すると、
  \[
  c_x(0,x)
  = e^{-\frac{1}{2}\sigma^2T} \tilde{\E}\left[
  e^{\sigma\tilde{W}(T)} \I_{f(x) > K} \right]
  = e^{-\frac{1}{2}\sigma^2T} \tilde{\E}\left[
  e^{\sigma\tilde{W}(T)} \I_{\tilde{W}(T) > - \sqrt{T} d_-(T,x)} \right]
  \]
  となる。
  また、\(\tilde{W}\)はリスク中立測度\(\tilde{\P}\)のもとでのブラウン運動であるから、
  とくに\(\tilde{W}(T)\)は平均\(0\)で分散\(T\)の
  (\(\tilde{\P}\)に関する)
  正規確率測度である。
  従って
  \begin{align*}
    &e^{-\frac{1}{2}\sigma^2T} \tilde{\E}\left[
    e^{\sigma\tilde{W}(T)} \I_{\tilde{W}(T) > - \sqrt{T} d_-(T,x)} \right] \\
    &= \frac{1}{\sqrt{2\pi T}}e^{-\sigma^2T/2}
    \int_{-\sqrt{T} d_-(T,x)}^{\infty} e^{\sigma t}e^{-t^2/2T} dt \\
    &= \frac{1}{\sqrt{2\pi T}}e^{-\sigma^2T/2}
    \int_{-\sqrt{T} d_-(T,x)}^{\infty} e^{ - (t-\sigma T)^2/2T + \sigma^2T/2} dt \\
    &= \frac{1}{\sqrt{2\pi T}}
    \int_{-\sqrt{T} d_-(T,x)}^{\infty} e^{ - (t-\sigma T)^2/2T} dt \\
    &= \frac{1}{\sqrt{2\pi T}}
    \int_{-\sqrt{T} d_-(T,x) - \sigma T}^{\infty} e^{-t^2/2T} dt \\
    &= \frac{1}{\sqrt{2\pi}}
    \int_{-d_-(T,x) - \sigma \sqrt{T}}^{\infty} e^{-t^2/2} dt \\
    &= N(d_-(T,x) + \sigma \sqrt{T})
    = N(d_+(T,x))
  \end{align*}
  となる。これは所望の結果である。

  \ref{enumi: 5.3-2}。
  \(\hat{W}(t)\)がブラウン運動となり、
  また\(c_x(0,x) = \hat{\P}(S(T)>K)\)
  となるように\(\hat{\P}\)を定める問題と解釈する。
  \(\tilde{W}(T)\)は平均\(0\)で分散\(T\)の正規確率変数であるから、
  ギルザノフの定理を用いると、
  \[
  Z(t) \dfn \exp \left( \sigma \tilde{W}(t) - \frac{1}{2}\sigma^2t\right)
  \]
  とおいて確率測度\(\hat{\P}\)を
  \[
  \hat{\P}(A) \dfn \int_AZ(\omega)\tilde{\P}(\omega)
  \]
  と定義すれば、
  \(\hat{W}(t) = \tilde{W}(t) - \sigma t\)
  は確率測度\(\hat{\P}\)のもとブラウン運動となる。
  また、\ref{enumi: 5.3-1}の解答の記号のもと、
  \(e^{-rT}f'(x) = f(1) = Z(T)\)であるから、
  \begin{align*}
    \hat{\P}(S(T)>K) &= \hat{\E}\left[\I_{S(T) > K}\right] \\
    &= \tilde{\E}\left[\I_{S(T) > K}Z(T)\right] \\
    &= \tilde{\E}\left[e^{-rT}f'(x)h'(f(x))\right] \\
    &= \tilde{\E}\left[\left(e^{-rT}h(f(x))\right)'\right] \\
    &= c_x(0,x)
  \end{align*}
  となって、\(c_x(0,x) = \hat{\P}(S(T)>K)\)も確認できた。

  \ref{enumi: 5.3-3}。
  \(S(T)\)を\(\hat{W}(T)\)を用いて表すと、
  \begin{align*}
    S(T) &= x\exp \left( \sigma\tilde{W}(T)
    + \left( r - \frac{1}{2}\sigma^2\right)T \right) \\
    &= x\exp \left( \sigma\left( \hat{W}(T) + \sigma T\right)
    + \left( r - \frac{1}{2}\sigma^2\right)T \right) \\
    &= x\exp \left( \sigma \hat{W}(T)
    + \left( r + \frac{1}{2}\sigma^2\right)T \right) \\
    &= K\exp \left(\sigma \sqrt{T} d_+(T,x) + \sigma \hat{W}(T)\right)
  \end{align*}
  となる。
  このとき、
  \begin{itemize}
    \item[ \ ]
    \(S(T) > K\)
    \item[\(\iff\)]
    \(K\exp \left(\sigma \sqrt{T} d_+(T,x)
    + \sigma \hat{W}(T)\right) > K \)
    \item[\(\iff\)]
    \(\exp \left(\sigma \sqrt{T} d_+(T,x) + \sigma \hat{W}(T)\right) > 1 \)
    \item[\(\iff\)]
    \(\sigma \hat{W}(T) > - \sigma \sqrt{T} d_+(T,x)\)
    \item[\(\iff\)]
    \(\hat{W}(T) > - \sqrt{T} d_+(T,x)\)
    \item[\(\iff\)]
    \(-\frac{\hat{W}(T)}{T} < d_+(T,x)\)
  \end{itemize}
  であるから、
  \begin{align*}
    \hat{\P}(S(T) > K)
    &= \hat{\P}\left(-\frac{\hat{W}(T)}{T} < d_+(T,x)\right) \\
    &= \hat{\P}\left( \hat{W}(T) > - \sqrt{T} d_+(T,x)\right) \\
    &= \frac{1}{\sqrt{2\pi T}}\int_{- \sqrt{T} d_+(T,x)}^\infty
    e^{-x^2/2T} dx \\
    &= \frac{1}{\sqrt{2\pi }}\int_{-d_+(T,x)}^\infty e^{-x^2/2} dx \\
    &= N(d_+(T,x))
  \end{align*}
  がわかる。
\end{proof}











\begin{prob}\label{prob: 5.4}
  \begin{enumerate}
    \item \label{enumi: 5.4-1}
    \item \label{enumi: 5.4-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.4-1}。
  \(Sd(\log(S)) = dS\)であるから、
  \begin{align*}
    d(\log S) &= \frac{1}{S}dS - \frac{1}{2S^2}(dS)^2 \\
    &= \frac{1}{S}\left( rSdt + \sigma S d\tilde{W}\right)
    - \frac{1}{2S^2}\left( rSdt + \sigma S d\tilde{W}\right)^2 \\
    &= rdt + \sigma d\tilde{W} - \frac{\sigma^2}{2}(d\tilde{W})^2 \\
    &= rdt + \sigma d\tilde{W} - \frac{\sigma^2}{2}dt \\
    &= \left( r-\frac{\sigma^2}{2}\right)dt + \sigma d\tilde{W}
  \end{align*}
  となる。
  これを積分すれば
  \[
  \log S(T) - \log S(0)
  = \int_0^T \left( r(t)-\frac{\sigma^2(t)}{2}\right)dt
  + \int_0^T \sigma(t)d\tilde{W}(t)
  \]
  となるので、右辺の確率変数を\(X\)とおけば\(S(T) = S(0)e^X\)となる。
  また、右辺第\(1\)項は\(r,\sigma\)は確定的であるから定数であり、
  第\(2\)項は確定的な関数の伊藤積分であるから
  (リスク中立測度\(\tilde{\P}\)に対して) (定理4.4.9より)
  期待値\(0\)で分散
  \(\int_0^T \sigma^2(t)dt\)の正規確率変数である。
  従って\(X\)は正規確率変数となる。
  リスク中立測度で\(X\)の期待値をとれば、伊藤積分の部分は\(0\)になって
  \[
  \tilde{\E}[X]
  = \tilde{\E}\left[ \int_0^T \left(r(t) - \frac{1}{2}\sigma^2(t)\right) dt\right]
  \]
  である。
  ここで\(r(t)\)は確定的であるから、
  \(\tilde{\E}[X] = \int_0^T (r(t) - \sigma^2(t)/2) dt\)がわかる。
  分散も同じく、\(r\)が確定的であることから、
  \begin{align*}
    \Var(X) &= \tilde{\E}[X^2 - \tilde{\E}[X]^2] \\
    &= \left( \int_0^T (r(t) - \sigma^2(t)/2) dt\right)^2
    - \left( \int_0^T (r(t) - \sigma^2(t)/2) dt\right)^2
    + \tilde{\E}\left[ \left(
    \int_0^T \sigma(t)d\tilde{W}(t)\right)^2 \right] \\
    &= \tilde{\E}\left[ \left(
    \int_0^T \sigma(t)d\tilde{W}(t)\right)^2 \right]
  \end{align*}
  となる。
  ここで伊藤積分の等長性と\(\sigma\)が確定的であることから、
  \[
  = \tilde{\E} \left[ \int_0^T \sigma^2(t) dt \right]
  = \int_0^T \sigma^2(t) dt
  \]
  がわかる。
  実測度では、\(d\tilde{W} = dW + \Theta dt\)であるから、
  \(\Theta\)が確定的であることから\(X\)は正規確率変数であり、
  期待値は\(\E [X] = \int_0^T( r(t) - \sigma^2(t)/2 + \sigma(t)\Theta(t))dt\)である。
  同じく分散は\(\Var(X) = \int_0^T\sigma^2(t)dt\)である。

  \ref{enumi: 5.4-2}。
  \(\bar{S}(t)\)を原資産であるボラティリティが一定値\(\Sigma\)で金利\(R\)も一定となる
  ヨーロピアン・コールに対する確率変数とすると、
  \[d\bar{S} = R\bar{S}dt + \Sigma\bar{S}dW\]
  であるから、\ref{enumi: 5.4-1}より、
  \[
  \bar{S}(T) = \bar{S}(0)e^{\bar{X}}
  \]
  となる (リスク中立測度に関する)
  平均\((R-\Sigma^2/2)T\)で分散\(T\Sigma^2\)の
  正規確率変数\(\bar{X}\)が存在する。
  ここで\(X=\bar{X}\)として定数\(R,\Sigma\)を\(r,\sigma\)で表すと、
  \begin{align*}
    &R = \frac{1}{T}\int_0^T r(t) dt, \\
    &\Sigma = \sqrt{\frac{1}{T}\int_0^T\sigma^2(t)dt},
  \end{align*}
  となる。
  このとき\(D(T) = \exp \left( -\int_0^T r(t) dt\right) = e^{-RT}\)であり、
  従って、
  \begin{align*}
    c(0,S(0)) &= \E \left[D(T)\left( S(T)-K \right)^+ \right]\\
    &= \E \left[ e^{-RT}\left( \bar{S}(T)-K \right)^+ \right]
  \end{align*}
  となるが、
  ここで最後の期待値は、
  原資産であるボラティリティが一定値\(\Sigma\)で金利\(R\)も一定となる
  ヨーロピアン・コールの時刻\(0\)での価格、つまり
  \(\mathrm{BSM}(T,S(0);K,R,\Sigma)\)に他ならない。
  以上で示された。
\end{proof}










\begin{prob}\label{prob: 5.5}
  \begin{enumerate}
    \item \label{enumi: 5.5-1}
    \item \label{enumi: 5.5-2}
    \item \label{enumi: 5.5-3}
    \item \label{enumi: 5.5-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.5-1}。
  \(Z=e^X\)とおくと\(dX = -\Theta dW - \frac{1}{2}\Theta^2du\)であるから、
  \begin{align*}
    dZ &= e^XdX + \frac{1}{2}e^X(dX)^2 \\
    &= Z\left( -\Theta dW - \frac{1}{2}\Theta^2du \right)
    + \frac{1}{2}Z\left( -\Theta dW - \frac{1}{2}\Theta^2du \right)^2  \\
    &= - Z\Theta dW - \frac{1}{2}Z\Theta^2du + \frac{1}{2}Z \Theta^2(dW)^2 \\
    &= - Z\Theta dW - \frac{1}{2}Z\Theta^2du + \frac{1}{2}Z \Theta^2du \\
    &= - Z\Theta dW
  \end{align*}
  となる。
  従って
  \begin{align*}
    d\left( \frac{1}{Z} \right)
    &= -Z^{-2}dZ + \frac{1}{2}\cdot 2Z^{-3} (dZ)^2 \\
    &= Z^{-2}Z\Theta dW  + \frac{1}{2}\cdot 2Z^{-3} Z^2\Theta^2(dW)^2 \\
    &= Z^{-1}\Theta dW  + Z^{-1} \Theta^2dt \\
    &= \frac{\Theta}{Z}\left( \Theta dt + dW \right)
  \end{align*}
  となる。

  \ref{enumi: 5.5-2}。
  \(0\leq s \leq t\)とする。
  \(\tilde{M}(t)\)は\(\mcF(t)\)-可測であるから、
  補題5.2.2より
  \begin{align*}
    \E [Z(t)\tilde{M}(t) \mid \mcF(s)]
    &= Z(s) \tilde{\E}[\tilde{M}(t) \mid \mcF(s)] \\
    &= Z(s) \tilde{M}(s)
  \end{align*}
  となって\(Z\tilde{M}\)は\(\P\)のもとでマルチンゲールである。

  \ref{enumi: 5.5-3}。
  仮定から\(dM = \Gamma dW\)である。
  よって
  \begin{align*}
    d\tilde{M}
    &= \frac{1}{Z}dM
    + Md\left( \frac{1}{Z}\right)
    + dMd\left( \frac{1}{Z} \right) \\
    &= \frac{1}{Z}\Gamma dW
    + M \frac{\Theta}{Z}\left( \Theta dt + dW \right)
    + \Gamma \frac{\Theta}{Z} dW \left( \Theta dt + dW \right) \\
    &= \frac{1}{Z} \left( \Gamma dW
    + M\Theta\left( \Theta dt + dW \right)
    + \Gamma\Theta (dW)^2 \right)\\
    &= \frac{1}{Z} \left( \Gamma dW
    + M\Theta\left( \Theta dt + dW \right)
    + \Gamma\Theta dt \right)\\
    &= \frac{1}{Z} \left (\Gamma + M\Theta \right) dW
    + \frac{\Theta}{Z} \left( M\Theta + \Gamma \right) dt \\
    &= \frac{M\Theta + \Gamma}{Z} \left( dW + \Theta dt \right)
  \end{align*}
  となる。

  \ref{enumi: 5.5-4}。
  \(d\tilde{W} = dW + \Theta dt\)となるから
  \(\tilde{\Gamma} \dfn (M\Theta + \Gamma)/Z\)とおけば
  \(d\tilde{M} = \tilde{\Gamma}d\tilde{W}\)である。
  これを積分すれば式(5.3.2)を得る。
\end{proof}







\begin{prob}\label{prob: 5.6}

\end{prob}

\begin{proof}
  まず\(Z\)について調べる。
  \(Z=e^X\)とおけば
  \[
  dX = -\sum \Theta_i dW_i - \frac{1}{2}\| \Theta \|^2 du
  \]
  である。
  \(dW_idW_j = 0 , (i\neq j), \ du , (i=j)\)
  と\(dW_idu = (du)^2 = 0\)より、
  \begin{align*}
    dZ &= ZdX + \frac{1}{2}Z(dX)^2 \\
    &= -Z\left( \sum \Theta_i dW_i + \frac{1}{2}\| \Theta \|^2 du \right)
    + \frac{Z}{2}\left( \sum \Theta_i dW
    - \frac{1}{2}\| \Theta \|^2 du \right) ^2 \\
    &= -Z\left( \sum \Theta_i dW_i + \frac{1}{2}\| \Theta \|^2 du \right)
    + \frac{Z}{2} \sum \Theta_i^2 (dW_i)^2 \\
    &= -Z\left( \sum \Theta_i dW_i + \frac{1}{2}\| \Theta \|^2 du \right)
    + \frac{Z}{2} \| \Theta \|^2 du \\
    &= -Z \sum \Theta_i dW_i
  \end{align*}
  となる。
  とくに\(Z\)は\(\P\)についてマルチンゲールであり、
  \(\E[Z(T)] = Z(0) = 1\)がわかる。
  また\(dZdu = 0, dZdW_i = -Z \Theta_i du\)もわかる。
  \(d\tilde{W}_i = dW_i + \Theta_i du\)であるから、
  \begin{align*}
    d(Z\tilde{W}_i) &= \tilde{W}_idZ + Zd\tilde{W}_i + d\tilde{W}_idZ \\
    &= \tilde{W}_idZ + Z(dW_i + \Theta_i du) + (dW_i + \Theta_i du)dZ \\
    &= \tilde{W}_idZ + Z(dW_i + \Theta_i du) + -Z \Theta_i du \\
    &= \tilde{W}_idZ + ZdW_i
  \end{align*}
  となって、\(dZ = -Z \sum \Theta_i dW_i\)より
  \(Z\tilde{W}_i\)も\(\P\)についてマルチンゲールである。
  従って
  \[
  \tilde{\E} [\tilde{W}_i(t) \mid \mcF(s)]
  = \frac{1}{Z(s)}\E [\tilde{W}_i(t)Z(t) \mid \mcF(s)]
  = \frac{1}{Z(s)}\tilde{W}_i(s)Z(s) = \tilde{W}_i(s)
  \]
  となって\(\tilde{W}_i(s)\)は\(\tilde{\P}\)についてマルチンゲールである。

  また、
  \[
  d\tilde{W}_id\tilde{W}_j
  = (dW_i + \Theta_i du) (dW_j + \Theta_j du)
  = dW_idW_j = \delta_{ij}du
  \]
  である (ここで\(\delta_{ij}\)はクロネッカーのデルタ) から、
  レヴィの定理により\(d\tilde{W}_i\)たちは互い独立なブラウン運動である。
  以上で示された。
\end{proof}












\begin{prob}\label{prob: 5.7}
  \begin{enumerate}
    \item \label{enumi: 5.7-1}
    \item \label{enumi: 5.7-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.7-1}。
  \(X_2(0) = a > 0\)とおく。
  \(X_2(t) \dfn (a+X_1(t))/D(t)\)とすれば
  \(X_2(t)D(t) = a+X_1(t)\)であるから、
  \[
  X_1(T) \geq 0 \ \iff \ X_1(T)+a \geq a \ \iff \ X_2(T)D(T) \geq X_2(0)
  \ \iff \ X_2(T) \geq X_2(0)/D(T)
  \]
  となって
  \(\P(X_2(T) \geq X_2(0) / D(T)) = \P(X_1(T) \geq 0) = 1\)となる。
  同じく
  \[
  X_1(T) > 0 \ \iff \ X_2(T) > X_2(0)/D(T)
  \]
  なので
  \(\P(X_2 > X_2(0)) = \P(X_1 > 0) > 0\)
  となる。
  以上より\(X_2\)は所望の確率過程である。

  \ref{enumi: 5.7-2}。
  \(X_2(0) = a > 0\)とおく。
  \(X_1(t) \dfn D(t)X_2(t) - a\)とおけば、
  \(D(0)=1\)であるから
  \(X_1(0) = D(0)X_2(0) - a = a-a = 0\)であり、
  また\ref{enumi: 5.7-1}の証明と同じく
  \begin{align*}
    &\P(X_1 \geq 0) = \P(X_2 \geq X_2(0)) = 0, \\
    &\P(X_1 > 0) = \P(X_2 > X_2(0)) > 0,
  \end{align*}
  となる。
  以上より\(X_1\)は所望の確率過程である。
\end{proof}






\begin{prob}\label{prob: 5.8}
  \begin{enumerate}
    \item \label{enumi: 5.8-1}
    \item \label{enumi: 5.8-2}
    \item \label{enumi: 5.8-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.8-1}。
  \(D=e^{-X}\)の形をしていて\(dX=Rdt\)であるので、
  \(dD = -e^{-X}dX = -DRdt\)となる。
  さらに\(dV\)は\(dt\)と\(dW\)のある適合過程を係数とした線形和であるから、
  \(dDdV = 0\)がわかる。
  よって伊藤の積の公式より
  \[
  d(DV) = DdV + VdD = DdV - VDRdt = D(dV-VRdt)
  \]
  となる。
  ここで\(DV\)がマルチンゲールであることから、
  マルチンゲールの表現定理より
  ある適合過程\(\tilde{\Gamma}\)があって
  \(d(DV) = \tilde{\Gamma}d\tilde{W}\)となる。
  代入すると、
  \[
  \tilde{\Gamma}d\tilde{W} = D(dV-VRdt)
  \]
  となり、これを整理すれば所望の式を得る。

  \ref{enumi: 5.8-2}。
  ほとんど確実に正な確率変数の条件付き期待値はほとんど確実に正であるが、
  ここで\(D(T)V(T)/D(t)\)はほとんど確実に正であるから、
  \(V(t) = \E [ D(T)V(T)/D(t) \mid \mcF(t)]\)もほとんど確実に正である。

  \ref{enumi: 5.8-3}。
  \(\sigma = \tilde{\Gamma}/DV\)とおくと良い。
\end{proof}


\begin{prob}\label{prob: 5.9}

\end{prob}

\begin{proof}
  \(c_K\)の式を見れば\(c_K\)が正しければ\(c_{K,K}\)が本の通りとなることは明らかである。
  よって本書の\(c_K\)の式が正しいことを確かめれば十分である。
  計算すると、
  \begin{align*}
    c_K(0,T,x,K) &= \frac{d}{dK}e^{-rT}\int_K^{\infty}(y-K)\tilde{p}(0,T,x,y) dy \\
    &= \frac{d}{dK}e^{-rT}\int_K^{\infty}y\tilde{p}(0,T,x,y) dy
    -\frac{d}{dK}\left(Ke^{-rT}\int_K^{\infty}y\tilde{p}(0,T,x,y) dy\right) \\
    &= -e^{-rT}K\tilde{p}(0,T,x,K)
    - e^{-rT}\int_K^{\infty}y\tilde{p}(0,T,x,y)
    + Ke^{-rT}\tilde{p}(0,T,x,K) \\
    &= - e^{-rT}\int_K^{\infty}y\tilde{p}(0,T,x,y)
  \end{align*}
  となる。
  以上で確認できた。
\end{proof}


\begin{prob}\label{prob: 5.10}
  \begin{enumerate}
    \item \label{enumi: 5.10-1}
    \item \label{enumi: 5.10-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.10-1}。
  オプションの買い手がコールとプットのどちらを選んでも良いようにするには
  \(t_0\)の時点でのオプションの価格は
  \(\max\left\{ C(t_0),P(t_0)\right\}\)
  でなければならない。
  式変形すれば
  \begin{align*}
    \max\left\{ C(t_0),P(t_0) \right\}
    &= C(t_0) + \max\left\{ 0, P(t_0)-C(t_0) \right\} \\
    &= C(t_0) + \max\left\{ 0, -F(t_0) \right\} \\
    &= C(t_0) + \left( e^{-r(T-t_0)}K-S(t_0) \right)^+
  \end{align*}
  となって所望の等式を得る。

  \ref{enumi: 5.10-2}。
  \(V(T)\)をこのオプションのペイオフとすると、
  時刻\(t\)でのオプション価格は、リスク中立価格評価式から
  \(V(t) = \tilde{\E}[e^{-r(T-t)}V(T)]\)
  である。
  行使価格\(K\)のコール・オプション、プット・オプションの価格を
  \(C_K(t),P_K(t)\)と表せば、初期値は
  \begin{align*}
    V(0) &= \tilde{\E}[e^{-r(T-t)}V(T)] \\
    &= \tilde{\E}\left[\tilde{\E}\left[
    e^{-r(T-t)}V(T)\mid\mcF(t_0)\right]\right] \\
    &= \tilde{\E}\left[ V(t_0) \right] \\
    &= \tilde{\E}\left[ C_K(t_0)\right] +
    \tilde{\E}\left[ \left( e^{-r(T-t_0)}K - S(t_0) \right)^+\right] \\
    &= C_K(0) + P_{e^{-r(T-t_0)}K}(0)
  \end{align*}
  となる。これは所望の結果である。
\end{proof}



\begin{prob}\label{prob: 5.11}

\end{prob}


\begin{proof}
  まず\(d(DX)\)を計算する。
  \(dD = -RDdu\)であることに注意。
  従って\(dDdX=0\)である。
  また\(\Theta =(\alpha-R)/\sigma\)を用いて
  \(d\tilde{W} = dW + \Theta du\)と定義する。
  \(\tilde{W}\)はリスク中立測度のもとブラウン運動である。
  \begin{align*}
    d(DX) &= DdX + XdD \\
    &= D\left( \Delta dS + R(X-\Delta S)du - Cdu \right) - XRDdu \\
    &= D\Delta dS - \Delta Sdu - CDdu \\
    &= D\Delta (\alpha Sdu + \sigma SdW) - R\Delta Sdu - CDdu \\
    &= D\Delta\sigma SdW + D\Delta \alpha Sdu - R\Delta Sdu - CDdu \\
    &= D\Delta\sigma SdW + DS\Delta (\alpha - R)du - CDdu \\
    &= D\Delta\sigma S(d\tilde{W} - \Theta du)
    + DS\Delta (\alpha - R)du - CDdu \\
    &= D\Delta\sigma Sd\tilde{W} - D\Delta S\sigma \Theta du
    + DS\Delta (\alpha - R)du - CDdu \\
    &= D\Delta\sigma Sd\tilde{W} - CDdu
  \end{align*}
  となる。
  \(\int_0^T\)で積分して
  リスク中立測度で条件つき期待値\(\tilde{\E}[(-)|\mcF(t)]\)をとる。
  伊藤積分はマルチンゲールであるから、
  \begin{align*}
    D(T)X(T) - D(0)X(0)
    &= \int_0^t\Delta(u)\sigma(u) D(u)S(u)d\tilde{W}(u)
    - \E \left[ \int_0^TC(u)D(u)du \middle| \mcF(t)\right] \\
    &= \int_0^t\Delta(u)\sigma(u) D(u)S(u)d\tilde{W}(u) - \tilde{M}(t)
  \end{align*}
  となる。
  定義から\(\tilde{M}(t)\)はマルチンゲールなので、
  マルチンゲールの表現定理から
  \(d\tilde{M} = \tilde{\Gamma}d\tilde{W}\)
  となる\(\tilde{\Gamma}\)が存在する。
  従って、
  \[
  \tilde{M}(t) - \tilde{M}(0) = \int_0^t\tilde{\Gamma}(u)d\tilde{W}(u)
  \]
  であり、代入すれば
  \[
  \int_0^t\left(\Delta(u)\sigma(u) D(u)S(u)
  - \tilde{\Gamma}(u) \right)d\tilde{W}(u)
  + \tilde{M}(0)
  = D(T)X(T) - D(0)X(0)
  \]
  がわかる。
  この等式から、
  \(\Delta \dfn \tilde{\Gamma} / \sigma DS\)と定めると、
  確定値\(X(0) = \tilde{M}(0) / D(0)\)に対して
  ほとんど確実に\(X(T)=0\)となることがわかる。
\end{proof}



\begin{prob}\label{prob: 5.12}
  \begin{enumerate}
    \item \label{enumi: 5.12-1}
    \item \label{enumi: 5.12-2}
    \item \label{enumi: 5.12-3}
    \item \label{enumi: 5.12-4}
    \item \label{enumi: 5.12-5}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.12-1}と\ref{enumi: 5.12-3}。
  まず\(dB_i = \sum_{j=1}^d \sigma_{ij}/\sigma_i dW_j\)
  と\(d\tilde{W}_j = dW_j + \Theta_j du\)であることから、
  \[
  d\tilde{B}_i = dB_i + \gamma_i du
  = \sum_{j=1}^d \frac{\sigma_{ij}}{\sigma_i} dW_j
  + \sum_{j=1}^d \frac{\sigma_{ij}\Theta_j}{\sigma_i} du
  = \sum_{j=1}^d \frac{\sigma_{ij}}{\sigma_i} (dW_j + \Theta_j du)
  = \sum_{j=1}^d \frac{\sigma_{ij}}{\sigma_i} d\tilde{W}_j
  \]
  となる。
  従って\(\tilde{B}_i\)はマルチンゲールである。
  また、
  \[
  d\tilde{B}_id\tilde{B}_j
  = \sum_{k_1=1}^d\sum_{k_2=1}^d
  \frac{\sigma_{ik_1}\sigma_{jk_2}}{\sigma_i\sigma_j}
  d\tilde{W}_{k_1}d\tilde{W}_{k_2}
  = \sum_{k=1}^d
  \frac{\sigma_{ik}\sigma_{jk}}{\sigma_i\sigma_j} (d\tilde{W}_k)^2
  = \rho_{ij} du
  \]
  となる。
  とくに\(i=j\)のときは\(\rho_{ij}=1\)であるから、
  各\(i\)について\(\tilde{B}_i\)はブラウン運動となる。

  \ref{enumi: 5.12-2}。
  \(d\tilde{B}_i = dB_i + \gamma_i dt\)であるから、
  \[
  RS_i + \sigma_iS_i\gamma_i = \alpha_iS_i
  \]
  を示せば十分である。
  \(\gamma_i = \sum_j\sigma_{ij}\Theta_j/\sigma_i\)であることから、
  \[
  S_i\sum_j\sigma_{ij}\Theta_j = (\alpha_i - R)S_i
  \]
  つまり
  \[\sum_j\sigma_{ij}\Theta_j = \alpha_i - R\]
  を示せば十分であるが、これはリスク市場価格方程式そのものであり、
  \(\Theta_j\)はこれを満たすようにとっている。

  \ref{enumi: 5.12-4}。
  \[
  d(B_iB_k) = B_idB_k + B_kdB_i + dB_idB_k
  = B_idB_k + B_kdB_i + \rho_{ik}du
  \]
  を\(\int_0^t\)で積分して確率測度\(\P\)で期待値をとると、
  \(dB_i\)は\(dW_i\)の線形和であるから、
  特に\(B_idB_k + B_kdB_i\)の積分の部分は期待値が\(0\)となり、
  また\(\rho\)が確定的であることから、
  \[
  \E[B_i(t)B_k(t)] = \int_0^t\rho_{ik}du
  \]
  となる。
  チルダをつけて同様のことを行えば
  \(\tilde{\E}[\tilde{B}_i(t)\tilde{B}_k(t)]
  = \int_0^t\rho_{ik}du\)
  もわかる。
  \(B_i(t),\tilde{B}_i(t)\)はそれぞれ
  \(\P, \tilde{\P}\)についてブラウン運動であるから、
  それぞれの測度に対して
  分散\(t\)であり、
  以上で相関が\(\frac{1}{t}\int_0^t\rho_{ik}du\)
  であることもわかる。

  \ref{enumi: 5.12-5}。
  \begin{align*}
    \E\left[B_1(t)B_2(t)\right]
    &= \E\left[\int_0^t\rho_{12}(u)du\right] \\
    &= \int_0^t\E\left[\mathrm{sign}\left( W_1(u) \right)\right] du \\
    &= \int_0^t\left( \P(W_1(u)\geq 0) - \P(W_1(u)<0)\right) du \\
    &= 0 \\
    \tilde{\E}\left[\tilde{B}_1(t)\tilde{B}_2(t)\right]
    &= \tilde{\E}\left[\int_0^t\rho_{12}(u)du\right] \\
    &= \int_0^t\tilde{\E}
    \left[\mathrm{sign}\left( W_1(u) \right)\right] du \\
    &= \int_0^t\left(
    \tilde{\P}(W_1(u)\geq 0) - \tilde{\P}(W_1(u)<0)\right) du \\
    &= \int_0^t\left(
    \tilde{\P}(\tilde{W}_1(u)\geq u)
    - \tilde{\P}(\tilde{W}_1(u) < u)\right) du \\
    &= - \int_0^t \frac{1}{\sqrt{2\pi u}}\int_{-u}^ue^{-s^2/2u}dsdu \\
    &> 0
  \end{align*}
  である。
\end{proof}


\begin{prob}\label{prob: 5.13}
  \begin{enumerate}
    \item \label{enumi: 5.13-1}
    \item \label{enumi: 5.13-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.13-1}。
  \(\tilde{W}_1=W_1\)であるから\(\tilde{\E}W_1(t) = 0\)なのは良い。
  これを用いれば
  \[
  \tilde{\E}W_2(t) = \tilde{\E}\tilde{W}_2(t)
  - \int_0^t\tilde{\E}W_1(u)du = 0 - 0 = 0
  \]
  となる。

  \ref{enumi: 5.13-2}。
  \(dW_2= d\tilde{W}_2 - W_1du\)に注意すると、
  \[
  d(W_1W_2) = W_1dW_2 + W_2dW_1
  = W_1 (d\tilde{W}_2 - W_1du) + W_2 d\tilde{W}_1
  = W_1 d\tilde{W}_2 + W_2d\tilde{W}_1 - W_1^2du
  \]
  となる。
  これを\(\int_0^T\)で積分して
  \(\tilde{\E}\)で期待値を取れば、
  伊藤積分の部分は消えるので、
  \[
  \tilde{\E}[W_1(T)W_2(T)]
  = \tilde{\E}\left[ -\int_0^TW_1^2(u)du\right]
  = -\int_0^T\tilde{\E}\left[ W_1^2(u)\right] du
  = -\int_0^Tu du
  = -\frac{1}{2}T^2
  \]
  となる。
\end{proof}


\begin{prob}\label{prob: 5.14}
  \begin{enumerate}
    \item \label{enumi: 5.14-1}
    \item \label{enumi: 5.14-2}
    \item \label{enumi: 5.14-3}
    \item \label{enumi: 5.14-4}
    \item \label{enumi: 5.14-5}
    \item \label{enumi: 5.14-6}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 5.14-1}。
  \begin{align*}
    d(e^{-rt}X)
    &= e^{-rt}dX - rXe^{-rt}dt \\
    &= - rXe^{-rt}dt
    + e^{-rt}\left( \Delta dS - a\Delta dt + r(X-\Delta S) dt \right) \\
    &= e^{-rt}\left( \Delta \left( rSdt + \sigma Sd\tilde{W} + at \right)
    - a\Delta dt - r\Delta S dt \right) \\
    &= e^{-rt} \Delta \sigma Sd\tilde{W}
  \end{align*}
  となるので\(e^{-rt}X\)はマルチンゲールである。

  \ref{enumi: 5.14-2}。
  指数の中身を\(Y'\)として\(Y=e^{Y'}\)とおく。
  \(dY' = \sigma d\tilde{W} + \left( r-\frac{1}{2}\sigma^2 \right)dt\)
  であるから、
  \((dY')^2 = \sigma^2 dt\)であり、
  \begin{align*}
    dY
    &= e^{Y'}dY' + \frac{1}{2}e^{Y'}(dY')^2 \\
    &= Y\sigma d\tilde{W}
    + Y\left( r-\frac{1}{2}\sigma^2 \right)dt
    + \frac{1}{2}Y\sigma^2dt \\
    &= rY dt + \sigma Yd\tilde{W}
  \end{align*}
  となる。これは所望の結果である。
  また、\(e^{-rt}\)を割り引くと、
  \begin{align*}
    d(e^{-rt}Y)
    &= e^{-rt}dY - re^{-rt}Ydt \\
    &= e^{-rt}\left( rY dt + \sigma Yd\tilde{W} \right) - re^{-rt}Ydt \\
    &= e^{-rt}\sigma Yd\tilde{W}
  \end{align*}
  となって\(e^{-rt}Y\)はマルチンゲールである。
  最後に式(5.9.8)で定められた\(S\)が式(5.9.7)を満たすことを確認する。
  \(Y > 0\)であるから、\(Y\)で割れば、
  \[
  d\left( \frac{S}{Y}\right) = \frac{a}{Y}dt
  \]
  となる。とくに\(Yd\left( \frac{S}{Y}\right) = adt\)である。
  左辺を計算するために、まず\(d\left( \frac{1}{Y}\right)\)を計算すると、
  \((dY^2) = \sigma^2Y^2dt\)であるから、
  \begin{align*}
    d\left( \frac{1}{Y} \right)
    &= \frac{-1}{Y^2}dY + \frac{1}{2} 2\frac{1}{Y^3} (dY)^2 \\
    &= \frac{-1}{Y}\left( rdt + \sigma d\tilde{W} \right)
    + \frac{\sigma^2}{Y} dt
  \end{align*}
  となる。
  とくに
  \[
  Yd\left( \frac{1}{Y}\right)
  = (-r + \sigma^2) dt - \sigma d\tilde{W}
  \]
  である。
  従って、
  \begin{align*}
    Yd\left( \frac{S}{Y} \right)
    &= SYd\left( \frac{1}{Y} \right) + dS +
    Yd\left( \frac{1}{Y} \right)dS \\
    &= S\left( (-r + \sigma^2) dt - \sigma d\tilde{W} \right)
    + dS
    + \left( (-r + \sigma^2) dt - \sigma d\tilde{W} \right) dS \\
    &= S\left( (-r + \sigma^2) dt - \sigma d\tilde{W} \right)
    + dS - \sigma d\tilde{W}dS \\
  \end{align*}
  となる。
  よって
  \[
  adt =
  S\left( (-r + \sigma^2) dt - \sigma d\tilde{W} \right)
  + dS - \sigma d\tilde{W}dS
  \]
  となる。
  \(d\tilde{W}dS\)を計算するために、
  この等式の両辺に\(d\tilde{W}\)をかけると、
  \[
  0 = - \sigma S (d\tilde{W})^2 + d\tilde{W}dS
  = - \sigma S dt + d\tilde{W}dS
  \]
  となるので、\(d\tilde{W}dS = \sigma S dt\)がわかる。
  これを代入して、
  \[
  adt =
  S\left( (-r + \sigma^2) dt - \sigma d\tilde{W} \right)
  + dS - \sigma ^2 S dt
  = -rS dt - \sigma Sd\tilde{W} + dS
  \]
  となるので、整理すれば
  \[
  dS = rSdt + \sigma S d\tilde{W} + adt
  \]
  となり、所望の等式を得る。

  \ref{enumi: 5.14-3}。
  式(5.9.9)は式(5.9.8)を
  \(\int_0^T = \int_0^t + \int_t^T\)で積分することで得られるものである。
  式(5.9.9)を整理する。
  \(e^{-rt}Y(t)\)は\(\tilde{\P}\)についてマルチンゲールなので
  \(
  \tilde{\E}\left[ e^{-rT}Y(T) \middle| \mcF(t)\right]
  = e^{-rt}Y(t)
  \)
  であり、従って
  \[\tilde{\E}[Y(T)\mid \mcF(t)] = e^{r(T-t)}Y(t)\]
  となる。
  また、\(t\leq s\leq T\)について\(Y(T)/Y(s)\)を計算すると、
  \begin{align*}
    \frac{Y(T)}{Y(s)}
    &= \exp \left( \sigma (\tilde{W}(T) - \tilde{W}(s))
    + \left( r-\frac{1}{2}\sigma^2 \right) (T-s)\right)
  \end{align*}
  であるが、ここで
  \(\tilde{W}\)は\(\tilde{\P}\)に関してブラウン運動であるため、
  \(t\leq s \leq T\)であることから、
  \(\tilde{W}(T) - \tilde{W}(s)\)は\(\mcF(t)\)と独立である。
  とくに\(Y(T)/Y(s)\)も\(\mcF(t)\)と独立であることがわかり、
  \begin{align*}
    \tilde{\E}\left[ \frac{Y(T)}{Y(s)} \middle| \mcF(t) \right]
    &= \tilde{\E} \left[ \frac{Y(T)}{Y(s)} \right] \\
    &= e^{\left( r-\frac{1}{2}\sigma^2 \right) (T-s)}
    \tilde{\E} \left[
    e^{\sigma (\tilde{W}(T) - \tilde{W}(s))}\right] \\
    &= e^{\left( r-\frac{1}{2}\sigma^2 \right) (T-s)}
    \frac{1}{\sqrt{2\pi (T-s)}}
    \int_{-\infty}^\infty e^{\sigma x}e^{-x^2/2(T-s)}dx \\
    &= e^{\left( r-\frac{1}{2}\sigma^2 \right) (T-s)
    + \frac{1}{2}\sigma^2(T-s)}
    \frac{1}{\sqrt{2\pi (T-s)}}
    \int_{-\infty}^\infty e^{-(x-\sigma(T-s))^2/2(T-s)}dx \\
    &= e^{r(T-s)}
    \frac{1}{\sqrt{2\pi}}
    \int_{-\infty}^\infty e^{-x^2/2}dx \\
    &= e^{r(T-s)}
  \end{align*}
  となることがわかる。
  以上より、
  \begin{align*}
    \tilde{\E} \left[S(T)\middle| \mcF(t)\right]
    &= S(0)\tilde{\E} \left[ Y(T)\middle| \mcF(t)\right]
    + \tilde{\E} \left[Y(T)\middle| \mcF(t)\right]
    \int_0^t\frac{a}{Y(s)}ds
    + a\int_t^T\tilde{\E} \left[
    \frac{Y(T)}{Y(s)}\middle| \mcF(t)\right] ds \\
    &= S(0)e^{r(T-t)}Y(t)
    + e^{r(T-t)}Y(t)\int_0^t\frac{a}{Y(s)}ds
    + a\int_t^T e^{r(T-s)} ds \\
    &= e^{r(T-t)}S(t)
    + \frac{a}{r}(e^{r(T-t)}-1)
  \end{align*}
  となる。

  \ref{enumi: 5.14-4}。
  \(dS = rSdt + \sigma Sd\tilde{W} + adt\)であるから、
  \begin{align*}
    d\left( \tilde{\E} \left[S(T)\middle| \mcF(t)\right] \right)
    &= d\left( e^{r(T-t)}S
    + \frac{a}{r}(e^{r(T-t)}-1)\right) \\
    &= -re^{r(T-t)}Sdt + e^{r(T-t)}dS - ae^{r(T-t)}dt \\
    &= -re^{r(T-t)}Sdt
    + e^{r(T-t)}(rSdt + \sigma Sd\tilde{W} + adt)
    - ae^{r(T-t)}dt \\
    &= \sigma Se^{r(T-t)}d\tilde{W}
  \end{align*}
  となって
  \(\tilde{\E} \left[S(T)\middle| \mcF(t)\right]\)
  はマルチンゲールであることがわかる。

  \ref{enumi: 5.14-5}。
  \(\mathrm{Fut}_S(t,T) = \tilde{\E}\left[ S(T) \middle| \mcF(t)\right]\)
  なので、
  \begin{align*}
    \tilde{\E}\left[e^{-r(T-t)}\left( S(T)-K \right)
    \middle| \mcF(t) \right]
    &= e^{-r(T-t)}\left(
    \tilde{\E}\left[ S(T) \middle| \mcF(t)\right] - K \right) \\
    &= e^{-r(T-t)}\left( \mathrm{Fut}_S(t,T) - K  \right)
  \end{align*}
  であるが、ここで
  \(K=\mathrm{For}_S(t,T)\)とすると、
  \[
  \tilde{\E}\left[e^{-r(T-t)}\left( S(T)-K \right)
  \middle| \mcF(t) \right] = 0
  \]
  より
  \[
  \mathrm{Fut}_S(t,T) = K = \mathrm{For}_S(t,T)
  \]
  を得る。

  \ref{enumi: 5.14-6}。
  \[
  \begin{cases}
    &dX = dS - adt + r(X-S)dt, \\
    &X(0) = 0,
  \end{cases}
  \]
  を解く。
  \(d(e^{-rt}S) = e^{-rt}dS - re^{-rt}Sdt\)に注意すると、
  \begin{align*}
    d(e^{-rt}X) &= e^{-rt}dX - re^{-rt}Xdt \\
    &= e^{-rt}\left( dS - adt + r(X-S)dt\right) - re^{-rt}Xdt \\
    &= e^{-rt}\left( dS - adt - rSdt\right) \\
    &= d(e^{-rt}S) - ae^{-rt}dt
  \end{align*}
  となる。
  これを\(\int_0^T\)で積分すると、
  \[
  e^{-rT}X(T) = e^{-rT}S(T) - S(0) - \frac{a}{r}(1-e^{-rT})
  \]
  となる。
  従って
  \[
  X(T) = S(T) - e^{rT}\left( S(0) + \frac{a}{r}(1-e^{-rT})\right)
  \]
  となる。
  次に\(\mathrm{For}_S(0,T)\)を求める。
  \ref{enumi: 5.14-5}より
  \(\mathrm{For}_S(t,T) = \mathrm{Fut}_S(t,T)\)なので、
  \ref{enumi: 5.14-3}より
  \begin{align*}
    \mathrm{For}_S(t,T)
    &= \mathrm{Fut}_S(t,T) \\
    &= \tilde{\E}[S(T)\mid\mcF(t)] \\
    &= e^{r(T-t)}S(t)
    + \frac{a}{r}(e^{r(T-t)}-1)
  \end{align*}
  となる。
  とくに
  \[
  \mathrm{For}_S(0,T) =
  e^{rT}\left( S(0) + \frac{a}{r}(1-e^{-rT})\right)
  \]
  となる。
  以上より\(X(T) = S(T) - \mathrm{For}_S(0,T)\)となる。

\end{proof}









\newpage

\section{偏微分方程式との関係}\label{section: 6}



\begin{prob}\label{prob: 6.1}
  \begin{enumerate}
    \item \label{enumi: 6.1-1}
    \item \label{enumi: 6.1-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.1-1}。
  \(u=t\)とすれば\(\int_t^u=\int_t^t=0\)であるから\(Z(t)=e^0=1\)である。
  \(Z=e^{Z'}\)となる\(Z'\)をとれば、
  \(d(Z') = \sigma dW + \left( b-\frac{1}{2}\sigma^2\right) du\)
  であるから、
  \begin{align*}
    dZ &= d(e^{Z'}) \\
    &= e^{Z'}d(Z') + \frac{1}{2}e^{Z'} (d(Z'))^2 \\
    &= Z\left( \sigma dW + \left( b-\frac{1}{2}\sigma^2\right) du \right)
    + \frac{1}{2}Z\left( \sigma dW
    + \left( b-\frac{1}{2}\sigma^2\right) du \right)^2 \\
    &= \sigma Z dW + \left( b-\frac{1}{2}\sigma^2\right) Zdu
    + \frac{1}{2}Z\sigma^2(dW)^2 \\
    &= \sigma Z dW + \left( b-\frac{1}{2}\sigma^2\right) Zdu
    + \frac{1}{2}Z\sigma^2du \\
    &= \sigma ZdW + bZ du
  \end{align*}
  となる。これは所望の等式である。

  \ref{enumi: 6.1-2}。
  \(X=YZ\)とおけば
  \begin{align*}
    dX &= YdZ + ZdY + dYdZ \\
    &= Y\left( \sigma ZdW + bZ du \right)
    + Z\left( \frac{a-\sigma\gamma}{Z}du + \frac{\gamma}{Z}dW \right)
    + \left( \frac{a-\sigma\gamma}{Z}du + \frac{\gamma}{Z}dW \right)
    \left( \sigma ZdW + bZ du \right) \\
    &= \sigma YZdW + bYZ du
    + \left(a-\sigma\gamma\right) du + \gamma dW
    + \left( \left(a-\sigma\gamma \right)du + \gamma dW \right)
    \left( \sigma dW + b du \right) \\
    &= \sigma XdW + bX du
    + \left(a-\sigma\gamma\right) du + \gamma dW
    + \gamma \sigma (dW)^2  \\
    &= (\gamma + \sigma X)dW + (a + bX) du
  \end{align*}
  となって所望の等式を得る。
\end{proof}


\begin{prob}\label{prob: 6.2}
  \begin{enumerate}
    \item \label{enumi: 6.2-1}
    \item \label{enumi: 6.2-2}
    \item \label{enumi: 6.2-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.2-1}。
  債券の価格は\(f(t,R(t),T)\)であるから、
  このポートフォリオ\(X(t)\)の満たす方程式は
  \begin{align*}
    dX(t)
    &= \Delta_1(t)df(t,R(t),T_1)
    + \Delta_2(t)df(t,R(t),T_2) \\
    &\ \ \ \ \ \ \ \
    + R(t)\left( X(t) - \Delta_1(t)f(t,R(t),T_1)
    - \Delta_2(t)f(t,R(t),T_2) \right)dt
  \end{align*}
  である。
  \(df(t,R(t),T)\)を計算すれば、
  \(\left( dR(t) \right)^2 = \gamma^2(t,R(t))dt\)であるから、
  \begin{align*}
    df(t,R(t),T)
    &= f_t(t,R(t),T)dt + f_r(t,R(t),T)dR(t)
    + \frac{1}{2}f_{r,r}(t,R(t),T)\left( dR(t)\right)^2 \\
    &= f_t(t,R(t),T)dt
    + f_r(t,R(t),T)\left( \alpha(t,R(t))dt + \gamma(t,R(t))dW(t)\right) \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}f_{r,r}(t,R(t),T)\gamma^2(t,R(t))dt \\
    &= \left( f_t(t,R(t),T)
    + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T) \right)dt \\
    &\ \ \ \ \ \ \ \
    + \alpha(t,R(t))f_r(t,R(t),T)dt
    + \gamma(t,R(t))f_r(t,R(t),T)dW(t) \\
    &= \left( R(t)f(t,R(t),T) - \beta(t,R(t),T) \right)dt \\
    &\ \ \ \ \ \ \ \
    + \alpha(t,R(t))f_r(t,R(t),T)dt
    + \gamma(t,R(t))f_r(t,R(t),T)dW(t) \\
    &= \left( R(t)f(t,R(t),T)
    + \left( \alpha(t,R(t))
    - \beta(t,R(t),T)\right)f_r(t,R(t),T) \right)dt \\
    &\ \ \ \ \ \ \ \
    + \gamma(t,R(t))f_r(t,R(t),T)dW(t)
  \end{align*}
  となる。
  とくに
  \begin{align*}
    &\Delta_1(t)df(t,R(t),T_1) + \Delta_2(t)df(t,R(t),T_2) \\
    &= \Delta_1(t)\left( R(t)f(t,R(t),T_1)
    + \left( \alpha(t,R(t))
    - \beta(t,R(t),T_1)\right)f_r(t,R(t),T_1) \right)dt \\
    &\ \ \ \ \ \ \ \
    + \Delta_1(t)\gamma(t,R(t))f_r(t,R(t),T_1)dW(t) \\
    &\ \ \ \ \ \ \ \ + \Delta_2(t)\left( R(t)f(t,R(t),T_2)
    + \left( \alpha(t,R(t))
    - \beta(t,R(t),T_2)\right)f_r(t,R(t),T_2) \right)dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + \Delta_2(t)\gamma(t,R(t))f_r(t,R(t),T_2)dW(t) \\
    &= R(t)f(t,R(t),T_1) \left( \Delta_1(t) + \Delta_2(t)\right) dt \\
    &\ \ \ \ \ \ \ \
    + \Delta_1(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_1)\right)f_r(t,R(t),T_1) dt \\
    &\ \ \ \ \ \ \ \
    + \Delta_2(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_2)\right)f_r(t,R(t),T_2)dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + \gamma(t,R(t)) \left( \Delta_1(t)f_r(t,R(t),T_1)
    + \Delta_2(t)f_r(t,R(t),T_2) \right) dW(t)
  \end{align*}
  となる。
  割引過程\(D(t) = e^{-\int_0^tR(u)du}\)の微分は、
  \(dD=-DRdt\)であるから、
  \[
  d(DX) = DdX + XdD = DdX - RDXdt = D(dX-RXdt)
  \]
  となる。
  ここで\(X\)の満たす方程式から、
  \begin{align*}
    dX(t) - R(t)X(t)dt
    &= \Delta_1(t)df(t,R(t),T_1)
    + \Delta_2(t)df(t,R(t),T_2) \\
    &\ \ \ \ \ \ \ \
    - R(t)f(t,R(t),T_2)\left( \Delta_1(t) + \Delta_2(t)\right)dt
  \end{align*}
  となるので、結局
  \begin{align*}
    d(D(t)X(t)) &= D(t)(dX(t)-R(t)X(t)dt)  \\
    &= D(t) \left( \Delta_1(t)df(t,R(t),T_1)
    + \Delta_2(t)df(t,R(t),T_2) \right) \\
    &\ \ \ \ \ \ \ \
    - R(t)D(t)f(t,R(t),T_2)
    \left( \Delta_1(t) + \Delta_2(t)\right)dt \\
    &= \Delta_1(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_1)\right)f_r(t,R(t),T_1) dt \\
    &\ \ \ \ \ \ \ \
    + \Delta_2(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_2)\right)f_r(t,R(t),T_2)dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + D(t)\gamma(t,R(t))\left( \Delta_1(t)f_r(t,R(t),T_1)
    + \Delta_2(t)f_r(t,R(t),T_2) \right) dW(t)
  \end{align*}
  となる。
  これは所望の等式である。

  \ref{enumi: 6.2-2}。
  \(\Delta_1(t) = S(t)f_r(t,R(t),T_2),
  \Delta_2(t) = - S(t)f_r(t,R(t),T_1)\)
  を代入すれば、
  \[\Delta_1(t)f_r(t,R(t),T_1) + \Delta_2(t)f_r(t,R(t),T_2) = 0\]
  であるから、
  \begin{align*}
    d(D(t)X(t))
    &= \Delta_1(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_1)\right)f_r(t,R(t),T_1) dt \\
    &\ \ \ \ \ \ \ \
    + \Delta_2(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_2)\right)f_r(t,R(t),T_2)dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + D(t)\gamma(t,R(t))\left( \Delta_1(t)f_r(t,R(t),T_1)
    + \Delta_2(t)f_r(t,R(t),T_2) \right) dW(t) \\
    &= S(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_1)\right)f_r(t,R(t),T_1)f_r(t,R(t),T_2) dt \\
    &\ \ \ \ \ \ \ \
    - S(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T_2)\right)f_r(t,R(t),T_1)f_r(t,R(t),T_2)dt \\
    &= S(t)D(t)\left( \beta(t,R(t),T_2) - \beta(t,R(t),T_1)
    \right)f_r(t,R(t),T_1)f_r(t,R(t),T_2) dt \\
    &= D(t)\left| \left(\beta(t,R(t),T_2) - \beta(t,R(t),T_1)
    \right)f_r(t,R(t),T_1)f_r(t,R(t),T_2)\right| dt
  \end{align*}
  となる。
  絶対値の中身を\(Y(t) \geq 0\)とおけば、
  \(D(0) = 1\)であるから、積分することで
  \[
  D(t)X(t) - X(0) = \int_0^tD(u)Y(u)du \geq 0
  \]
  を得る。
  これは
  \(\P(X(t) \geq X(0)/D(t)) = 1\)を示している。
  また、もしある\(t\)で
  \(\beta(t,R(t),T_1) \neq \beta(t,R(t),T_2)\)
  となれば\(Y(t) > 0\)となるので
  \(D(T)X(T) > X(0)\)となり、
  このことは裁定機会を生じさせることを意味する
  (\autoref{prob: 5.7} \ref{enumi: 5.7-2})。
  従ってすべての\(t\)で
  \(\beta(t,R(t),T_1) = \beta(t,R(t),T_2)\)
  となることがわかる。

  \ref{enumi: 6.2-3}。
  問題文がよくわからないが、
  保有債券数が\(\Delta(t)\)のポートフォリオ\(X(t)\)を考えているはず。
  つまり\(X(t)\)は次を満たす：
  \[
  dX(t) = \Delta(t) df(t,R(t),T)
  + R(t)\left( X(t) - \Delta(t)f(t,R(t),T)\right)dt.
  \]
  \ref{enumi: 6.2-2}で得たいろいろな計算結果をそのまま用いる。
  \begin{align*}
    df(t,R(t),T)
    &= \left( R(t)f(t,R(t),T)
    + \left( \alpha(t,R(t))
    - \beta(t,R(t),T)\right)f_r(t,R(t),T) \right)dt \\
    &\ \ \ \ \ \ \ \
    + \gamma(t,R(t))f_r(t,R(t),T)dW(t)
  \end{align*}
  であるから、
  \begin{align*}
    &dX(t) - R(t)X(t)dt \\
    &= \Delta(t) \left( df(t,R(t),T) - R(t) f(t,R(t),T) \right) dt \\
    &= \Delta(t) \left( \left( \alpha(t,R(t))
    - \beta(t,R(t),T)\right)f_r(t,R(t),T) dt
    + \gamma(t,R(t)) f_r(t,R(t),T) dW(t)\right)
  \end{align*}
  となるので、
  \begin{align*}
    &d(D(t)X(t)) \\
    &= D(t)(dX(t)-R(t)X(t)dt) \\
    &= \Delta(t)D(t)\left( \alpha(t,R(t))
    - \beta(t,R(t),T)\right)f_r(t,R(t),T) dt
    + D(t)\Delta(t)\gamma(t,R(t))f_r(t,R(t),T) dW(t)
  \end{align*}
  となる。
  ここで\(\beta\)の定義 (式(6.9.2)または式(6.9.3)) より
  \begin{align*}
    &\left( \alpha(t,R(t)) - \beta(t,R(t),T)\right)f_r(t,R(t),T) \\
    &= \alpha(t,R(t))f_r(t,R(t),T) - R(t)f(t,R(t),T)
    + f_t(t,R(t),T) + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T)
  \end{align*}
  であるから、以上を代入することで所望の等式(6.9.5)を得る。

  \(f_r(t,r,T)=0\)とする。すると
  \begin{align*}
    &d(D(t)X(t)) \\
    &= D(t)(dX(t)-R(t)X(t)dt) \\
    &= \Delta(t)D(t)\left( - R(t)f(t,R(t),T)
    + f_t(t,R(t),T) + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T)
    \right) dt
  \end{align*}
  であるから、積分すれば
  \begin{align*}
    &D(T)X(T)  \\
    &= X(0) + \int_0^T \Delta(t)D(t)\left( - R(t)f(t,R(t),T)
    + f_t(t,R(t),T) + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T)
    \right) dt
  \end{align*}
  となる。
  保有債券数\(\Delta(t)\)を調節して
  \(X\)を裁定機会のあるポートフォリオとすることを考える。
  そのためには、右辺の積分の中身が\(\geq 0\)であり、
  またある\(t\)に対して\(>0\)となれば良い
  そうするためには
  \[
  \Delta(t) = \mathrm{sign}\left( D(t)\left( - R(t)f(t,R(t),T)
  + f_t(t,R(t),T) + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T)
  \right)\right)
  \]
  とすればよく、
  このとき\(X\)に裁定機会があることと
  \[
  R(t)f(t,R(t),T)
  = f_t(t,R(t),T) + \frac{1}{2}\gamma^2(t,R(t))f_{r,r}(t,R(t),T)
  \]
  は同値となる。
\end{proof}



\begin{prob}\label{prob: 6.3}
  \begin{enumerate}
    \item \label{enumi: 6.3-1}
    \item \label{enumi: 6.3-2}
    \item \label{enumi: 6.3-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.3-1}。
  \begin{align*}
    \frac{d}{ds}\left[ e^{-\int_0^sb(v)dv}C(s,T) \right]
    &= e^{-\int_0^sb(v)dv}\frac{d}{ds}C(s,T)
    - b(v)e^{-\int_0^sb(v)dv}C(s,T) \\
    &= e^{-\int_0^sb(v)dv}\left( b(s)C(s,T) - 1\right)
    - b(s)e^{-\int_0^sb(v)dv}C(s,T) \\
    &= -e^{-\int_0^sb(v)dv}.
  \end{align*}

  \ref{enumi: 6.3-2}。
  \begin{align*}
    - e^{-\int_0^tb(v)dv}C(t,T)
    &= e^{-\int_0^Tb(v)dv}C(T,T) - e^{-\int_0^tb(v)dv}C(t,T) \\
    &= \int_t^T \frac{d}{ds}\left[ e^{-\int_0^sb(v)dv}C(s,T) \right] ds \\
    &= - \int_t^T e^{-\int_0^sb(v)dv} ds
  \end{align*}
  であるから両辺に\(-e^{\int_0^tb(v)dv}\)をかけることで
  \[
  C(t,T) = \int_t^T e^{-\int_t^sb(v)dv} ds,
  \]
  つまり式(6.5.10)を得る。

  \ref{enumi: 6.3-3}。
  これは示すべきことが問題文中に書かれている。
\end{proof}


\begin{prob}\label{prob: 6.4}
  \begin{enumerate}
    \item \label{enumi: 6.4-1}
    \item \label{enumi: 6.4-2}
    \item \label{enumi: 6.4-3}
    \item \label{enumi: 6.4-4}
    \item \label{enumi: 6.4-5}
    \item \label{enumi: 6.4-6}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.4-1}。
  \(\int_t^TC(t,T)du = \log\left( \frac{2}{\sigma^2}\varphi(t)\right)\)
  なので、
  \[
  C(t,T) = - \frac{2\varphi'(t)}{\sigma^2\varphi(t)}
  \]
  となり、また
  \begin{align*}
    C'(t,T)
    &= - \frac{2\left( \varphi''(t)\varphi(t) - (\varphi'(t))^2\right)}
    {\sigma^2\varphi^2(t)} \\
    &= - \frac{2\varphi''(t)}{\sigma^2\varphi(t)}
    + \frac{1}{2}\sigma^2\left(
    \frac{2\varphi'(t)))}{\sigma^2\varphi(t)} \right)^2 \\
    &= - \frac{2\varphi''(t)}{\sigma^2\varphi(t)}
    + \frac{1}{2}\sigma^2C^2(t,T)
  \end{align*}
  となる。

  \ref{enumi: 6.4-2}。
  式(5.6.14)を
  \[
  C'(t,T) - \frac{1}{2}\sigma^2C^2(t,T) = bC(t,T) - 1
  \]
  と書き直すと、左辺は\ref{enumi: 6.4-1}の結果より
  \[
  - \frac{2\varphi''(t)}{\sigma^2\varphi(t)}
  \]
  であり、右辺は\ref{enumi: 6.4-1}の結果より
  \[
  - b\frac{2\varphi'(t)}{\sigma^2\varphi(t)} - 1
  \]
  であるから、
  以上より
  \[
  \frac{2\varphi''(t)}{\sigma^2\varphi(t)}
  = b\frac{2\varphi'(t)}{\sigma^2\varphi(t)} + 1
  \]
  となって、
  両辺に\(\frac{1}{2}\sigma^2\varphi(t)\)
  をかけて整理することで所望の等式を得る。

  \ref{enumi: 6.4-3}。
  線形常微分方程式の解は指数関数の線形和であるから、
  その係数などを求めれば良い。
  \(\varphi(t) = a_1e^{\lambda_1t} + a_2e^{\lambda_2t}\)
  とおくと、
  \begin{align*}
    &\varphi'(t)
    = a_1\lambda_1e^{\lambda_1t} + a_2\lambda_2e^{\lambda_2t}  \\
    &\varphi''(t)
    = a_1\lambda_1^2e^{\lambda_1t} + a_2\lambda_2^2e^{\lambda_2t}
  \end{align*}
  であるから、\ref{enumi: 6.4-2}で得た方程式に代入して
  \(e^{\lambda_1t},e^{\lambda_2t}\)の係数を比較すると、
  \(i=1,2\)に対して
  \[
  \lambda_i^2 - b\lambda_i - \frac{1}{2}\sigma^2 = 0
  \]
  となる。
  この方程式の解は
  \[
  \lambda_i
  = \frac{b}{2} \pm \sqrt{b^2+2\sigma^2}
  = \frac{b}{2} \pm \gamma
  \]
  である。
  従って\ref{enumi: 6.4-2}で得た方程式の解はすべて、
  ある定数\(a_1,a_2\)により
  \[
  \varphi = a_1e^{\frac{b}{2}t + \gamma t}
  + a_2e^{\frac{b}{2}t - \gamma t}
  \]
  とかける。
  \(e^{T\left( \frac{b}{2} \pm \gamma \right)}\)
  を\(a_1,a_2\)にかけて定数倍で置き換えれば所望の結果を得る。

  \ref{enumi: 6.4-4}。
  \ref{enumi: 6.4-3}の結果を微分すれば\(\varphi'(t)\)が求まる。
  式(6.9.8)で\(t=T\)とすれば\(\varphi'(T)=0\)であるから
  \(c_1=c_2\)を得る。

  \ref{enumi: 6.4-5}。
  計算を実行するのみ。

  \ref{enumi: 6.4-6}。
  \(A(T,T)=0\)を用いれば、
  \[
  A(t,T) = -\frac{2a}{\sigma^2}
  \int_t^T \left( \log\varphi(t) \right)' ds
  = -\frac{2a}{\sigma^2}\log\frac{\varphi(T)}{\varphi(t)}
  \]
  である。
  これに\ref{enumi: 6.4-5}の結果を代入すれば良い。
\end{proof}








\begin{prob}\label{prob: 6.5}
  \begin{enumerate}
    \item \label{enumi: 6.5-1}
    \item \label{enumi: 6.5-2}
    \item \label{enumi: 6.5-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.5-1}。
  本文では述べられていないが、定理6.3.1の多次元版がある？
  それを用いると
  \(\E[h(X_1(T),X_2(T)\mid \mcF(s)] = g(s,X_1(s),X_2(s))\)
  であるからマルチンゲール性は反復条件付きの性質より従う。
  割引かれていても同じ。

  \ref{enumi: 6.5-2}。
  \begin{align*}
    &(dX_1)^2
    = \gamma_{1,1}^2dt + \gamma_{1,2}^2dt \\
    &(dX_2)^2
    = \gamma_{2,1}^2dt + \gamma_{2,2}^2dt \\
    &dX_1dX_2
    = \gamma_{1,1}\gamma_{2,1}dt + \gamma_{1,2}\gamma_{2,2}dt
  \end{align*}
  であるから、
  \begin{align*}
    &dg(t,X_1(t),X_2(t)) \\
    &= g_tdt
    + g_{x_1}dX_1 + g_{x_2}dX_2 \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}g_{x_1,x_1}(dX_1)^2
    + g_{x_1,x_2}dX_1dX_2
    + \frac{1}{2}g_{x_2,x_2}(dX_2)^2 \\
    &= g_tdt
    + g_{x_1}\left( \beta_1dt + \gamma_{1,1}dW_1 + \gamma_{1,2}dW_2\right)
    + g_{x_2}\left( \beta_2dt + \gamma_{2,1}dW_1 + \gamma_{2,2}dW_2\right) \\
    &\ \ \ \ \ \ \ \
    + \left( \frac{1}{2}g_{x_1,x_1}
    \left( \gamma_{1,1}^2 + \gamma_{1,2}^2\right)
    + g_{x_1,x_2}\left( \gamma_{1,1}\gamma_{2,1}
    + \gamma_{1,2}\gamma_{2,2}\right)
    + \frac{1}{2}g_{x_2,x_2}
    \left( \gamma_{2,1}^2 + \gamma_{2,2}^2\right) \right) dt
  \end{align*}
  となる。
  \(dt\)の係数は
  \begin{align*}
    &g_t + g_{x_1}\beta_1 + g_{x_2}\beta_2 \\
    &\ \ \ \ \ \ \ +
    \frac{1}{2}g_{x_1,x_1}
    \left( \gamma_{1,1}^2 + \gamma_{1,2}^2\right)
    + g_{x_1,x_2}\left( \gamma_{1,1}\gamma_{2,1}
    + \gamma_{1,2}\gamma_{2,2}\right)
    + \frac{1}{2}g_{x_2,x_2}
    \left( \gamma_{2,1}^2 + \gamma_{2,2}^2\right)
  \end{align*}
  であり、これが\(=0\)となる方程式は
  式(6.6.3)そのものである。
  同じく、
  \(f(t,X_1(t),X_2(t)) = e^{-r(T-t)}g(t,X_1(t),X_2(t))\)であるから、
  \[
  d(e^{-r(T-t)}g) = -re^{-r(T-t)}gdt + e^{-r(T-t)}dg
  = -r fdt + e^{-r(T-t)}dg
  \]
  となるが、
  \(f_t = -rf + f = -rf + e^{-r(T-t)}g\)と
  \(f_{x_i} = e^{-r(T-t)}g_{x_i},
  f_{x_i,x_j} = e^{-r(T-t)}g_{x_i,x_j}\)
  に注意すれば、\(dg\)の計算結果より
  \(f\)の満たす偏微分方程式(6.6.4)が求まる。

  \ref{enumi: 6.5-3}。
  \ref{enumi: 6.5-2}の最後の議論と同じく、
  式(6.6.14)は式(6.6.13)より導かれる。
  よって式(6.6.13)を示せば良い。
  \begin{align*}
    &(dX_1)^2
    = \gamma_{1,1}^2dt + \gamma_{1,2}^2dt
    + \rho \gamma_{1,1}\gamma_{1,2}dt \\
    &(dX_2)^2
    = \gamma_{2,1}^2dt + \gamma_{2,2}^2dt
    + \rho \gamma_{2,1}\gamma_{2,2}dt \\
    &dX_1dX_2
    = \gamma_{1,1}\gamma_{2,1}dt + \gamma_{1,2}\gamma_{2,2}dt
    + \rho (\gamma_{1,1}\gamma_{2,2} + \gamma_{1,2}\gamma_{2,1}) dt
  \end{align*}
  であるから、
  \begin{align*}
    &dg(t,X_1(t),X_2(t)) \\
    &= g_tdt
    + g_{x_1}dX_1 + g_{x_2}dX_2 \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}g_{x_1,x_1}(dX_1)^2
    + g_{x_1,x_2}dX_1dX_2
    + \frac{1}{2}g_{x_2,x_2}(dX_2)^2 \\
    &= g_tdt
    + g_{x_1}\left( \beta_1dt + \gamma_{1,1}dW_1 + \gamma_{1,2}dW_2\right)
    + g_{x_2}\left( \beta_2dt + \gamma_{2,1}dW_1 + \gamma_{2,2}dW_2\right) \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}g_{x_1,x_1}
    \left( \gamma_{1,1}^2
    + \gamma_{1,2}^2
    + \rho \gamma_{1,1}\gamma_{1,2}\right)dt
    + \frac{1}{2}g_{x_2,x_2}\left( \gamma_{2,1}^2
    + \gamma_{2,2}^2
    + \rho \gamma_{2,1}\gamma_{2,2}\right) dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + g_{x_1,x_2}\left( \gamma_{1,1}\gamma_{2,1}
    + \gamma_{1,2}\gamma_{2,2}
    + \rho (\gamma_{1,1}\gamma_{2,2} + \gamma_{1,2}\gamma_{2,1}) \right) dt
  \end{align*}
  \(dt\)の係数を\(=0\)とすれば式(6.9.3)を得る。
\end{proof}











\begin{prob}\label{prob: 6.6}
  \begin{enumerate}
    \item \label{enumi: 6.6-1}
    \item \label{enumi: 6.6-2}
    \item \label{enumi: 6.6-3}
    \item \label{enumi: 6.6-4}
    \item \label{enumi: 6.6-5}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.6-1}。
  方程式は各\(j\)ごとに定まっているので、ここでは\(j\)を省略する。
  \(d(e^{\frac{b}{2}t}X(t))\)を計算すると、
  \begin{align*}
    d(e^{\frac{b}{2}t}X(t))
    &= \frac{b}{2}e^{\frac{b}{2}t}X(t)dt + e^{\frac{b}{2}t}dX(t) \\
    &= \frac{b}{2}e^{\frac{b}{2}t}X(t)dt
    + e^{\frac{b}{2}t}\left( -\frac{b}{2}X(t)
    + \frac{1}{2}\sigma dW\right) \\
    &= \frac{1}{2}e^{\frac{b}{2}t}\sigma dW \\
  \end{align*}
  となるので、これを\(\int_0^t\)で積分すれば
  \[
  e^{\frac{b}{2}t}X(t) - X(0)
  = \frac{\sigma}{2}\int_0^te^{\frac{b}{2}u}dW(u)
  \]
  が得られる。
  これを整理して所望の等式を得る。
  伊藤積分の項は正規確率変数となるので、
  \(X(t)\)は正規確率変数の定数倍に定数を足したものであるから、
  \(X(t)\)も正規確率変数である。
  期待値をこのまま計算すれば、
  伊藤積分の期待値は\(0\)なので
  \[
  \E[X(t)] = e^{-\frac{b}{2}t}X(0)
  \]
  となる。
  分散は、伊藤積分の等長性から、
  \begin{align*}
    \Var(X(t))
    &= \E[X^2(t)] - \E[X(t)]^2 \\
    &= e^{-bt}\left(X^2(0)
    + \sigma X(0)\E\left[ \int_0^te^{\frac{1}{2}bu}dW(u)\right]
    + \frac{\sigma^2}{4}\E\left[
    \left(\int_0^te^{\frac{1}{2}bu}dW(u)\right)^2 \right]
    \right) - e^{-bt}X^2(0) \\
    &= \frac{\sigma^2}{4}e^{-bt}\E\left[ \int_0^te^{bu}du \right]) \\
    &= \frac{\sigma^2}{4b}e^{-bt}(e^{bt}-1) \\
    &= \frac{\sigma^2}{4b}(1-e^{-bt})
  \end{align*}
  となる。これは所望の結果である。

  \ref{enumi: 6.6-2}。
  \(\sqrt{R}dB = \sum_j X_j dW_j\)であるから、
  \begin{align*}
    dR &= \sum_j d(X_j^2) \\
    &= \sum_j \left( 2X_jdX_j + (dX_j)^2 \right) \\
    &= \sum_j \left( 2X_j\left(
    - \frac{b}{2}X_j + \frac{1}{2}\sigma dW_j\right)
    + \frac{1}{4}\sigma^2\sum_j dt \right) \\
    &= - \sum_j bX_j^2dt + \frac{d}{4}\sigma^2dt
    + \sigma \sum_j X_jdW_j \\
    &= \left( \frac{1}{4}\sigma^2 + bR\right) dt + \sigma \sqrt{R}dB
  \end{align*}
  となる。
  \(a = \frac{d}{4}\sigma^2\)とすれば式(6.9.19)となる。
  また
  \begin{align*}
    (dB)^2
    &= \frac{1}{R}\sim_{j_1,j_2} X_{j_1}X_{j_2}dW_{j_1}dW_{j_2} \\
    &= \frac{1}{R}\sim_i X_i^2dt \\
    &= dt
  \end{align*}
  であるから\(B\)はブラウン運動である
  (\(B\)は伊藤積分の和なのでマルチンゲールである)。

  \ref{enumi: 6.6-3}。
  \ref{enumi: 6.6-1}よりまだ示されていないのは
  \(X_j\)たちの独立性だけであるが、
  それは\(W_j\)たちが独立であることから従う。

  \ref{enumi: 6.6-4}。
  \(\mu = \mu(t), v=v(t)\)と省略する。
  \(X\)は平均\(\mu\)で分散\(v\)の正規確率変数であるから、
  \begin{align*}
    &\E[e^{uX^2}] \\
    &= \frac{1}{\sqrt{2\pi v}}
    \int_{-\infty}^\infty \exp\left(
    ux^2 - \frac{1}{2v}(x-\mu)^2 \right)dx \\
    &= \frac{1}{\sqrt{2\pi v}}
    \int_{-\infty}^\infty \exp\left(
    - \frac{1-2uv}{2v}\left(x^2-\frac{2}{1-2uv}\mu x
    + \frac{1}{1-2uv}\mu^2\right) \right)dx \\
    &= \frac{1}{\sqrt{2\pi v}}
    \int_{-\infty}^\infty \exp\left(
    - \frac{1-2uv}{2v}\left(x-\frac{\mu}{1-2uv}\right)^2
    + \frac{1-2uv}{2v}\left( \frac{\mu}{1-2uv}\right)^2
    - \frac{1}{2v}\mu^2 ) \right)dx \\
    &= \frac{1}{\sqrt{2\pi v}}
    \int_{-\infty}^\infty \exp\left(
    - \frac{1-2uv}{2v}\left(x-\frac{\mu}{1-2uv}\right)^2
    + \frac{1}{2v}\mu^2\left( \frac{1}{1-2uv}-1 \right) \right)dx \\
    &= \frac{1}{\sqrt{2\pi v}}
    \int_{-\infty}^\infty \exp\left(
    - \frac{1-2uv}{2v}\left(x-\frac{\mu}{1-2uv}\right)^2
    + \frac{u}{1-2uv}\mu^2 \right)dx \\
    &= \frac{1}{\sqrt{2\pi v}}
    \exp\left(\frac{u}{1-2uv}\mu^2 \right)
    \int_{-\infty}^\infty \exp\left( - \frac{1-2uv}{2v}x^2\right) dx \\
    &= \frac{1}{\sqrt{1-2uv}}
    \exp\left(\frac{u}{1-2uv}\mu^2 \right)
  \end{align*}
  となる。これは所望の結果である。

  \ref{enumi: 6.6-5}。
  各\(X_j\)は独立なので\(X_j^2\)も独立である。
  あとは\ref{enumi: 6.6-4}の結果を掛け合わせることで所望の結果を得る。
\end{proof}


\begin{prob}\label{prob: 6.7}
  \begin{enumerate}
    \item \label{enumi: 6.7-1}
    \item \label{enumi: 6.7-2}
    \item \label{enumi: 6.7-3}
    \item \label{enumi: 6.7-4}
    \item \label{enumi: 6.7-5}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.7-1}。
  \[
  e^{-rt}c(t,S(t),V(t))
  = \tilde{\E}\left[ e^{-rT}c(T,S(T),V(T)) \middle| \mcF{t} \right]
  \]
  であるから反復条件付きの性質より
  \(e^{-rt}c(t,S(t),V(t))\)はマルチンゲールである。
  微分を計算する。
  \begin{align*}
    &(dS)^2 = VS^2dt,
    &(dV)^2 = \sigma^2Vdt,
    &dSdV = \sigma \rho SVdt,
  \end{align*}
  なので、
  \begin{align*}
    d(e^{-rt}c)
    &= -re^{-rt}c dt + e^{-rt}dc \\
    &= -re^{-rt}c dt +
    e^{-rt}(c_tdt + c_sdS + c_vdV) \\
    &\ \ \ \ \ \ \ \
    + e^{-rt}\left( \frac{1}{2}c_{s,s}(dS)^2
    + \frac{1}{2}c_{v,v}(dV)^2 + c_{s,v}dSdV \right) \\
    &= -re^{-rt}c dt + e^{-rt}
    \left( c_tdt + c_s(rSdt + \sqrt{V}Sd\tilde{W}_1)
    + c_v((a-bV)dt + \sigma\sqrt{V}d\tilde{W}_2) \right) \\
    &\ \ \ \ \ \ \ \
    + e^{-rt}\left( \frac{1}{2}c_{s,s}VS^2dt
    + \frac{1}{2}c_{v,v}\sigma^2Vdt
    + c_{s,v}\sigma \rho SVdt \right)
  \end{align*}
  となる。
  ここでマルチンゲール性から\(dt\)の係数を\(=0\)とすることで
  方程式
  \begin{align*}
    &-rc + c_t + rsc_s + (a-bv)c_v \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}s^2vc_{s,s}
    + \frac{1}{2}\sigma^2vc_{v,v}
    + \sigma \rho svc_{s,v} = 0
  \end{align*}
  を得る。
  これを整理すると式(6.9.26)となる。

  \ref{enumi: 6.7-2}。
  マジでただだるいだけの計算。流石に省略。

  \ref{enumi: 6.7-3}。
  \(df(t,X(t),V(t))\)を計算して、
  \(f(t,X(t),V(t))\)がマルチンゲールであることを使って
  \(dt\)項を\(=0\)とすれば所望の方程式を得る。
  実際、
  \((dX)^2 = Vdt, (dV)^2 = \sigma Vdt, dXdV = \sigma V\rho dt\)
  であることに注意すれば、
  \begin{align*}
    df
    &= f_tdt + f_xdX + f_vdV + \frac{1}{2}f_{x,x}(dX)^2 +
    \frac{1}{2}f_{v,v}(dV)^2 + f_{x,v}dXdV \\
    &= \left( f_t + \frac{1}{2}V f_{x,x} + \frac{1}{2}\sigma V f_{v,v}
    + \sigma V \rho f_{x,v}\right) dt \\
    &\ \ \ \ \ \ \ \
    + f_x\left(  \left( r + \frac{1}{2}V\right) dt + \sqrt{V} dW_1\right) \\
    &\ \ \ \ \ \ \ \
    + f_v\left(  \left( a-bV+\rho\sigma V\right) dt
    + \sigma\sqrt{V} dW_2\right) \\
    &= \left( f_t + f_v \left( a-bV+\rho\sigma V\right)
    + f_x \left( r + \frac{1}{2}V\right)
    + \frac{1}{2}V f_{x,x} + \frac{1}{2}\sigma V f_{v,v}
    + \sigma V \rho f_{x,v} \right)dt \\
    &\ \ \ \ \ \ \ \
    + f_x\sqrt{V} dW_1 + f_v\sigma\sqrt{V} dW_2
  \end{align*}
  であるから、\(dt\)の係数の\(X,V\)を
  それぞれ\(x,v\)で置き換えれば式(6.9.32)を得る。
  \(t=T\)とすれば境界条件が出る。

  \ref{enumi: 6.7-4}。
  \ref{enumi: 6.7-3}と同じことを\(g(t,X(t),V(t))\)でやるだけ。
  省略してもいいだろう。

  \ref{enumi: 6.7-5}。
  普通に\(t=T\)を代入すると
  \begin{align*}
    c(T,s,v)
    &= sf(T,\log s, v) - Kg(T,\log s, v) \\
    &= s\I_{\log s \geq \log K} - K\I_{\log s \geq \log K} \\
    &= s\I_{s \geq K} - K\I_{s\geq K} \\
    &= (s-K)^+
  \end{align*}
  となる。
\end{proof}


\begin{prob}\label{prob: 6.8}

\end{prob}

\begin{proof}
  \(p\)は初期条件を\(X(t)=x\)としたときに得られる\(X(T)\)の密度関数であるから、
  任意の可測関数\(h\)に対して
  \[
  \E^{t,x}h(X) = \int_0^\infty h(y)p(t,T,x,y)dy
  \]
  となる。
  \(g(t,x) \dfn \E^{t,x}h(X)\)とおいて
  \(dg(t,X(t))\)を計算すれば、
  \((dX)^2 = \gamma^2dt\)であるから、
  \begin{align*}
    dg &= g_tdt + g_xdX + \frac{1}{2}g_{x,x}(dX)^2 \\
    &= g_tdt + g_x\left( \beta dt + \gamma dW\right)
    + \frac{1}{2}\gamma^2g_{x,x}dt \\
    &= \left( g_t + \beta g_x + \frac{1}{2}\gamma^2g_{x,x}\right) dt
    + \gamma g_x dW
  \end{align*}
  となる。
  ここで\(g(t,X(t))\)がマルチンゲールであることから
  \(dt\)の係数を\(=0\)とおけば
  \begin{align*}
    g_t + \beta g_x + \frac{1}{2}\gamma^2g_{x,x} = 0
  \end{align*}
  を得る。
  一方、
  \(g(t,x) = \int_0^\infty h(y)p(t,T,x,y)dy\)であるから、
  \begin{align*}
    &g_t = \int_0^\infty h(y)p_t(t,T,x,y)dy, \\
    &g_x = \int_0^\infty h(y)p_x(t,T,x,y)dy, \\
    &g_{x,x} = \int_0^\infty h(y)p_{x,x}(t,T,x,y)dy,
  \end{align*}
  となって、方程式
  \[
  \int_0^\infty h(y)\left(
  p_t(t,T,x,y) + \beta(t,x) p_x(t,T,x,y)
  + \frac{1}{2}\gamma^2p_{x,x}(t,T,x,y)
  \right) dy = 0
  \]
  を得る。
  これが任意の\(h\)で成立するためには、
  カッコの中身が\(0\)とならなければならない。
  なぜなら、カッコの中身を\(q\)とおけば、
  たとえば\(h=\mathrm{sign}(q)\)とすることで、
  被積分関数がつねに\(\geq 0\)であるようにでき、
  このとき\(\int_0^\infty\)を施して\(=0\)となるには\(q=0\)とならなければならない。
  以上で
  \[
  p_t(t,T,x,y) + \beta(t,x) p_x(t,T,x,y)
  + \frac{1}{2}\gamma^2p_{x,x}(t,T,x,y) = 0
  \]
  となって、整理すれば所望の方程式を得る。
\end{proof}


\begin{prob}\label{prob: 6.9}
  \begin{enumerate}
    \item \label{enumi: 6.9-1}
    \item \label{enumi: 6.9-2}
    \item \label{enumi: 6.9-3}
    \item \label{enumi: 6.9-4}
    \item \label{enumi: 6.9-5}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.9-1}。
  \((dX)^2 = \gamma^2dt\)なので
  \begin{align*}
    dh_b(X) &= h'_b(X)dX + \frac{1}{2}h''_b(X)(dX)^2 \\
    &= h'_b(X)\left( \beta dt + \gamma dW\right)
    + \frac{1}{2}\gamma^2 h''_b(X)dt \\
    &= \left( \beta h'_b(X) + \frac{1}{2}\gamma^2 h''_b(X) \right) dt
    + \gamma h'_b(X)dW
  \end{align*}
  となる。

  \ref{enumi: 6.9-2}。
  \(h_b'(x) = 0 , (x \geq b)\)と
  \(h_b(b) = 0\)から\(h_b(x) = 0 , (x \geq b)\)である。
  従って期待値をとるときは\(\int_0^b\)での積分として良い
  (仮定から\(h_b(x)=0 , (x<0)\)でもある)。
  \ref{enumi: 6.9-1}の結果を\(\int_t^T\)で積分して期待値をとれば、
  \begin{align*}
    \E \left[ h_b(X(T)) - h_b(X(t))\right]　
    &= \int_t^T \E \left[ \beta h'_b(X)
    + \frac{1}{2}\gamma^2 h''_b(X)\right] du \\
    &= \int_t^T \int_0^b \left( \beta (t,y) h'_b(y)
    + \frac{1}{2}\gamma^2(t,y) h''_b(y)\right) p(t,u,x,y) du
  \end{align*}
  となる。
  左辺は
  \[
  = \int_0^b h_b(y)p(t,T,x,y)dy - h_b(x)
  \]
  であるから、整理すれば所望の等式を得る。

  \ref{enumi: 6.9-3}。
  第二項を計算すると、\(h_b(b)=h_b(0)=0\)であるから、
  \begin{align*}
    &\int_0^b\beta(u,y)p(t,u,x,y)h_b'(y)dy \\
    &= \beta(u,b)p(t,u,x,b)h_b(b) - \beta(u,0)p(t,u,x,0)h_b(0) -
    \int_0^b\frac{\partial}{\partial y}
    \left( \beta(u,y)p(t,u,x,y)\right)h_b(y)dy \\
    &= - \int_0^b\frac{\partial}{\partial y}
    \left( \beta(u,y)p(t,u,x,y)\right)h_b(y)dy
  \end{align*}
  である。
  第三項を計算すると、
  \(h_b'(b)=h_b'(0)=h_b(b)=h_b(0)=0\)であるから、
  \begin{align*}
    &\int_0^b\gamma^2(u,y)p(t,u,x,y)h_b''(y)dy \\
    &= \gamma^2(u,b)p(t,u,x,b)h_b'(b) - \gamma^2(u,0)p(t,u,x,0)h_b'(0) -
    \int_0^b\frac{\partial}{\partial y}
    \left( \gamma^2(u,y)p(t,u,x,y)\right)h_b'(y)dy \\
    &= - \int_0^b\frac{\partial}{\partial y}
    \left( \beta(u,y)p(t,u,x,y)\right)h_b'(y)dy \\
    &= \frac{\partial}{\partial y}
    \left( \beta(u,y)p(t,u,x,y)\right)|_{y=b}h_b(b)
    - \frac{\partial}{\partial y}
    \left( \beta(u,y)p(t,u,x,y)\right)|_{y=0}h_b(0)
    + \int_0^b\frac{\partial^2}{\partial y^2}
    \left( \gamma^2(u,y)p(t,u,x,y)\right)h_b(y)dy \\
    &= \int_0^b\frac{\partial^2}{\partial y^2}
    \left( \gamma^2(u,y)p(t,u,x,y)\right)h_b(y)dy
  \end{align*}
  である。
  以上を組み合わせると所望の結果が得られる。

  \ref{enumi: 6.9-4}。
  言われた通り微分するだけ。流石に省略。

  \ref{enumi: 6.9-5}。
  \(h_b\)は問\ref{enumi: 6.9-1}の条件を満たすものであればなんでもいい。
  だからもしこのような\(y_1<y_2\)があれば、
  \((y_1,y_2)\)に含まれるある区間内でのみ\(h_b(y)>0\)
  (または\(h_b(y)<0\)) であって
  他の部分で\(h_b(y)=0\)となる\(h_b\)がとれる。
  このとき式(6.9.50)の等号は成り立たない。
\end{proof}


\begin{prob}\label{prob: 6.10}
  \begin{enumerate}
    \item \label{enumi: 6.10-1}
    \item \label{enumi: 6.10-2}
    \item \label{enumi: 6.10-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 6.10-1}。
  部分積分すると
  \begin{align*}
    \int_K^\infty \left(
    (y-K)\frac{\partial}{\partial y}ry\tilde{p}(0,T,x,y)
    + ry\tilde{p}(0,T,x,y)\right) dy
    = \left[ (y-K)ry\tilde{p}(0,T,x,y)\right]_K^\infty = 0
  \end{align*}
  となるので整理すれば所望の等式を得る。

  \ref{enumi: 6.10-2}。
  計算すると、
  \begin{align*}
    &\frac{1}{2}\int_K^{\infty}(y-K)\frac{\partial^2}{\partial y^2}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y)\right) dy \\
    &= \left[ (y-K)\frac{\partial}{\partial y}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y)\right)
    \right]_K^{\infty}
    - \frac{1}{2}\int_K^{\infty}
    \frac{\partial}{\partial y}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y)\right) dy \\
    &= - \frac{1}{2}\left[ \frac{\partial}{\partial y}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y)\right) \right]_K^\infty \\
    &= \frac{1}{2}\sigma^2(T,K)K^2\tilde{p}(0,T,x,K)
  \end{align*}
  となる。

  \ref{enumi: 6.10-3}。
  計算すると、
  \begin{align*}
    &c_T(0,T,x,K) \\
    &\overset{\bigstar}{=}
    -rc(0,T,x,K) + e^{-rT}\int_K^{\infty}(y-K)\tilde{p}_T(0,T,x,y)dy \\
    &\overset{\spadesuit}{=}
    -re^{-rT}\int_K^\infty (y-K)\tilde{p}(0,T,x,y)dy
    + e^{-rT}\int_K^\infty (y-K)\tilde{p}_T(0,T,x,y)dy \\
    &\overset{\clubsuit}{=}
    -re^{-rT}\int_K^\infty (y-K)\tilde{p}(0,T,x,y)dy \\
    &\ \ \ \ \ \
    + e^{-rT}\int_K^\infty (y-K)
    \left( -\frac{\partial}{\partial y}\left( ry\tilde{p}(0,T,x,y) \right)
    + \frac{1}{2}\frac{\partial^2}{\partial y^2}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y) \right)
    \right)dy \\
    &\overset{\heartsuit}{=}
    rK e^{-rT}\int_K^\infty\tilde{p}(0,T,x,y)dy
    + \frac{1}{2}e^{-rT}\int_K^\infty (y-K)\frac{\partial^2}{\partial y^2}
    \left( \sigma^2(T,y)y^2\tilde{p}(0,T,x,y) \right) dy \\
    &\overset{\diamondsuit}{=}
    rK e^{-rT}\int_K^\infty\tilde{p}(0,T,x,y)dy
    + e^{-rT}\sigma^2(T,K)K^2\tilde{p}(0,T,x,y) \\
    &\overset{\applekey}{=}
    - rK c_K(0,T,x,K) + \frac{1}{2}\sigma^2(T,K)K^2c_{K,K}(0,T,x,K)
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は式(6.9.52)を微分することで得られる式(6.9.53)を用い、
  \(\spadesuit\)の箇所は式(6.9.52)を用い、
  \(\clubsuit\)の箇所は式(6.9.51)を用い、
  \(\heartsuit\)の箇所は式(6.9.54)を用い、
  \(\diamondsuit\)の箇所は式(6.9.56)を用い、
  \(\applekey\)の箇所は\autoref{prob: 5.9}の計算結果を用いた。
\end{proof}






\newpage

\section{エキゾチック・オプション}\label{section: 7}



\begin{prob}\label{prob: 7.1}
  \begin{enumerate}
    \item \label{enumi: 7.1-1}
    \item \label{enumi: 7.1-2}
    \item \label{enumi: 7.1-3}
    \item \label{enumi: 7.1-4}
    \item \label{enumi: 7.1-5}
    \item \label{enumi: 7.1-6}
    \item \label{enumi: 7.1-7}
    \item \label{enumi: 7.1-8}
    \item \label{enumi: 7.1-9}
    \item \label{enumi: 7.1-10}
    \item \label{enumi: 7.1-11}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 7.1-1}。
  普通に計算する。
  \[
  \delta_{\pm}(\tau, s) \dfn
  \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
  r \pm \frac{1}{2}\sigma^2\right)\tau \right)
  \]
  であるから、
  \begin{align*}
    \frac{d}{dt}\delta_{\pm}\left(\tau, \frac{x}{c}\right)
    &= - \frac{d\tau}{dt}\frac{1}{2\sigma\sqrt{\tau^3}}\log s
    + \frac{d\tau}{dt}\frac{1}{2\sigma\sqrt{\tau}}
    \left( r \pm \frac{1}{2}\sigma^2\right) \\
    &= \frac{1}{2\sigma\tau\sqrt{\tau}} \left( \log s
    - \left( r \pm \frac{1}{2}\sigma^2\right) \tau \right) \\
    &= -\frac{1}{2\tau}\delta_{\pm}(\tau,s)
  \end{align*}
  となる。

  \ref{enumi: 7.1-2}。
  \begin{align*}
    &\delta_{\pm}\left( \tau, \frac{x}{c}\right) \dfn
    \frac{1}{\sigma\sqrt{\tau}}\left( \log x - \log c + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right) \\
    &\delta_{\pm}\left( \tau, \frac{c}{x}\right) \dfn
    \frac{1}{\sigma\sqrt{\tau}}\left( \log c - \log x + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right)
  \end{align*}
  であるから、
  \begin{align*}
    \frac{d}{dx}\delta_{\pm}\left( \tau, \frac{x}{c}\right)
    &= \frac{1}{x\sigma\sqrt{\tau}} \\
    \frac{d}{dx}\delta_{\pm}\left( \tau, \frac{c}{x}\right)
    &= - \frac{1}{x\sigma\sqrt{\tau}}
  \end{align*}
  となる。

  \ref{enumi: 7.1-3}。
  \begin{align*}
    \delta_+(\tau,s) - \delta_-(\tau,s)
    &= \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r + \frac{1}{2}\sigma^2\right)\tau \right)
    - \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r - \frac{1}{2}\sigma^2\right)\tau \right) \\
    &= \frac{1}{2\sigma\sqrt{\tau}}\sigma^2\tau
    + \frac{1}{2\sigma\sqrt{\tau}}\sigma^2\tau \\
    &= \sigma\sqrt{\tau} \\
    \delta_+(\tau,s) + \delta_-(\tau,s)
    &= \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r + \frac{1}{2}\sigma^2\right)\tau \right)
    + \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r - \frac{1}{2}\sigma^2\right)\tau \right) \\
    &= \frac{2}{\sigma\sqrt{\tau}}\left( \log s + r\tau \right) \\
    \delta_+^2(\tau,s) - \delta_-^2(\tau,s)
    &= \left( \delta_+(\tau,s) - \delta_-(\tau,s) \right)
    \left( \delta_+(\tau,s) + \delta_-(\tau,s) \right) \\
    &= \sigma\sqrt{\tau}\frac{2}{\sigma\sqrt{\tau}}
    \left( \log s + r\tau \right) \\
    &= 2\left( \log s + r\tau \right)
  \end{align*}
  であり、また
  \(N'(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}\)
  であるから、
  \begin{align*}
    \frac{N'(\delta_+(\tau,s))}{N'(\delta_-(\tau,s))}
    &= \exp \left( - \frac{1}{2}\delta_+^2(\tau,s)
    + \frac{1}{2}\delta_-^2(\tau,s)\right) \\
    &= \exp \left( - \frac{1}{2}\delta_+^2(\tau,s)
    + \frac{1}{2}\delta_-^2(\tau,s)\right) \\
    &= \exp \left( -\left( \log s + r\tau \right) \right) \\
    &= \frac{e^{-r\tau}}{s}
  \end{align*}
  となる。

  \ref{enumi: 7.1-4}。
  \begin{align*}
    \delta_{\pm}(\tau,s) - \delta_{\pm}(\tau,s^{-1})
    &= \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right)
    - \frac{1}{\sigma\sqrt{\tau}}\left( - \log s + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right) \\
    &= \frac{2}{\sigma\sqrt{\tau}}\log s \\
    \delta_{\pm}(\tau,s) + \delta_{\pm}(\tau,s^{-1})
    &= \frac{1}{\sigma\sqrt{\tau}}\left( \log s + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right)
    + \frac{1}{\sigma\sqrt{\tau}}\left( - \log s + \left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \right) \\
    &= \frac{2}{\sigma\sqrt{\tau}}\left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \\
    \delta_{\pm}^2(\tau,s) - \delta_{\pm}^2(\tau,s^{-1})
    &= \left( \delta_{\pm}(\tau,s) - \delta_{\pm}(\tau,s^{-1}) \right)
    \left( \delta_{\pm}(\tau,s) + \delta_{\pm}(\tau,s^{-1}) \right) \\
    &= \frac{2}{\sigma\sqrt{\tau}}\log s
    \frac{2}{\sigma\sqrt{\tau}}\left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \\
    &= \frac{4}{\sigma^2\tau}\left(
    r \pm \frac{1}{2}\sigma^2\right)\tau \log s \\
    &= \left(\frac{4r}{\sigma^2} \pm 2\right) \log s
  \end{align*}
  であるから、
  \begin{align*}
    \frac{N'(\delta_{\pm}(\tau,s))}{N'(\delta_{\pm}(\tau,s^{-1}))}
    &= \exp \left( - \frac{1}{2}\delta_{\pm}^2(\tau,s)
    + \frac{1}{2}\delta_{\pm}^2(\tau,s)\right) \\
    &= \exp \left( - \left(\frac{2r}{\sigma^2} \pm 1\right) \log s\right) \\
    &= s^{- \left(\frac{2r}{\sigma^2} \pm 1\right)}
  \end{align*}

  \ref{enumi: 7.1-5}と\ref{enumi: 7.1-6}はすでに計算済みである。

  \ref{enumi: 7.1-7}。
  \[
  N''(y)
  = \left( \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2}\right)' \\
  = -y\cdot \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} \\
  = -yN'(y)
  \]
  となる。

  \ref{enumi: 7.1-8}。
  \ref{enumi: 7.1-9}。
  \ref{enumi: 7.1-10}。
  \ref{enumi: 7.1-11}。
  やる意味ねーって思ったからもうやらない。
\end{proof}



\begin{prob}\label{prob: 7.2}
\end{prob}

\begin{proof}
  やる意味がなさそうな演習なのでやらない。
\end{proof}



\begin{prob}\label{prob: 7.3}
\end{prob}

\begin{proof}
  まず
  \begin{align*}
    S(T)
    &= S(0)e^{\sigma\hat{W}(T)} \\
    &= S(t)e^{\sigma \left( \hat{W}(T) - \hat{W}(t)\right) }
  \end{align*}
  である。
  ここで\(\hat{W}(T) - \hat{W}(t)\)は\(\mcF(t)\)と独立であることに注意する。
  次に、
  \begin{align*}
    \hat{M}(T) - \hat{M}(t)
    &= \max_{0\leq u\leq T}\hat{W}(u) - \max_{0\leq u\leq t}\hat{W}(u) \\
    &= \left( \max_{t\leq u\leq T}\hat{W}(u)
    - \max_{0\leq u\leq t}\hat{W}(u) \right)^+ \\
    &= \left( \max_{t\leq u\leq T}\left( \hat{W}(u) - \hat{W}(t)\right)
    - \hat{M}(t) + \hat{W}(t)\right)^+
  \end{align*}
  と式変形することで
  \begin{align*}
    Y(T) &= Y(0)e^{\sigma \hat{M}(T)} \\
    &= Y(t)e^{\sigma \left( \hat{M}(T) - \hat{M}(t)\right)} \\
    &= Y(t)e^{ \sigma \left(
    \max_{t\leq u\leq T}\left( \hat{W}(u) - \hat{W}(t)\right)
    - \hat{M}(t) + \hat{W}(t) \right)^+ }
  \end{align*}
  を得る。
  ここで
  \(\max_{t\leq u\leq T}\left( \hat{W}(u) - \hat{W}(t)\right)\)
  は\(\mcF(t)\)と独立であり、
  \(\hat{M}(t),\hat{W}(t)\)は\(\mcF(t)\)-可測であることに注意する。
  確率変数\(F\)と関数\(G\)を
  \begin{align*}
    &F(s,y,w,m) \dfn
    f\left( se^{\sigma \left( \hat{W}(T)-\hat{W}(t)\right)},
    ye^{ \sigma \left(
    \max_{t\leq u\leq T}\left( \hat{W}(u) - \hat{W}(t)\right)
    - m + w \right)^+ } \right) \\
    &G(s,y,w,m) \dfn \E\left[ F(s,y,w,m)\right]
  \end{align*}
  と定義すれば、
  これまでの計算結果を考慮すれば、
  \[
  F(S(t),Y(t),\hat{W}(t),\hat{M}(t))
  = f(S(T),Y(T))
  \]
  となることがわかる。また
  \(\hat{W}(T)-\hat{W}(t)\)と
  \(\max_{t\leq u\leq T}\left( \hat{W}(u) - \hat{W}(t)\right)\)
  は\(\mcF(t)\)と独立な確率変数であり、
  \(S(t),Y(t),\hat{W}(t),\hat{M}(t)\)は
  \(\mcF(t)\)-可測な確率変数であるから、
  独立性の補題より
  \[
  G(S(t),Y(t),\hat{W}(t),\hat{M}(t))
  = \E\left[ F(S(t),Y(t),\hat{W}(t),\hat{M}(t)) \middle| \mcF(t)\right]
  = \E\left[ f(S(T),Y(T)) \middle| \mcF(t)\right]
  \]
  となる。
  ここで
  \begin{align*}
    &\hat{W}(t) = \frac{1}{\sigma}\log \left( \frac{S(t)}{S(0)}\right) \\
    &\hat{M}(t) = \frac{1}{\sigma}\log \left( \frac{Y(t)}{Y(0)}\right) \\
  \end{align*}
  であることに注意すれば、
  \(G(S(t),Y(t),\hat{W}(t),\hat{M}(t))\)は
  \(S(t),Y(t)\)に関する関数として表すことができる。
  これは所望の結果である。
\end{proof}







\begin{prob}\label{prob: 7.4}

\end{prob}

\begin{proof}
  まず\(d\hat{W} = d\tilde{W} + \alpha dt\)なので
  \((d\hat{W})^2 = dt\)であり、
  従って\((dS)^2 = (Sd\hat{W})^2 = S^2dt\)となる。
  以上より、区間\([0,t]\)の分割\(\Pi\)に対して
  \[
  \sum _{j=0}^m\left| S(t_j) - S(t_{j-1})\right|^2
  \to \int_0^t S^2(u)du \ , \ (\|\Pi\| \to 0)
  \]
  となる。
  また、区間\([0,t]\)上の単調増加関数\(f\)に対して、
  その二次変分を計算すると、
  区間\([0,t]\)の分割\(\Pi\)に対して
  \begin{align*}
    \sum_{j=0}^m \left| f(t_j) - f(t_{j-1})\right| ^2
    &\leq \left(\max_{0\leq j \leq m}f(t_j) - f(t_{j-1})\right)
    \sum_{j=0}^m \left| f(t_j) - f(t_{j-1})\right|  \\
    &= \left(\max_{0\leq j \leq m}f(t_j) - f(t_{j-1})\right)
    \left( f(t) - f(0) \right)  \\
    &\to 0 \ , \ (\|\Pi\| \to 0)
  \end{align*}
  となる。
  \(Y(u)\)はどの経路でも単調増加であるから、
  従って
  \[
  \sum _{j=0}^m\left| Y(t_j) - Y(t_{j-1})\right|^2
  \to 0 \ , \ (\|\Pi\| \to 0)
  \]
  となる。
  あとは、コーシーシュワルツの不等式より、
  \begin{align*}
    \sum _{j=0}^m\left| Y(t_j) - Y(t_{j-1})\right|
    \left| S(t_j) - S(t_{j-1})\right|
    &\leq \left( \sum_{j=0}^m\left| Y(t_j) - Y(t_{j-1})\right| ^2
    \sum_{j=0}^m\left| S(t_j) - S(t_{j-1})\right| ^2 \right)
    ^{\frac{1}{2}}  \\
    &\to 0 \ , \ (\|\Pi\|\to 0)
  \end{align*}
  となる。以上で示された。
\end{proof}








\begin{prob}\label{prob: 7.5}
\end{prob}
\begin{proof}
  単純計算。やる意味ない。
\end{proof}
\begin{prob}\label{prob: 7.6}
\end{prob}
\begin{proof}
  単純計算。やる意味ない。
\end{proof}





\begin{prob}\label{prob: 7.7}
  \begin{enumerate}
    \item \label{enumi: 7.7-1}
    \item \label{enumi: 7.7-2}
    \item \label{enumi: 7.7-3}
    \item \label{enumi: 7.7-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 7.7-1}。
  \(S\)は幾何ブラウン運動\(dS = rSdu + \sigma S d\tilde{W}\)に従うので、
  割引過程\(e^{-ru}S\)は
  \[
  d(e^{-ru}S) = e^{-ru}dS - re^{-ru}Sdu = \sigma e^{-ru} S d\tilde{W}
  \]
  となってリスク中立測度に関してマルチンゲールである。
  とくに\(u\geq t\)に対して
  \(\E\left[ e^{-ru}S(u)\middle| \mcF(t)\right] = e^{-rt}S(t)\)
  であるから、整理すれば
  \[
  \E\left[ S(u)\middle| \mcF(t)\right] = e^{r(u-t)}S(t)
  \]
  を得る。
  以上より、
  \begin{align*}
    v(t,x,y)
    &= e^{-r(T-t)}\E\left[ \frac{1}{T}\int_0^TS(u)du
    \middle| \mcF(t)\right] \\
    &= e^{-r(T-t)}\E\left[
    \frac{1}{T}\int_0^tS(u)du + \frac{1}{T}\int_t^TS(u)du
    \middle| \mcF(t)\right]  \\
    &= \frac{e^{-r(T-t)}}{T}\int_0^tS(u)du
    + \frac{e^{-r(T-t)}}{T}\E\left[ \int_t^TS(u)du
    \middle| \mcF(t)\right] \\
    &= \frac{e^{-r(T-t)}}{T}y
    + \frac{e^{-r(T-t)}}{T}\int_t^T
    \E\left[ S(u) \middle| \mcF(t)\right] du \\
    &= \frac{ye^{-r(T-t)}}{T}
    + \frac{e^{-r(T-t)}}{T}\int_t^T e^{r(u-t)}S(t) du \\
    &= \frac{ye^{-r(T-t)}}{T}
    + \frac{e^{-rT}}{T}S(t)\int_t^T e^{ru} du \\
    &= \frac{ye^{-r(T-t)}}{T}
    + \frac{e^{-rT}}{rT}S(t)\left( e^{rT}-e^{rt} \right) \\
    &= \frac{ye^{-r(T-t)}}{T}
    + \frac{1}{rT}\left( 1-e^{-r(T-t)} \right) x
  \end{align*}
  となる。

  \ref{enumi: 7.7-2}。
  微分を計算すると、
  \begin{align*}
    &v_t(t,x,y)
    = \frac{rye^{-r(T-t)}}{T} - \frac{xe^{-r(T-t)}}{T} \\
    &v_x(t,x,y)
    = \frac{1}{rT}\left( 1-e^{-r(T-t)} \right) \\
    &v_y(t,x,y)
    = \frac{e^{-r(T-t)}}{T} \\
    &v_{x,x}(t,x,y)
    = 0
  \end{align*}
  となる。
  従って
  \begin{align*}
    &v_t(t,x,y) + rxv_x(t,x,y) + xv_y(t,x,y)
    + \frac{1}{2}\sigma^2x^2v_{x,x}(t,x,y) \\
    &= \frac{rye^{-r(T-t)}}{T} - \frac{xe^{-r(T-t)}}{T}
    + rx\frac{1}{rT}\left( 1-e^{-r(T-t)} \right)
    + x\frac{e^{-r(T-t)}}{T} \\
    &= \frac{rye^{-r(T-t)}}{T}
    + \frac{1}{T}\left( 1-e^{-r(T-t)} \right) x \\
    &= rv(t,x,y)
  \end{align*}
  となり、式(7.5.8)が成立する。
  \(x=0\)とすれば、\(K=0, y\geq 0\)であるから、
  \[
  v(t,0,y) = \frac{ye^{-r(T-t)}}{T}
  = e^{-r(T-t)}\left( \frac{y}{T} - K\right)^+
  \]
  となり、式(7.5.9)が成立する。
  \(t=T\)とすれば、\(K=0, y\geq 0\)であるから、
  \[
  v(T,x,y) = \frac{y}{T}
  = \left( \frac{y}{T} - K\right)^+
  \]
  となり、式(7.5.11)が成立する。
  以上で全て確認できた。

  \ref{enumi: 7.7-3}。
  \(\Delta(t) = v_x(t,x,y)\)は\ref{enumi: 7.7-2}で求めている。
  これはそもそも\(x,y\)と無関係であるから
  \(v_x(t,S(t),Y(t))\)は確率的ではない。

  \ref{enumi: 7.7-4}。
  \(X\)の従う確率微分方程式は、条件から、
  \[
  dX = \Delta dS + (X-\Delta S)rdt
  = \Delta ( rSdt + \sigma Sd\tilde{W}) + (X-\Delta S)rdt
  = \sigma \Delta S d\tilde{W} + rXdt
  \]
  である。
  割引過程\(e^{-rt}X\)の微分は
  \[
  d(e^{-rt}X) = -re^{-rt}Xdt + e^{-rt}dX
  = e^{-rt}(-rXdt + dX)
  = e^{-rt}\sigma \Delta Sd\tilde{W}
  \]
  となる。これを\(\int_0^T\)で積分することを考える。
  \[
  e^{-rt}\Delta(t) = e^{-rt}v_x(t,x,y)
  = \frac{1}{rT}\left( e^{-rt}-e^{-rT} \right)
  \]
  であり、また
  \[
  X(0) = v(0,S(0),0) = \frac{S(0)}{rT}\left( 1-e^{-rT}\right)
  \]
  であることに注意する。
  \(d(e^{-rt}S) = \sigma e^{-rt}Sd\tilde{W}\)と
  \(dS = \sigma S d\tilde{W} + rSdt\)より、
  \(d\left( e^{-rt}X(t) \right)\)の\(\int_0^T\)での積分は、
  \begin{align*}
    &e^{-rT}X(T) - X(0)  \\
    &= \int_0^T e^{-rt}\sigma \Delta(t) S(t) d\tilde{W}(t) \\
    &= \frac{1}{rT} \int_0^T \sigma
    \left( e^{-rt}-e^{-rT} \right) S(t) d\tilde{W}(t) \\
    &= \frac{1}{rT} \int_0^T \sigma e^{-rt}S(t) d\tilde{W}(t)
    - \frac{e^{-rT}}{rT} \int_0^T \sigma S(t) d\tilde{W}(t) \\
    &= \frac{1}{rT} \int_0^T d(e^{-rt}S(t))
    - \frac{e^{-rT}}{rT} \int_0^T dS(t)
    + \frac{e^{-rT}}{T} \int_0^T S(t) dt \\
    &= \frac{1}{rT} \left( e^{-rT}S(T) - S(0) \right)
    - \frac{e^{-rT}}{rT} \left( S(T) - S(0) \right)
    + \frac{e^{-rT}}{T} \int_0^T S(t) dt \\
    &= \frac{S(0)}{rT} \left( e^{-rT} - 1 \right)
    + \frac{e^{-rT}}{T} \int_0^T S(t) dt \\
    &= - X(0) + \frac{e^{-rT}}{T} \int_0^T S(t) dt
  \end{align*}
  となる。
  これを整理すれば所望の等式を得る。
\end{proof}







\begin{prob}\label{prob: 7.8}
\end{prob}

\begin{proof}
  式(7.5.22)で\(r\to 0\)とすることで
  \[
  \gamma(t) =
  \begin{cases}
    1 \ , \ (t \leq T-c) \\
    \frac{T-t}{c} \ , \ (t \geq T-c)
  \end{cases}
  \]
  と予測できる。
  実際にこの\(\gamma\)が求めるもの、
  つまり式(7.5.27)を満たすものであることを示す。

  金利\(0\)なので\(dX = \gamma dS = \sigma \gamma S d\tilde{W}\)である。
  とくに\(S,X\)はマルチンゲールである。
  よって
  \begin{align*}
    X(0) &= \E\left[ X(T)\right] \\
    &= \E\left[ \frac{1}{c}\int_{T-c}^TS(u)du - K \right] \\
    &= \frac{1}{c}\int_{T-c}^T\E\left[ S(u) \right] du - K \\
    &= \frac{1}{c}\int_{T-c}^TS(0) du - K \\
    &= S(0) - K
  \end{align*}
  である。
  また
  \[
  d(\gamma S) = \gamma dS + \gamma 'Sdu
  \]
  であるから、
  \(dX = d(\gamma S) - \gamma 'Sdu\)となることがわかる。
  この両辺を\(\int_0^t\)で積分する。
  \(u \leq T-c\)に対しては\(\gamma'(u) = 0\)であるから、
  \(t\leq T-c\)のときは
  \begin{align*}
    X(t)
    &= X(0) + \int_0^t d(\gamma (u)S(u))
    - \int_0^t \gamma'(u)S(u)du \\
    &= X(0) + \gamma(t)S(t) - \gamma(0)S(0) \\
    &= X(0) + S(t) - S(0) \\
    &= S(t) - K
  \end{align*}
  となり、
  \(u \geq T-c\)に対しては\(\gamma'(u) = -\frac{1}{c}\)であるから、
  \(t\geq T-c\)のときは
  \begin{align*}
    X(t)
    &= X(0) + \int_0^t d(\gamma (u)S(u))
    - \int_0^t \gamma'(u)S(u)du \\
    &= X(0) + \gamma(t)S(t) - \gamma(0)S(0)
    + \frac{1}{c} \int_{T-c}^t S(u)du \\
    &= \frac{T-t}{c}S(t) - K
    + \frac{1}{c} \int_{T-c}^t S(u)du
  \end{align*}
  となる。
  とくに\(t=T\)のときは
  \(X(K) = \frac{1}{c} \int_{T-c}^T S(u)du - K\)
  となって所望の結果を得る。
\end{proof}







\begin{prob}\label{prob: 7.9}
  \begin{enumerate}
    \item \label{enumi: 7.9-1}
    \item \label{enumi: 7.9-2}
    \item \label{enumi: 7.9-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 7.9-1}。
  普通に計算すると
  \begin{alignat*}{3}
    &v_t(t,s,x) & &= sg_t(t,y), \\
    &v_s(t,s,x) & &= g(t,y) + s \cdot \left(\frac{-x}{s^2}g_y(s,y)\right) \\
    & & &= g(t,y) - yg_y(t,y), \\
    &v_x(t,s,x) & &= s\frac{1}{s}g_y(t,y) \\
    & & &= g_y(t,y), \\
    &v_{s,s}(t,s,x) &
    &= \frac{\partial}{\partial s}\left( g(t,y) - yg_y(t,y) \right)\\
    & & &= \frac{-x}{s^2}g_y(t,y) -
    \left( \frac{-x}{s^2}g(t,y) + y\cdot \frac{-x}{s^2}g_{y,y}(t,y)\right) \\
    & & &= \frac{y^2}{s}g_{y,y}(t,y), \\
    &v_{s,x}(t,s,x) & &= \frac{\partial}{\partial s}g_y(t,y) \\
    & & &= \frac{-x}{s^2}g_{y,y}(t,y) \\
    & & &= \frac{-y}{s}g_{y,y}(t,y), \\
    &v_{x,x}(t,s,x) & &= \frac{\partial}{\partial x}g_y(t,y) \\
    & & &= \frac{1}{s}g_{y,y}(t,y),
  \end{alignat*}
  となる。これらは所望の結果である。

  \ref{enumi: 7.9-2}。
  普通に考えたら
  \(e^{-rt}v\left(t,S(t),X(t)\right)
  = \tilde{\E}\left[e^{-rT}X^+(T)\middle|\mcF(t)\right]\)
  なんだから反復条件付きの性質から勝手にマルチンゲールになるはずだけど、
  この問題の意図はそうじゃない？
  たぶん\(v(t,s,x) = sg(t,y)\)と\(g\)の満たす微分方程式(7.5.39)から
  直接\(v\)がマルチンゲールであることを示せということだと思う。
  クソ面倒だしやる意味が感じられないけど仕方なく計算をしてやると、
  \begin{align*}
    &dS = rSdt + \sigma S d\tilde{W} \\
    &dX = rXdt + \sigma \gamma S d\tilde{W} \\
    &(dS)^2 = \sigma^2 S^2 dt \\
    &dSdX = \sigma^2 \gamma S^2 dt \\
    &(dX)^2 = \sigma^2 \gamma^2 S^2 dt
  \end{align*}
  なので、
  \begin{align*}
    &d\left( e^{-rt}v\right) \\
    &= e^{-rt}dv - re^{-rt}vdt \\
    &= e^{-rt}\left( - rvdt
    + v_t dt + v_s dS + v_x dX
    + \frac{1}{2}v_{s,s}(dS)^2
    + v_{s,x}dSdX
    + \frac{1}{2}v_{x,x}(dX)^2
    \right) \\
    &= e^{-rt}\left( - rv
    + v_t + rS v_s + rX v_x
    + \frac{1}{2}\sigma^2 S^2 v_{s,s}
    + \sigma^2 \gamma S^2 v_{s,x}
    + \frac{1}{2} \sigma^2 \gamma^2 S^2 v_{x,x}\right) dt \\
    &\ \ \ \ \ \ \ \
    + \text{(何らか)}d\tilde{W}
  \end{align*}
  となる。
  \(dt\)の係数が\(0\)になれば良いので、カッコ内を計算する。
  \(S(t)=s, X(t)=x\)とおく。
  \ref{enumi: 7.9-1}での計算結果と
  \(x = sy\)より、
  \begin{align*}
    & v_t + rs v_s + rx v_x
    + \frac{1}{2}\sigma^2 s^2 v_{s,s}
    + \sigma^2 \gamma s^2 v_{s,x}
    + \frac{1}{2} \sigma^2 \gamma^2 s^2 v_{x,x} \\
    &= sg_t + rs(g-yg_y) + rxg_y
    + \frac{1}{2}\sigma^2 s^2 \frac{y^2}{s}g_{y,y}
    + \sigma^2 \gamma s^2 \left( - \frac{y}{s}g_{y,y}\right)
    + \frac{1}{2} \sigma^2 \gamma^2 s^2 \frac{1}{s}g_{y,y} \\
    &= sg_t + rsg
    + \frac{1}{2}\sigma^2 s
    \left( y^2 - 2y\gamma + \gamma^2 \right)g_{y,y} \\
    &= rsg + s\left( g_t
    + \frac{1}{2}\sigma^2 (\gamma - y)^2g_{y,y}\right) \\
    &\overset{\bigstar}{=} rsg \\
    &\overset{\spadesuit}{=} rv \\
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所で\(g\)の満たす微分方程式(7.5.39)を用い、
  \(\spadesuit\)の箇所は\(v\)の定義 (つまり\(v=sg\)) を用いた
  以上より\(dt\)の係数は\(0\)となり、
  \(e^{-rt}v\)はマルチンゲールであることが示された。

  \ref{enumi: 7.9-3}。
  デルタ・ヘッジ法 (cf. 4.5.3節)で求める。
  まずヘッジ・ポートフォリオの構成から、
  \(V(t) = v(t,S(t),X(t))\)は次の確率微分方程式を満たす：
  \[
  dV = \Delta dS + r(V-\Delta S) dt
  = \Delta \left( rSdt + \sigma Sd\tilde{W}\right)
  + rVdt - r\Delta rSdt
  = rVdt + \sigma S \Delta d\tilde{W}
  \]
  次に普通に\(v(t,S(t),X(t))\)を微分すると、
  \begin{align*}
    &dS = rS dt + \sigma Sd\tilde{W}, \\
    &dX = rXdt + \sigma \gamma S d\tilde{W}, \\
    &(dS)^2 = (\text{何らか})dt, \\
    &(dX)^2 = (\text{何らか})dt, \\
    &dSdX = (\text{何らか})dt,
  \end{align*}
  であるから、
  \begin{align*}
    d\left(v\left(t,S(t),X(t)\right)\right)
    &= (\text{何らか})dt + v_sdS + v_xdX \\
    &= (\text{何らか})dt + v_s\sigma Sd\tilde{W}
    + v_x\sigma S \gamma d\tilde{W} \\
    &= (\text{何らか})dt
    + \sigma S\left( v_s + \gamma v_x\right)d\tilde{W}
  \end{align*}
  となる。
  ここで\(d\tilde{W}\)の係数を比較すれば、
  \[
  \Delta(t) = v_s(t,S(t),X(t)) + \gamma(t)v_x(t,S(t),X(t))
  \]
  を得る。
  \(\gamma\)の明示的な式は式(7.5.22)で与えられていることに注意。
  以上で\(\Delta\)が求まった。

  \underline{\textbf{コメント}}：
  本文では唐突に\(\gamma\)を定義しているが、
  \(\gamma\)の式(7.5.22)も同様の方法で求めることができる。
\end{proof}









\newpage

\section{アメリカン派生証券}\label{section: 8}



\begin{prob}\label{prob: 8.1}
\end{prob}

\begin{proof}
  \(x > L \)に対しては
  \[
  v'_L(x) = \frac{K-L}{L^{-\frac{2r}{\sigma^2}}}
  \left( -\frac{2r}{\sigma^2}\right) x^{-\frac{2r}{\sigma^2}-1}
  \]
  であるから、\(x\to L+\)とすれば
  \[
  v'_L(L+)
  = -\frac{2r}{\sigma^2}\frac{K-L}{L}
  = -\frac{2r(K-L)}{\sigma^2L}
  \]
  となる。
  \(v'_L(L+) = -1\)とすれば、
  \(2r(K-L) = \sigma^2L\)
  を得て、変形すれば\(2rK = (2r + \sigma^2)L\)であるから、
  結局
  \[
  L = \frac{2r}{2r+\sigma^2}K
  \]
  がわかる。
\end{proof}







\begin{prob}\label{prob: 8.2}
\end{prob}

\begin{proof}
  \(L_i = \frac{2r}{2r+\sigma^2}K_i \ , \ (i=1,2)\)とおく。
  このとき、式(8.3.11)と式(8.3.12)より、
  \[
  v_1(x) =
  \begin{cases}
    K_1-x \ , \ (0\leq x \leq L_1), \\
    (K_1-L_1)\left( \frac{x}{L_1}\right)^{-\frac{2r}{\sigma^2}} \ , \ (L_1\leq x),
  \end{cases}
  \ \ \ \ \
  v_2(x) =
  \begin{cases}
    K_2-x \ , \ (0\leq x \leq L_2), \\
    (K_2-L_2)\left( \frac{x}{L_2}\right)^{-\frac{2r}{\sigma^2}} \ , \ (L_2\leq x),
  \end{cases}
  \]
  となる。
  \(v_2\)は行使価格が\(K_2\)である永久アメリカン・プット価格に対する
  線形相補条件 (式(8.3.18)) を満たすので、
  \[
  v_2(x) \geq (K_2-x)^+ \geq (K_1-x)^+
  \]
  がわかり、とくに式(8.8.1)が成立する。
  また、式(8.3.16)と式(8.3.17)より
  \[
  rv_2(x) - rxv'_2(x) - \frac{1}{2}\sigma^2x^2v''_2(x) =
  \begin{cases}
    0 \ , \ (x > L_2), \\
    rK_2 \ , \ (0\leq x < L_2),
  \end{cases}
  \]
  であるから、特に式(8.8.2)も成立する。
  さらに
  \(K_1 < K_2\)であることに注意すれば\(L_1 < L_2\)であり、
  また\(\sigma > 0\)であることに注意すれば\(L_1 < K_1\)であるから、
  \(L_1 < x < \min\{ K_1, L_2\}\)となる\(x\)に対しては
  \[
  v_2(x) = K_2 - x > K_1 - x = ( K_1-x )^+
  \]
  と
  \[
  rv_2(x) - rxv'_2(x) - \frac{1}{2}\sigma^2x^2v''_2(x) = rK_2 > 0
  \]
  が成立する。
  特に条件(8.8.3)は満たされない。
\end{proof}








\begin{prob}\label{prob: 8.3}
  \begin{enumerate}
    \item \label{enumi: 8.3-1}
    \item \label{enumi: 8.3-2}
    \item \label{enumi: 8.3-3}
    \item \label{enumi: 8.3-4}
    \item \label{enumi: 8.3-5}
    \item \label{enumi: 8.3-6}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 8.3-1}。
  誘導に従って\(p\)を決めても良いが、
  練習のためにも普通に解く。
  式(8.8.4)に\(x=e^t\)を代入すれば
  \[
  rv(e^t) - re^tv'(e^t) - \frac{1}{2}\sigma^2e^{2t}v''(e^t) = 0
  \]
  となる。
  ここで\((v(e^t))' = e^tv'(e^t)\)と
  \[
  (v(e^t))'' = \left( e^tv'(e^t) \right)'
  = e^tv'(e^t) + e^{2t}v''(e^t)
  = (v(e^t))' + e^{2t}v''(e^t)
  \]
  に注意すれば、上の方程式は
  \[
  0 = rv(e^t) - r(v(e^t))'
  - \frac{1}{2}\sigma^2\left( (v(e^t))'' - (v(e^t))'\right)
  = rv(e^t) + \left( \frac{1}{2}\sigma^2-r\right) (v(e^t))'
  - \frac{1}{2}\sigma^2(v(e^t))''
  \]
  と整理できる。
  \(w(t) = v(e^t)\)とおけば
  \[
  \frac{1}{2}\sigma^2\frac{d^2}{dt^2}w
  - \left( \frac{1}{2}\sigma^2-r\right) \frac{d}{dt}w - rw = 0
  \]
  であり、これは定数係数の微分方程式である。
  \begin{align*}
    0 &= \left[ \frac{1}{2}\sigma^2 \left( \frac{d}{dt} - 1\right) \frac{d}{dt}
    + r\left( \frac{d}{dt} - 1 \right) \right] w \\
    &= \left[ \left( \frac{1}{2}\sigma^2 \frac{d}{dt} + r \right)
    \left( \frac{d}{dt} - 1 \right) \right] w
  \end{align*}
  と整理して\(w\)の係数を\(=0\)とし、
  \(\frac{d}{dt}\)に関する方程式として解けば、
  \(\frac{d}{dt} = 1 , -\frac{2r}{\sigma^2}\)である。
  これに\(w\)を右からかけると
  \[
  \frac{d}{dt}w = w \ , \ \frac{d}{dt}w = -\frac{2r}{\sigma^2}w
  \]
  を得て、このような\(w\)は\(w=e^t, e^{-\frac{2r}{\sigma^2}t}\)となる。
  特に\(w\)に関する上記の微分方程式の解は
  \(e^t\)と\(e^{-\frac{2r}{\sigma^2}t}\)の線形結合である。
  同様に、\(t=\log x\)を代入することで、
  \(v\)は\(x, x^{-\frac{2r}{\sigma^2}}\)の線形結合であることがわかる。
  以降、
  \[
  v(x) = Ax^{-\frac{2r}{\sigma^2}} + Bx
  \]
  と置く。

  \ref{enumi: 8.3-2}。
  そのような\(0<x_1<x_2<\infty\)が存在したとする。
  \[
  v'(x) = - \frac{2r}{\sigma^2}Ax^{-\frac{2r}{\sigma^2}-1} + B
  \]
  であるから、
  \begin{align*}
    &v(x) \xrightarrow{x\to x_1+}
    Ax_1^{-\frac{2r}{\sigma^2}} + Bx_1, \\
    &v(x) \xrightarrow{x\to x_1-}
    (K-x_1)^+, \\
    &v'(x) \xrightarrow{x\to x_1+}
    - \frac{2r}{\sigma^2}Ax_1^{-\frac{2r}{\sigma^2}-1} + B, \\
    &v'(x) \xrightarrow{x\to x_1-}
    -1 , (x_1 \leq K) \ , \ 0 , (x_1 > K), \\
    &v(x) \xrightarrow{x\to x_2-}
    Ax_2^{-\frac{2r}{\sigma^2}} + Bx_2, \\
    &v(x) \xrightarrow{x\to x_2+}
    (K-x_2)^+, \\
    &v'(x) \xrightarrow{x\to x_2-}
    - \frac{2r}{\sigma^2}Ax_2^{-\frac{2r}{\sigma^2}-1} + B, \\
    &v'(x) \xrightarrow{x\to x_2+}
    -1 , (x_2 \leq K) \ , \ 0 , (x_2 > K),
  \end{align*}
  となる。

  \(x_1 < x_2 \leq K\)のとき。
  \(v\)と\(v'\)の連続性から
  \begin{align*}
    &Ax_1^{-\frac{2r}{\sigma^2}} + Bx_1
    = K - x_1, \\
    &- \frac{2r}{\sigma^2}Ax_1^{-\frac{2r}{\sigma^2}-1} + B
    = -1, \\
    &Ax_2^{-\frac{2r}{\sigma^2}} + Bx_2
    = K - x_2, \\
    &- \frac{2r}{\sigma^2}Ax_2^{-\frac{2r}{\sigma^2}-1} + B
    = -1,
  \end{align*}
  を得る。
  第二式の両辺に\(\frac{\sigma^2}{2r}x_1\)をかけて
  第一式と両辺足し合わせると、
  \[K = x_1(B-1)\left( 1+\frac{\sigma^2}{2r} \right)\]
  を得る。
  \(x_2\)の方でも同じことをすれば
  \[K = x_2(B-1)\left( 1+\frac{\sigma^2}{2r} \right)\]
  を得る。
  \(x_1\neq x_2, K > 0\)であるから、
  これらの等式が同時に成立することはない。

  \(x_1 \leq K \leq x_2\)のときも同様に
  \[
  x_1(B-1)\left( 1+\frac{\sigma^2}{2r} \right)
  = K =
  x_2\left( B\left( 1+\frac{\sigma^2}{2r} \right) + 1 \right)
  \]
  を得るが、これらから\(B > 1\)がわかり、
  すると\(x_1 < x_2\)より
  \[
  x_1(B-1)\left( 1+\frac{\sigma^2}{2r} \right)
  < x_2B\left( 1+\frac{\sigma^2}{2r} \right)
  < x_2\left( B\left( 1+\frac{\sigma^2}{2r} \right) + 1 \right)
  \]
  となって矛盾である。

  \(K \leq x_1 < x_2\)のときも同様に
  \[
  x_1\left( B\left( 1+\frac{\sigma^2}{2r} \right) + 1 \right)
  = K =
  x_2\left( B\left( 1+\frac{\sigma^2}{2r} \right) + 1 \right)
  \]
  を得るが\(x_1 < x_2\)より矛盾である。

  \ref{enumi: 8.3-3}。
  もしそのような\(x_2\)があれば\(v(0)=0\)となるがそれは
  \(K>0\)という仮定に反する。

  \ref{enumi: 8.3-4}。
  これは\ref{enumi: 8.3-3}で示している通り。

  \ref{enumi: 8.3-5}。
  導関数が\(x=K\)で連続にならないから。

  \ref{enumi: 8.3-6}。
  \(x_1 \geq K\)と仮定すると\(v'\)が\(x=K\)で連続とならないため矛盾。
  従って\(x_1 < K\)である。
  \(x > x_1\)のもとでは
  \[
  v(x) = Ax^{-\frac{2r}{\sigma^2}} + Bx
  \]
  であるが、
  \(x\to \infty\)とすれば、
  \(v(x)\)の有界性より\(B=0\)がわかる。
  また、\(v,v'\)の連続性から、
  \begin{align*}
    &Ax_1^{-\frac{2r}{\sigma^2}} = K-x_1 \\
    &-\frac{2r}{\sigma^2}Ax_1^{-\frac{2r}{\sigma^2}-1}
    = -1
  \end{align*}
  を得る (\(x_1<K\)に注意)。
  第一式より
  \[
  A = x_1^{\frac{2r}{\sigma^2}}(K-x_1)
  \]
  となる。
  第二式に代入すれば、
  \[
  -1 = -\frac{2r}{\sigma^2}x_1^{\frac{2r}{\sigma^2}}(K-x_1)
  x_1^{-\frac{2r}{\sigma^2}-1}
  = -\frac{2r(K-x_1)}{x_1\sigma^2}
  \]
  を得る。
  これを整理して
  \(x_1\sigma^2 = 2rK-2rx_1\)となり、
  よって\(x_1(\sigma^2+2r)=2rK\)を得る。
  以上より、\(L_*\)の定義から
  \[x_1 = \frac{2r}{2r+\sigma^2}K = L_*\]
  となり、また
  \[
  v(x) = Ax^{-\frac{2r}{\sigma^2}}
  = (K-x_1)x_1^{\frac{2r}{\sigma^2}}x^{-\frac{2r}{\sigma^2}}
  = (K-L_*)\left( \frac{x}{L_*}\right)^{-\frac{2r}{\sigma^2}}
  \]
  となる。
  以上で全て示された。
\end{proof}






\begin{prob}\label{prob: 8.4}
  \begin{enumerate}
    \item \label{enumi: 8.4-1}
    \item \label{enumi: 8.4-2}
    \item \label{enumi: 8.4-3}
    \item \label{enumi: 8.4-4}
    \item \label{enumi: 8.4-5}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 8.4-1}。
  単純計算。
  \begin{align*}
    &f'(x) = - \frac{2r}{\sigma^2}Ax^{- \frac{2r}{\sigma^2} - 1} + B, \\
    &f''(x) = - \frac{2r}{\sigma^2}\left( - \frac{2r}{\sigma^2} - 1\right)
    Ax^{- \frac{2r}{\sigma^2} - 2},
  \end{align*}
  であるから、
  \begin{align*}
    &rf - rxf' - \frac{1}{2}\sigma^2x^2f'' \\
    &= r \left( Ax^{-\frac{2r}{\sigma^2}}+Bx \right)
    - rx \left( - \frac{2r}{\sigma^2}Ax^{- \frac{2r}{\sigma^2} - 1} + B \right)
    - \frac{1}{2}\sigma^2x^2
    \frac{2r}{\sigma^2}\left( \frac{2r}{\sigma^2} + 1 \right)
    Ax^{- \frac{2r}{\sigma^2} - 2} \\
    &= rAx^{-\frac{2r}{\sigma^2}} + rBx
    + \frac{2r^2}{\sigma^2}Ax^{-\frac{2r}{\sigma^2}} - rBx
    - r\left( \frac{2r}{\sigma^2} + 1 \right)
    Ax^{-\frac{2r}{\sigma^2}} \\
    &= 0
  \end{align*}
  となる。

  \ref{enumi: 8.4-2}。
  不定元\(A,B\)に関する二元連立一次方程式
  \begin{align*}
    &AL^{-\frac{2r}{\sigma^2}} + BL = K-L, \\
    &-\frac{2r}{\sigma^2}AL^{-\frac{2r}{\sigma^2}-1} + B = -1,
  \end{align*}
  は解を持つ。
  実際に解くと、二つ目の式に\(L\)をかけて一つ目から引くことで
  \[
  \left(1+\frac{2r}{\sigma^2}\right) A L^{-\frac{2r}{\sigma^2}} = K
  \]
  となるので\(A\)が求まり、二つ目の式に代入すると\(B\)も求まる。
  具体的には、
  \begin{align*}
    &A = \frac{\sigma^2}{2r+\sigma^2}KL^{\frac{2r}{\sigma^2}}, \\
    &B = \frac{2r}{2r+\sigma^2}KL^{-1} - 1,
  \end{align*}
  となる。

  \ref{enumi: 8.4-3}。
  まず\(g(x) = f(x) + x\)とおく。
  \(g(L) = f(L) + L = K\)である。
  所望の結果を得るには、次の二つを示せば良い：
  \begin{enumerate}
    \item \label{enumi: 8.4-3-1}
    \(L\leq x \leq K\)に対して
    \(g(x) \geq K\)である。
    \item \label{enumi: 8.4-3-2}
    \(K\leq x\)に対して\(f(x) \geq 0\)である。
  \end{enumerate}
  \ref{enumi: 8.4-3-1}が成立するには
  \(L \leq x \leq K\)において\(g'(x) \geq 0\)であることが十分である。
  微分を計算すると、\ref{enumi: 8.4-2}の計算結果より
  \(A,B > 0\)であるから、
  \begin{align*}
    g'(x) &= f'(x) + 1 \\
    &= Ax^{-\frac{2r}{\sigma^2}-1} + B + 1 \\
    &> 0
  \end{align*}
  となる。以上で\ref{enumi: 8.4-3-1}が成立することがわかった。
  \ref{enumi: 8.4-3-2}も同様に、\(A,B > 0\)であるから、
  \begin{align*}
    f(x) &= Ax^{-\frac{2r}{\sigma^2}} + Bx > 0
  \end{align*}
  となる。

  \ref{enumi: 8.4-4}。
  \(v\)の定義から明らか。

  \ref{enumi: 8.4-5}。
  これは\autoref{prob: 8.3} \ref{enumi: 8.3-6}で既に示していることである。
\end{proof}












\begin{prob}\label{prob: 8.5}
  \begin{enumerate}
    \item \label{enumi: 8.5-1}
    \item \label{enumi: 8.5-2}
    \item \label{enumi: 8.5-3}
    \item \label{enumi: 8.5-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 8.5-1}。
  \(x = S(0)\)とおく。
  \(x \leq L\)であれば直ちに権利行使するので、
  このときのペイオフは\((K-x)^+\)である。
  \(x \leq L < K\)なので\((K-x)^+ = K-x\)であり、
  よって\(v_L(x) = K-x , (x \leq L)\)である。
  \(x > L\)における\(v_L(x)\)の挙動を調べる。

  \(S\)に関する確率微分方程式(8.8.9)を解けば
  \[
  S(t) = x\exp \left( \left( r-a-\frac{1}{2}\sigma^2\right) t
  + \sigma \tilde{W}(t)\right)
  \]
  となる。
  よって
  \begin{itemize}
    \item[ \ ]
    \(S(t) \leq L\),
    \item[\(\iff\)]
    \(\left( r-a-\frac{1}{2}\sigma^2\right) t
    + \sigma \tilde{W}(t) \leq \log \left( \frac{L}{x}\right) \),
    \item[\(\iff\)]
    \(\log\left( \frac{x}{L} \right) \leq
    - \left( r-a-\frac{1}{2}\sigma^2\right) t - \sigma\tilde{W}(t)\),
    \item[\(\iff\)]
    \(\frac{1}{\sigma}\log\left( \frac{x}{L} \right) \leq
    - \frac{r-a-\frac{1}{2}\sigma^2}{\sigma}t - \tilde{W}(t)\),
  \end{itemize}
  である。
  ここで
  \begin{alignat*}{3}
    &\mu & &\dfn \frac{-r+a+\frac{1}{2}\sigma^2}{\sigma}, \\
    &m & &\dfn \frac{1}{\sigma}\log\left( \frac{x}{L} \right), \\
    &\tau_m & &\dfn \min\{ t \geq 0 \mid -\tilde{W}(t) \geq m\}, \\
    &\gamma & &\dfn \frac{1}{\sigma^2}\left( r-a-\frac{1}{2}\sigma^2 \right)
    + \frac{1}{\sigma}\sqrt{\frac{1}{\sigma^2}
    \left( r-a-\frac{1}{2}\sigma^2\right)^2 + 2r} \\
    & & &= \frac{1}{\sigma}\left( -\mu + \sqrt{\mu^2 + 2r}\right),
  \end{alignat*}
  とおく。
  \(\tau_m\)はブラウン運動\(-\tilde{W}(t)\)
  (\(\tilde{W}(t)\)はブラウン運動なので\(-\tilde{W}(t)\)もブラウン運動となる)
  の\(m\)への到達時刻であり、
  \(\gamma\)は本書内で定義されているものと同じである。
  \(x > L , \sigma > 0\)であるから、
  \(m > 0\)となっていることに注意する。

  このオプションのペイオフは\(K-S(\tau_m) = K-L\)であることに注意。
  利率\(r\)なので、割引かれたペイオフは\((K-L)e^{-r\tau_m}\)である。
  従ってこのペイオフのリスク中立測度における期待値は、
  定理8.3.2を用いて計算すれば、
  \begin{align*}
    v_L(x) &\dfn \tilde{\E}\left[(K-L)e^{-r\tau_m}\right] \\
    &= (K-L) \tilde{\E}\left[e^{-r\tau_m}\right] \\
    &= (K-L) \exp\left( - m\left( -\mu + \sqrt{\mu^2 + 2r}\right)\right) \\
    &= (K-L) \exp\left( - m\sigma\lambda\right) \\
    &= (K-L) \left( \frac{x}{L}\right)^{-\lambda}
  \end{align*}
  となる。

  \ref{enumi: 8.5-2}。
  \(v_L(x)\)を\(L\)の関数として微分すれば
  \[
  \frac{d}{dL}v_L(x) =
  \begin{cases}
    0 \ , \ &(x \leq L), \\
    x^{-\lambda}L^{\lambda-1}
    \left(\lambda K - (\lambda + 1)L\right) \ , \ &(x \geq L),
  \end{cases}
  \]
  であるから、\(L\)に関する関数として\(v_L(x)\)は
  \(0\leq L \leq \frac{\lambda}{\lambda+1}K\)において増加し、
  \(L=\frac{\lambda}{\lambda+1}K\)で極値をとり、
  \(\frac{\lambda}{\lambda+1}K < L < x\)で減少して、
  \(x\leq L\)で一定の値\(K-x\)をとる。
  従って\(L\)の関数としての\(v_L(x)\)の最大値は
  \(L=\frac{\lambda}{\lambda+1}K\)の時に達成される。
  以上より\(L_*=\frac{\lambda}{\lambda+1}K\)である。

  \ref{enumi: 8.5-3}。
  まずはじめに、\(\lambda\)は二次方程式
  \[
  \lambda^2 + \frac{2}{\sigma^2}\left( -r+a+\frac{1}{2}\sigma^2\right)\lambda
  - \frac{2r}{\sigma^2} = 0
  \]
  の解の一つであることに注意しておく。

  \(e^{-rt}v_{L_*}(S(t))\)の微分を計算すると、
  \(dS = (r-a)Sdt + \sigma Sd\tilde{W},
  (dS)^2 = \sigma^2S^2dt\)であるから、
  \begin{align*}
    d\left( e^{-rt}v_{L_*}(S)\right)
    &= e^{-rt} \left( d(v_{L_*}(S)) - rv_{L_*}(S)dt \right) \\
    &= e^{-rt} \left( - rv_{L_*}(S)dt
    + v_{L_*}'(S)dS + \frac{1}{2}v_{L_*}''(S) (dS)^2 \right) \\
    &= e^{-rt} \left( - rv_{L_*}(S)
    + (r-a)Sv_{L_*}'(S) + \frac{1}{2}\sigma^2S^2v_{L_*}''(S) \right) dt
    + (\text{何らか})d\tilde{W}
  \end{align*}
  である。
  ここで\((\text{何らか})d\tilde{W}\)の項の積分は
  \(\tilde{\P}\)のもとでマルチンゲールであるから、
  \(dt\)項の係数が正でなければ
  \(e^{-rt}v_{L_*}(S(t))\)の優マルチンゲール性がわかる。
  \(S(t) < L_*\)であれば
  \(v'_{L_*}(S(t)) = -1, v''_{L_*}(S(t)) = 0\)であるから、
  \begin{align*}
    &- rv_{L_*}(S)
    + (r-a)Sv_{L_*}'(S) + \frac{1}{2}\sigma^2S^2v_{L_*}''(S) \\
    &= - r(K-S(t)) - (r-a)S(t) \\
    &= -rK + aS(t) \\
    &< -rK + aL_* \\
    &= -rK + a\frac{\lambda}{\lambda+1}K \\
    &< K\left( a - r\right) \\
    &< 0
  \end{align*}
  となる。
  \(S(t) > L_*\)であれば、
  \begin{align*}
    &v'_{L_*}(S(t))
    = -\lambda\frac{K-L_*}{L_*}\left(\frac{S(t)}{L_*}\right)^{-\lambda-1}, \\
    &v''_{L_*}(S(t))
    = \lambda(\lambda+1)\frac{K-L_*}{L_*^2}
    \left(\frac{S(t)}{L_*}\right)^{-\lambda-2},
  \end{align*}
  となるので、
  \begin{align*}
    &- rv_{L_*}(S)
    + (r-a)Sv_{L_*}'(S) + \frac{1}{2}\sigma^2S^2v_{L_*}''(S) \\
    &= -r(K-L_*)
    - (r-a)S(t)\lambda\frac{K-L_*}{L_*}\left(\frac{S(t)}{L_*}\right)^{-\lambda-1}
    + \frac{1}{2}\sigma^2S^2\lambda(\lambda+1)\frac{K-L_*}{L_*^2}
    \left(\frac{S(t)}{L_*}\right)^{-\lambda-2} \\
    &= (K-L_*)\left( \frac{S(t)}{L_*}\right)^{-\lambda}
    \left( -r - \lambda(r-a) + \frac{1}{2}\sigma^2\lambda(\lambda+1) \right) \\
    &= \frac{1}{2}(K-L_*)\sigma^2\left( \frac{S(t)}{L_*}\right)^{-\lambda}
    \left( \lambda^2
    + \frac{2}{\sigma^2}\left( -r+a+\frac{1}{2}\sigma^2\right)\lambda
    - \frac{2r}{\sigma^2}\right) \\
    &= 0
  \end{align*}
  となる。
  \(S(t) = L_*\)となる確率は\(0\)であるからこの場合は無視して良い。
  以上よりどの場合においても\(dt\)の係数は正でないことがわかった。
  従って\(e^{-rt}v_{L_*}(S(t))\)は優マルチンゲールである。
  また\(S(0) > L_*\)から開始する確率過程\(e^{-rt}v_{L_*}(S(t))\)が
  \(S(t) = L_*\)となる時刻で停止すれば、
  \(S(t) > L_*\)において\(dt\)の係数が\(0\)であることから
  この過程はマルチンゲールとなる。
  以上で全て示された。

  \ref{enumi: 8.5-4}。
  系8.3.6の証明を真似る。
  \(\tau_{L_*}\)を\(S(t)\)が\(L_*\)に到達する時刻を表す確率変数とする。
  つまりこれは\(L=L_*\)のときの\(\tau_m\)である。
  関数\(v_{L_*}\)の定義と
  \(\mcT\)がすべての到達時刻の集合であることから、
  \begin{align*}
    v_{L_*}(x)
    &= (K-L_*)\tilde{\E}\left[ e^{-r\tau_{L_*}}\right] \\
    &= \left( K-S(\tau_{L_*}) \right) \tilde{\E}\left[ e^{-r\tau_{L_*}}\right] \\
    &= \tilde{\E}\left[ \left( K-S(\tau_{L_*}) \right) e^{-r\tau_{L_*}}\right] \\
    &\leq \max_{\tau\in \mcT}
    \tilde{\E}\left[ \left( K-S(\tau) \right) e^{-r\tau}\right]
  \end{align*}
  がわかる。
  逆向きの不等号を証明する。
  \(v_{L_*}(x)\)の優マルチンゲール性と任意抽出定理 (定理8.2.4) より、
  任意の停止時刻\(\tau\)に対して
  確率過程
  \(e^{-r(t\wedge\tau)}v_{L_*}\left(S(t\wedge \tau)\right)\)
  は優マルチンゲールであり、
  従って任意の時刻\(t\)に対して
  \begin{align*}
    v_{L_*}(x)
    &= v_{L_*}(S(0)) \\
    &= e^{-r(0\wedge\tau)}v_{L_*}(S(0\wedge\tau)) \\
    &\geq \tilde{\E}\left[
    e^{-r(t\wedge\tau)}v_{L_*}\left(S(t\wedge \tau)\right) \right]
  \end{align*}
  がわかる。
  ここで\(t\to \infty\)とすることで
  \[
  v_{L_*}(x) \geq \tilde{\E}\left[
  e^{-r\tau}v_{L_*}\left(S(\tau)\right) \right]
  \]
  を得る。
  停止時刻\(\tau\)は任意だったので、以上より
  \[
  v_{L_*}(x) \geq \max_{\tau\in\mcT}\tilde{\E}\left[
  e^{-r\tau}v_{L_*}\left(S(\tau)\right) \right]
  \]
  を得る。
  これは所望の不等式である。
\end{proof}










\begin{prob}\label{prob: 8.6}
\end{prob}

\begin{proof}
  まず関数\((x-K)^+\)は凸関数であることに注意する
  (図8.5.1を見る)。
  よって補題8.5.1より
  確率過程\(e^{-rt}\left( S(t)-K \right)^+\)は劣マルチンゲールである。
  従って定理8.8.1より、
  任意の時刻\(t\)と任意の停止時刻\(\tau\in\mcT_{0,T}\)に対して
  \(\tau\)の取りうる値が\([0,T]\)内であるかまたは\(\infty\)であることから、
  \begin{align*}
    \tilde{\E}\left[ e^{-rT}\left( S(T)-K \right)^+ \right]
    &\geq \tilde{\E}\left[ e^{-r(T\wedge \tau)}
    \left( S(T\wedge\tau)-K \right)^+ \right] \\
    &\geq \tilde{\E}\left[ e^{-r\tau}
    \left( S(\tau)-K \right)^+ \right]
  \end{align*}
  となる。
  停止時刻\(\tau\)は任意だったので
  \[
  \tilde{\E}\left[ e^{-rT}\left( S(T)-K \right)^+ \right]
  \geq \max_{\tau\in\mcT_{0,T}}\tilde{\E}\left[ e^{-r\tau}
  \left( S(\tau)-K \right)^+ \right]
  \]
  を得る。
  逆向きの不等式を証明する。
  確率変数\(\tau'\)として
  一定値\(\tau' = T\)となるものを考えれば
  \(\tau'\in\mcT_{0,T}\)であるから
  \[
  \tilde{\E}\left[ e^{-rT}\left( S(T)-K \right)^+ \right]
  = \tilde{\E}\left[ e^{-r\tau'}\left( S(\tau')-K \right)^+ \right]
  \leq \max_{\tau\in\mcT_{0,T}}\tilde{\E}\left[ e^{-r\tau}
  \left( S(\tau)-K \right)^+ \right]
  \]
  となる。
  以上で示された。
\end{proof}













\begin{prob}\label{prob: 8.7}
\end{prob}

\begin{proof}
  まず任意の\(x\geq 0\)に対して
  \(h(x) \geq f(x),g(x)\)であることに注意する。
  任意の\(0\leq x_1\leq x_2\)に対して
  \[
  h(x_1) \geq f(x_1),g(x_1), \ \ \ h(x_2) \geq f(x_2),g(x_2)
  \]
  を得て、従って任意の\(a,b > 0, a+b=1\)で線形に足し合わせれば
  \[
  ah(x_1)+bh(x_2) \geq af(x_1)+bf(x_2) , ag(x_1)+bg(x_2)
  \]
  を得る。
  右辺のうち大きい方を選択しても不等式は成立するので、
  \[
  ah(x_1)+bh(x_2) \geq \max\{ af(x_1)+bf(x_2) , ag(x_1)+bg(x_2) \}
  \]
  となる。
  一方、\(f,g\)は凸なので
  \[
  af(x_1)+bf(x_2) \geq f(ax_1+bx_2), \ \ \
  ag(x_1)+bg(x_2) \geq g(ax_1+bx_2),
  \]
  となり、
  両辺のうち大きい方をとることで
  \[
  \max\{ af(x_1)+bf(x_2) , ag(x_1)+bg(x_2) \}
  \geq \max\{ f(ax_1+bx_2),g(ax_1+bx_2) \}
  \]
  を得る。
  ここで\(h\)の定義より右辺は\(h(ax_1+bx_2)\)に他ならない。
  以上より
  \begin{align*}
    ah(x_1)+bh(x_2)
    &\geq \max\{ af(x_1)+bf(x_2) , ag(x_1)+bg(x_2) \} \\
    &\geq \max\{ f(ax_1+bx_2),g(ax_1+bx_2) \} \\
    &= h(ax_1+bx_2)
  \end{align*}
  が得られ、これは所望の結果である。
\end{proof}













\newpage

\section{基準財の変更}\label{section: 9}




\begin{prob}\label{prob: 9.1}
  \begin{enumerate}
    \item \label{enumi: 9.1-1}
    \item \label{enumi: 9.1-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 9.1-1}。
  与えられたfiltrationを\(\mcF(t)\)とおく。
  まず定義から
  \[
  \frac{d\P^{(M_2)}}{d\P} = M_2(T)
  \]
  である。つまり\(M_2(T)\)は\(\P^{(M_2)}\)の\(\P\)に対する
  ラドン-ニコディム微分である。
  また\(M_2(t)\)はマルチンゲールであるから、
  \(M_2\)はラドン-ニコディム微分過程である。
  従って補題5.2.2より、
  \(0\leq s\leq t\leq T\)に対して、
  \begin{align*}
    \E^{(M_2)}\left[ \frac{M_1(t)}{M_2(t)} \middle| \mcF(s)\right]
    &= \frac{1}{M_2(s)}
    \E\left[ \frac{M_1(t)}{M_2(t)}\cdot M_2(t) \middle| \mcF(s)\right] \\
    &= \frac{1}{M_2(s)}\E\left[ M_1(t) \middle| \mcF(s)\right] \\
    &= \frac{M_1(s)}{M_2(s)}
  \end{align*}
  となる。
  最後の等号は\(M_1\)が\(\P\)に関してマルチンゲールであることによる。
  以上より\(M_1(t)/M_2(t)\)は\(\P^{(M_2)}\)に関してマルチンゲールとなる。

  \ref{enumi: 9.1-2}。
  \begin{align*}
    &M_1(t) \dfn \frac{D(t)}{N(0)}S(t), \\
    &M_2(t) \dfn \frac{D(t)}{N(0)}N(t), \\
  \end{align*}
  と定義すれば、\(M_2(0) = 1, M_2(t) > 0\)であり、
  また\(D(t)S(t), D(t)N(t)\)が\(\tilde{\P}\)のもとでマルチンゲールであることから、
  \(M_1(t),M_2(t)\)も\(\tilde{\P}\)のもとでマルチンゲールである。
  従ってこれらは注意9.2.5の仮定を満たす。
  また、\(M_1(t)/M_2(t) = S(t)/N(t) = S^{(N)}(t)\)となる。
  よって\ref{enumi: 9.1-1}より
  \(S^{(N)}(t)\)は\(\tilde{\P}^{(N)}\)のもとでマルチンゲールである。
  以上で示された。
\end{proof}










\begin{prob}\label{prob: 9.2}
  \begin{enumerate}
    \item \label{enumi: 9.2-1}
    \item \label{enumi: 9.2-2}
    \item \label{enumi: 9.2-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 9.2-1}。
  普通に計算する。
  \[
  dN = \nu Nd\tilde{W} + rNdt
  \]
  なので、\((dN)^2 = \nu^2N^2dt\)であり、
  \begin{align*}
    d\left( \frac{1}{N} \right)
    &= -\frac{1}{N^2}dN + \frac{1}{N^3}(dN)^2 \\
    &= -\frac{1}{N}\left(\nu d\tilde{W} + rt \right) + \frac{\nu^2}{N}dt \\
    &= -\frac{\nu}{N}d\tilde{W}
    + \frac{1}{N}(\nu^2 - r)dt \\
    &= -\frac{\nu}{N}d\hat{W} - \frac{r}{N}dt
  \end{align*}
  となる。

  \ref{enumi: 9.2-2}。
  普通に計算すると、\(dM = rMdt\)であるから、
  \begin{align*}
    d\left(\frac{M}{N}\right)
    &= \frac{1}{N}dM + Md\left( \frac{1}{N} \right)
    + dMd\left( \frac{1}{N} \right) \\
    &= \frac{1}{N}rMdt
    + M\left( -\frac{\nu}{N}d\hat{W} - \frac{r}{N}dt \right) \\
    &= -\frac{\nu}{N}Md\hat{W} \\
    &= -\nu\hat{M}d\hat{W} \\
  \end{align*}
  となる。

  \ref{enumi: 9.2-3}。
  まず示すべき等式の左辺を計算する。
  次に注意する：
  \begin{itemize}
    \item
    \(\frac{S}{M},\frac{N}{M},\frac{X}{M}\)
    はどれも\(\tilde{\P}\)についてマルチンゲールである。
  \end{itemize}
  これは\(S,N\)については既に何度も使っている事実であり、
  \(X\)についても本文中で示されているが、普通に微分を計算しても証明できる
  (この事実は今までに何度も用いている)。
  よって
  \(M_1(t) = \frac{X(t)}{N(0)M(t)}, M_2(t) = \frac{N(t)}{N(0)M(t)}\)
  に対して\autoref{prob: 9.1} \ref{enumi: 9.1-1}を用いれば、
  \(\hat{X}\)が\(\hat{\P}\)についてマルチンゲールであることがわかる。
  以上より
  \[
  d\hat{X} = Yd\hat{W}
  \]
  と置くことができる。
  次に\(d\left( N\hat{X}\right) = dX\)を二通りの方法で計算する。
  \(dN = \nu N d\hat{W} + (\text{何らか})dt\)であるから、
  \begin{align*}
    d\left( N\hat{X}\right)
    &= Nd\hat{X} + \hat{X}dN + dNd\hat{X} \\
    &= NYd\hat{W} + \nu N\hat{X}d\hat{W}
    + \nu N Y\left( d\hat{W}\right)^2 + (\text{何らか})dt \\
    &= \left( NY + \nu N\hat{X} \right) d\hat{W}
    + (\text{何らか})dt \\
    &= \left( NY + \nu X \right) d\hat{W}
    + (\text{何らか})dt \\
  \end{align*}
  となる。
  一方、式(9.7.1)を用いれば、
  \(dM = rMdt, dS = \sigma S d\hat{W} + (\text{何らか})dt\)であるから、
  \begin{align*}
    dX &= \Delta dS + \Gamma dM \\
    &= \sigma S \Delta d\hat{W} + (\text{何らか})dt
  \end{align*}
  となって、\(d\hat{W}\)の係数を比較することで
  \[
  NY + \nu X = \sigma S \Delta
  \]
  を得る。
  以上より
  \[
  Y = \frac{\sigma S \Delta - \nu X}{N}
  \]
  となる。

  次に示すべき等式の右辺を計算する。
  \(d\hat{S} = (\sigma - \nu)\hat{S}d\hat{W}\)と
  \ref{enumi: 9.2-2}より、
  \begin{align*}
    \Delta d\hat{S} + \Gamma d\hat{M}
    &= \left( (\sigma - \nu)\hat{S}\Delta - \nu\hat{M}\Gamma \right) d\hat{W} \\
    &= \frac{1}{N}\left( \sigma S\Delta - \nu S\Delta
    - \nu M \Gamma \right) d\hat{W} \\
    &= \frac{1}{N}\left( \sigma S\Delta - \nu X \right) d\hat{W} \\
    &= Yd\hat{W} \\
    &= d\hat{X}
  \end{align*}
  となる。
  以上で示された。
\end{proof}















\begin{prob}\label{prob: 9.3}
  \begin{enumerate}
    \item \label{enumi: 9.3-1}
    \item \label{enumi: 9.3-2}
    \item \label{enumi: 9.3-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 9.3-1}。
  普通に計算する。
  \(d\left( \frac{1}{N} \right) = -\frac{1}{N^2}dN + (\text{何らか})dt\)
  であることと、
  \(dSdN = (\text{何らか})dt\)であることから、
  \begin{align*}
    \frac{d\left(S^{(N)}\right)}{S^{(N)}}
    &= \frac{1}{S^{(N)}}\left( \frac{1}{N}dS
    + S d\left( \frac{1}{N} \right)
    + dS d\left( \frac{1}{N} \right)\right) \\
    &= \frac{1}{S}dS - \frac{1}{N}dN + (\text{何らか})dt \\
    &= \sigma d\tilde{W}_1 - \nu d\tilde{W}_3 + (\text{何らか})dt
  \end{align*}
  となる。
  定数\(\gamma \neq 0\)に対して
  \[
  \tilde{W}_4 \dfn
  \frac{1}{\gamma}\left( \sigma \tilde{W}_1 - \nu \tilde{W}_3 \right)
  \]
  はマルチンゲールであるから、
  これがブラウン運動となるためには (Leviの定理より)
  二次変分が\(t\)であれば良い。
  そのような\(\gamma\)を求める。
  \begin{align*}
    \left( d\tilde{W}_4 \right)^2
    &= \frac{1}{\gamma^2}\left( \sigma d\tilde{W}_1 - \nu d\tilde{W}_3 \right)^2 \\
    &= \frac{1}{\gamma^2}\left( \sigma^2 + \nu^2 - 2\rho\sigma\nu \right) dt
  \end{align*}
  であるから、\(\gamma = \sqrt{\sigma^2 + \nu^2 - 2\rho\sigma\nu}\)
  に対して\(\tilde{W}_4\)は\(\tilde{\P}\)のもとでのブラウン運動となる。
  以上で示された。

  \ref{enumi: 9.3-2}。
  \(dN = rNdt + \nu N d\tilde{W}_3\)であるから、
  このような\(\tilde{W}_2\)を探す問題は
  \[
  \rho d\tilde{W}_1 + \sqrt{1-\rho^2}d\tilde{W}_2 = d\tilde{W}_3
  \]
  となるブラウン運動\(\tilde{W}_2\)を探す問題となる。
  \[
  d\tilde{W}_2
  = \frac{1}{\sqrt{1-\rho^2}}
  \left( \rho d\tilde{W}_1 + d\tilde{W}_3 \right)
  \]
  と書きなおして積分すれば、このような\(\tilde{W}_2\)は
  \[
  \tilde{W}_2
  = \frac{\rho}{\sqrt{1-\rho^2}}\tilde{W}_1
  + \frac{1}{\sqrt{1-\rho^2}}\tilde{W}_3
  \]
  とすることで得られることがわかる。

  \ref{enumi: 9.3-3}。
  二つの独立なブラウン運動\(\tilde{W}_1,\tilde{W}_2\)について
  定理9.2.2を用いる。
  \(S\)の方のボラティリティ・ベクトルは\((\sigma,0)\)であり、
  \(N\)の方のボラティリティ・ベクトルは\((\nu\rho, \nu\sqrt{1-\rho^2})\)である。
  定理9.2.2より、
  \(S^{(N)}\)のボラティリティ・ベクトル\((v_1,v_2)\)は
  その差であるから、
  \[
  (v_1,v_2) = (\sigma-\nu\rho,-\nu\sqrt{1-\rho^2})
  \]
  となる。
  また
  \[
  v_1^2+v_2^2
  = (\sigma-\nu\rho)^2 + \nu^2(1-\rho^2)
  = \sigma^2 - 2\nu\rho + \nu^2
  \]
  もわかる。
\end{proof}












\begin{prob}\label{prob: 9.4}
\end{prob}

\begin{proof}
  次に注意：
  \begin{align*}
    &d\tilde{W}_1^f = d\tilde{W}_1 - \sigma_2 \rho du, \\
    &d\tilde{W}_3^f = d\tilde{W}_3 - \sigma_2 \rho du, \\
    &d\tilde{W}_1d\tilde{W}_3 = \rho du, \\
    &dS = S(Rdu + \sigma_1d\tilde{W}_1), \\
    &d\left( M^fQ \right) = M^fQ(Rdu + \sigma_2d\tilde{W}_3), \\
    &D^f = (M^f)^{-1}, \\
    &d(M^{-1}) = d\left(e^{-\int_0^tR(u)du}\right) = -RM^{-1}du.
  \end{align*}
  これらはいずれも定義そのものであったり、本文中に書いてあることである。
  \(T = M^fQ\)とおく。
  示さなければならないのは次の二つの等式である：
  \begin{align*}
    &d\left( \frac{M}{T} \right)
    = -\frac{M}{T}\sigma_2d\tilde{W}_3^f, \\
    &d\left( \frac{S}{T} \right)
    = \frac{S}{T}\left( \sigma_1d\tilde{W}_1^f - \sigma_2d\tilde{W}_3^f\right).
  \end{align*}
  まず一つ目の等式から証明する。
  \(X=\frac{T}{M}\)とおく。
  示したいことは
  \[d\left( \frac{1}{X}\right) = - \frac{1}{X}\sigma_2d\tilde{W}_3^f\]
  である。
  \(d\left( M^{-1} \right) = -RM^{-1}du\)であるから、
  \begin{align*}
    dX
    &= M^{-1}dT - RTM^{-1}du \\
    &= M^{-1}(dT - RTdu) \\
    &= M^{-1}T\sigma_2d\tilde{W}_3 \\
    &= \sigma_2Xd\tilde{W}_3
  \end{align*}
  となる。
  よって\((dX)^2 = \sigma_2^2X^2dt\)となり、
  \begin{align*}
    d\left( \frac{1}{X} \right)
    &= -\frac{1}{X^2}dX + \frac{1}{X^3}(dX)^2 \\
    &= -\frac{1}{X^2}\sigma_2Xd\tilde{W}_3
    + \frac{1}{X^3}\sigma_2^2X^2dt \\
    &= -\frac{\sigma_2}{X}\left( d\tilde{W}_3 - \sigma_2dt \right) \\
    &= -\frac{\sigma_2}{X}d\tilde{W}_3^f \\
  \end{align*}
  となる。これは所望の結果である。

  二つ目の等式を証明する。
  \(Y = \frac{S}{M}\)と置く。
  計算したいのは\(d\left( \frac{Y}{X} \right)\)である。
  \(X\)のときと同様に
  \begin{align*}
    dY
    &= M^{-1}dS - RSM^{-1}du \\
    &= M^{-1}(dS - RSdu) \\
    &= M^{-1}S\sigma_1d\tilde{W}_1 \\
    &= \sigma_1Yd\tilde{W}_1
  \end{align*}
  となる。
  \(d\tilde{W}_1d\tilde{W}_3^f
  = d\tilde{W}_1(d\tilde{W}_3-\sigma_2du)
  = d\tilde{W}_1d\tilde{W}_3
  = \rho du\)
  であるから、よって
  \begin{align*}
    d\left( \frac{Y}{X} \right)
    &= Yd\left( \frac{1}{X} \right)
    + \frac{1}{X}dY + d\left( \frac{1}{X} \right)dY \\
    &= -Y\frac{\sigma_2}{X}d\tilde{W}_3^f
    + \frac{1}{X}\sigma_1Yd\tilde{W}_1
    + \frac{\sigma_2}{X}d\tilde{W}_3^f\sigma_1Yd\tilde{W}_1 \\
    &= \frac{Y}{X}\left( \sigma_1d\tilde{W}_1 - \sigma_2d\tilde{W}_3^f\right)
    + \frac{\sigma_1\sigma_2Y}{X}d\tilde{W}_1d\tilde{W}_3^f \\
    &= \frac{Y}{X}\left( \sigma_1d\tilde{W}_1^f
    - \sigma_2d\tilde{W}_3^f + \sigma_1\sigma_2\rho du \right)
    + \frac{\sigma_1\sigma_2Y}{X}\rho du \\
    &= \frac{Y}{X}\left( \sigma_1d\tilde{W}_1^f - \sigma_2d\tilde{W}_3^f \right)
  \end{align*}
  となる。
  これは所望の計算結果である。
  以上で全て示された。
\end{proof}










\begin{prob}\label{prob: 9.5}
  \begin{enumerate}
    \item \label{enumi: 9.5-1}
    \item \label{enumi: 9.5-2}
    \item \label{enumi: 9.5-3}
    \item \label{enumi: 9.5-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 9.5-1}。
  確率微分方程式(9.3.1)を解く問題。
  まず式(9.3.1)より
  \[
  (dS)^2 = \sigma_1^2S^2 \left( d\tilde{W}_1 \right)^2 = \sigma_1^2S^2du
  \]
  であることに注意。
  金利の過程\(R\)は定数\(r\)なので、
  \(d\left(\log S\right)\)を計算すると、
  \begin{align*}
    d\left(\log S\right)
    &= \frac{1}{S}dS - \frac{1}{2S^2}(dS)^2 \\
    &= \frac{1}{S}S\left( rdu + \sigma_1d\tilde{W}_1\right)
    - \frac{1}{2S^2}\sigma_1^2S^2du \\
    &= \sigma_1d\tilde{W}_1 + \left( r - \frac{1}{2}\sigma_1^2 \right) du
  \end{align*}
  となるので、これを\(\int_0^t\)で積分すれば、
  \[
  \log\frac{S(t)}{S(0)}
  = \sigma_1\tilde{W}_1(t)
  + \int_0^t\left( r-\frac{1}{2}\sigma_1^2 \right) du
  = \sigma_1\tilde{W}_1(t)
  + \left( r-\frac{1}{2}\sigma_1^2 \right) t
  \]
  となる。
  整理すれば
  \[
  S(t) = S(0)\exp\left( \sigma_1\tilde{W}_1(t)
  + \left( r-\frac{1}{2}\sigma_1^2 \right) t\right)
  \]
  となることがわかる。

  \ref{enumi: 9.5-2}。
  \(\sigma_1\)を\(\sigma_2\)でおきかえ、
  \(\tilde{W}_1\)を\(\tilde{W}_3\)でおきかえ、
  \(r\)を\(r-r^f\)で置き換えて
  \ref{enumi: 9.5-1}と全く同様の計算をすることで
  \[
  Q(t) = Q(0)\exp\left( \sigma_2\tilde{W}_3(t)
  + \left( r-r^f-\frac{1}{2}\sigma_2^2 \right) t\right)
  \]
  となることがわかるが、
  ここで\(\tilde{W}_3 = \rho\tilde{W}_1 + \sqrt{1-\rho^2}\tilde{W}_2\)
  を代入すれば所望の式を得る。

  \ref{enumi: 9.5-3}。
  \ref{enumi: 9.5-1}と\ref{enumi: 9.5-2}で得られた結果の両辺を割り、
  さらに\(\tilde{W}_4\)や\(\sigma_4,a\)などで置き換えれば所望の結果を得る。
  \(\tilde{W}_4\)がブラウン運動であることは二次変分を計算すればわかる。

  \ref{enumi: 9.5-4}。
  \(X = S/Q\)とおけば、これは
  \[
  dX = (r-a)Xdt + \sigma_4Xd\tilde{W}_4
  \]
  を満たす。
  クウォント・コールのペイオフが\((X(T)-K)^+\)であることから、
  求めるクウォント・コールの時刻\(t\)での価格は、
  原資産価格が\(X(t)\)で表される
  ヨーロピアン・コール・オプションの時刻\(t\)での価格と等しい。
  従って初期値を\(X(0)=x\)とおけば、
  この価格は式(5.5.12)によって求められる。
  これは求める結果である。
\end{proof}












\begin{prob}\label{prob: 9.6}
  \begin{enumerate}
    \item \label{enumi: 9.6-1}
    \item \label{enumi: 9.6-2}
    \item \label{enumi: 9.6-3}
    \item \label{enumi: 9.6-4}
    \item \label{enumi: 9.6-5}
    \item \label{enumi: 9.6-6}
    \item \label{enumi: 9.6-7}
    \item \label{enumi: 9.6-8}
    \item \label{enumi: 9.6-9}
    \item \label{enumi: 9.6-10}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 9.6-1}。
  式を眺めるだけ。

  \ref{enumi: 9.6-2}。
  式(9.4.10)を眺めて\ref{enumi: 9.6-1}の結果を代入すると
  \[
  d_+ + d_- = \frac{2}{\sigma\sqrt{T-t}}\log\frac{\mathrm{For}_S(t,T)}{K}
  = \frac{2}{d_+ - d_-}\log\frac{\mathrm{For}_S(t,T)}{K}
  \]
  となるので両辺に\(d_+ - d_-\)をかければ所望の結果を得る。

  \ref{enumi: 9.6-3}。
  \ref{enumi: 9.6-2}の結果の両辺を\(e\)の肩に乗せて整理するだけ。

  \ref{enumi: 9.6-4}。
  式(9.4.10)をそのまま微分する。
  まず\(d\left( \log \frac{\mathrm{For}_S(t,T)}{K} \right)\)を計算すると、
  \begin{align*}
    &d\left( \log \frac{\mathrm{For}_S(t,T)}{K} \right) \\
    &= d\left( \log \mathrm{For}_S(t,T) - \log K \right) \\
    &= d \left( \log \mathrm{For}_S(t,T) \right) \\
    &= \frac{1}{\mathrm{For}_S(t,T)} d\mathrm{For}_S(t,T)
    - \frac{1}{\mathrm{For}_S(t,T)^2} \left( d\mathrm{For}_S(t,T)\right)^2 \\
    &\overset{\bigstar}{=} \sigma d\tilde{W}^T
    - \sigma^2\left( \tilde{W}^T\right)^2 \\
    &= \sigma d\tilde{W}^T - \sigma^2dt
  \end{align*}
  となる。
  ここで\(\bigstar\)の箇所は式(9.4.8)を用いた。
  従って、
  \begin{align*}
    &dd_+(t) \\
    &= d\left( \frac{1}{\sigma\sqrt{T-t}}\left(
    \log\frac{\mathrm{For}_S(t,T)}{K} + \frac{1}{2}\sigma^2(T-t)
    \right)\right) \\
    &= \log\frac{\mathrm{For}_S(t,T)}{K} \cdot
    d\left( \frac{1}{\sigma\sqrt{T-t}}\right)
    + \frac{1}{\sigma\sqrt{T-t}}d\left( \log\frac{\mathrm{For}_S(t,T)}{K} \right)
    + \frac{1}{2}d \left( \sigma\sqrt{T-t}\right) \\
    &= \log\frac{\mathrm{For}_S(t,T)}{K} \cdot
    \frac{-1}{2\sigma^2}\left( -(T-t)^{-3/2} \right) dt \\
    &\ \ \ \ \ \
    + \frac{1}{\sigma\sqrt{T-t}}\sigma d\tilde{W}^T
    - \frac{1}{\sigma\sqrt{T-t}}\sigma^2dt
    + \frac{1}{2}\sigma \left( -\frac{1}{2}(T-t)^{-1/2} \right)dt \\
    &= \frac{1}{2\sigma^2(T-t)^{3/2}}\log\frac{\mathrm{For}_S(t,T)}{K} dt
    + \frac{1}{\sqrt{T-t}} d\tilde{W}^T
    - \frac{3}{4\sqrt{T-t}}\sigma dt
  \end{align*}
  となる。
  これは所望の結果である。

  \ref{enumi: 9.6-5}。
  \ref{enumi: 9.6-1}の結果の両辺に\(d\)をつけるだけ。

  \ref{enumi: 9.6-6}。
  二乗すると\(dt\)の係数は消えて\(d\tilde{W}^T\)の係数だけ二乗になって生き残る。
  このことを念頭におけば結果は\ref{enumi: 9.6-4}と\ref{enumi: 9.6-5}より明らかである。

  \ref{enumi: 9.6-7}。
  \(N'(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2},
  N''(x) = -\frac{x}{\sqrt{2\pi}}e^{-x^2/2}\)
  と\ref{enumi: 9.6-6}の結果である
  \[(dd_+)^2 = \frac{dt}{T-t}\]
  に注意すれば、
  \begin{align*}
    d\left( N(d_+)\right)
    &= N'(d_+)dd_+ + \frac{1}{2}N''(d_+)(dd_+)^2 \\
    &= \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}dd_+
    - \frac{1}{2}\frac{d_+}{\sqrt{2\pi}}e^{-d_+^2/2}(dd_+)^2 \\
    &= \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}dd_+
    - \frac{d_+}{2\sqrt{2\pi}}e^{-d_+^2/2}\frac{dt}{T-t} \\
    &= \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}dd_+
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}e^{-d_+^2/2}dt
  \end{align*}
  となる。これは所望の結果である。

  \ref{enumi: 9.6-8}。
  計算すると、
  \begin{align*}
    d\left( N(d_-)\right)
    &= N'(d_-)dd_- + \frac{1}{2}N''(d_-)(dd_-)^2 \\
    &= \frac{1}{\sqrt{2\pi}}e^{-d_-^2/2}dd_-
    - \frac{1}{2}\frac{d_-}{\sqrt{2\pi}}e^{-d_-^2/2}(dd_-)^2 \\
    &\overset{\bigstar}{=}
    \frac{1}{\sqrt{2\pi}}e^{-d_-^2/2}
    \left( dd_+ + \frac{\sigma}{2\sqrt{T-t}}dt\right)
    - \frac{d_-}{2\sqrt{2\pi}}e^{-d_-^2/2}\frac{dt}{T-t} \\
    &\overset{\spadesuit}{=}
    \frac{1}{\sqrt{2\pi}}e^{-d_-^2/2}dd_+
    + \frac{\sigma}{2\sqrt{2\pi(T-t)}}e^{-d_-^2/2}dt
    - \frac{d_+ - \sigma\sqrt{T-t}}{2(T-t)\sqrt{2\pi}}e^{-d_-^2/2}dt \\
    &= \frac{1}{\sqrt{2\pi}}e^{-d_-^2/2}dd_+
    + \frac{\sigma}{\sqrt{2\pi(T-t)}}e^{-d_-^2/2}dt
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}e^{-d_-^2/2}dt
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は\ref{enumi: 9.6-5}と\ref{enumi: 9.6-6}の結果を用い、
  \(\spadesuit\)の箇所は\ref{enumi: 9.6-1}の結果を用いた。
  これは所望の結果である。

  \ref{enumi: 9.6-9}。
  計算すると、
  \begin{align*}
    d\left( \mathrm{For}_S(t,T)\right) d\left( N(d_+) \right)
    &\overset{\bigstar}{=}
    \sigma \mathrm{For}_S(t,T)d\tilde{W}^T
    \left( \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}dd_+
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}e^{-d_+^2/2}dt \right) \\
    &\overset{\spadesuit}{=}
    \sigma \mathrm{For}_S(t,T)
    \left( \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}\frac{1}{T-t} \right)
    \left( d\tilde{W}^T \right)^2\\
    &= \frac{\sigma \mathrm{For}_S(t,T)}
    {\sqrt{2\pi (T-t)}} e^{-d_+^2/2} dt
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は式(9.4.10)と\ref{enumi: 9.6-7}の結果を用い、
  \(\spadesuit\)の箇所は
  等式\(dtdt = 0, dtd\tilde{W}^T=0\)と\ref{enumi: 9.6-4}の結果を用いた。

  \ref{enumi: 9.6-10}。
  今までの結果をあわせると、
  \begin{align*}
    &\mathrm{For}_S(t,T)dN(d_+)
    + d\left( \mathrm{For}_S(t,T)\right)dN(d_+) - KdN(d_-) \\
    &\overset{\bigstar}{=}
    \mathrm{For}_S(t,T)\left( \frac{1}{\sqrt{2\pi}}e^{-d_+^2/2}dd_+
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}e^{-d_+^2/2}dt \right) \\
    &\ \ \ \ \ \
    + \frac{\sigma \mathrm{For}_S(t,T)}
    {\sqrt{2\pi (T-t)}} e^{-d_+^2/2} dt \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    - K\left( \frac{1}{\sqrt{2\pi}}e^{-d_-^2/2}dd_+
    + \frac{\sigma}{\sqrt{2\pi(T-t)}}e^{-d_-^2/2}dt
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}e^{-d_-^2/2}dt \right) \\
    &\overset{\spadesuit}{=}
    \frac{1}{\sqrt{2\pi}}\mathrm{For}_S(t,T)e^{-d_+^2/2}dd_+
    - \frac{d_+}{2(T-t)\sqrt{2\pi}}\mathrm{For}_S(t,T)e^{-d_+^2/2}dt
    + \frac{\sigma \mathrm{For}_S(t,T)}
    {\sqrt{2\pi (T-t)}} e^{-d_+^2/2} dt \\
    &\ \ \ \ \ \
    - \frac{1}{\sqrt{2\pi}}\mathrm{For}_S(t,T)e^{-d_+^2/2}dd_+
    - \frac{\sigma}{\sqrt{2\pi(T-t)}}\mathrm{For}_S(t,T)e^{-d_+^2/2}dt
    + \frac{d_+}{2(T-t)\sqrt{2\pi}}\mathrm{For}_S(t,T)e^{-d_+^2/2}dt \\
    &= 0
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は第一項に\ref{enumi: 9.6-7}の結果を使って
  第二項に\ref{enumi: 9.6-9}の結果を使って
  第三項に\ref{enumi: 9.6-8}の結果を使った。
  また\(\spadesuit\)の箇所は\ref{enumi: 9.6-3}の結果を使い、
  最後は第一項と第四項、第二項と第六項、第三項と第五項が相殺する。
  以上で示された。
\end{proof}






















\newpage

\section{期間構造モデル}\label{section: 10}



\begin{prob}\label{prob: 10.1}
  \begin{enumerate}
    \item \label{enumi: 10.1-1}
    \item \label{enumi: 10.1-2}
    \item \label{enumi: 10.1-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.1-1}。
  これは伊藤積分の期待値が\(0\)であることを念頭において
  式(10.2.43)-(10.2.46)を眺めることでわかる。

  \ref{enumi: 10.1-2}。
  一つ目は伊藤積分の等長性を用いることで
  \begin{align*}
    \tilde{\E}I_1^2(t)
    &= \int_0^te^{2\lambda_1u}du \\
    &= \frac{1}{2\lambda_1}\left( e^{2\lambda_1t} - 1 \right)
  \end{align*}
  となる。

  二つ目を計算する。
  伊藤積分の等長性より、
  \begin{align*}
    \tilde{\E}\left[ I_1(t)I_2(t) \right]
    &= \frac{1}{2}\left( \tilde{\E}\left[ \left( I_1(t)+I_2(t) \right)^2 \right]
    - \tilde{\E}I_1(t) - \tilde{\E}I_2(t) \right) \\
    &= \frac{1}{2}\tilde{\E}\left[ \left(
    \int_0^t\left(e^{\lambda_1u}+e^{\lambda_2u}\right)
    d\tilde{W}_1(u)\right)^2\right] \\
    &\ \ \ \ \ \
    - \frac{1}{2}\tilde{\E}\left[ \left( \int_0^t e^{\lambda_1u}
    d\tilde{W}_1(u)\right)^2\right]
    - \frac{1}{2}\tilde{\E}\left[ \left( \int_0^t e^{\lambda_2u}
    d\tilde{W}_1(u)\right)^2\right]  \\
    &= \frac{1}{2}
    \int_0^t\left(e^{\lambda_1u}+e^{\lambda_2u}\right)^2 du
    - \frac{1}{2}\int_0^t e^{2\lambda_1u} du
    - \frac{1}{2}\int_0^t e^{2\lambda_2u} du \\
    &= \int_0^t e^{(\lambda_1 + \lambda_2)u} du \\
    &= \frac{1}{\lambda_1+\lambda_2}\left( e^{(\lambda_1+\lambda_2)t}-1\right)
  \end{align*}
  となる。

  三つ目を計算する。
  \(dI_1 = e^{\lambda_1u}d\tilde{W}_1,
  dI_3 = e^{\lambda_2u}d\tilde{W}_2\)
  であるから、
  \begin{align*}
    d\left(I_1I_3\right)
    &= I_1dI_3 + I_3dI_1 + dI_1dI_3 \\
    &= e^{\lambda_2u}I_1d\tilde{W}_2 + e^{\lambda_1u}I_3d\tilde{W}_1
    + e^{\lambda_1u}e^{\lambda_2u}d\tilde{W}_1d\tilde{W}_2 \\
    &= e^{\lambda_2u}I_1d\tilde{W}_2 + e^{\lambda_1u}I_3d\tilde{W}_1
  \end{align*}
  となる。
  これを\(\int_0^t\)で積分して平均をとれば、
  右辺は伊藤積分の和なので平均\(0\)であり、
  従って\(\tilde{\E}[I_1(t)I_3(t)] = 0\)がわかる。

  四つ目を計算するt。
  \(dI_4 = ue^{\lambda_1u}d\tilde{W}_1\)であるから、
  \begin{align*}
    d(I_1I_4)
    &= I_1dI_4+I_4dI_1+dI_1dI_4 \\
    &= ue^{\lambda_1u}I_1d\tilde{W}_1
    + e^{\lambda_1u}I_4d\tilde{W}_1
    + ue^{\lambda_1u}e^{\lambda_1u}d\tilde{W}_1d\tilde{W}_1 \\
    &= \left( ue^{\lambda_1u}I_1 + e^{\lambda_1u}I_4\right)d\tilde{W}_1
    + ue^{2\lambda_1u}du
  \end{align*}
  となる。
  これを\(\int_0^t\)で積分して平均を取れば、
  伊藤積分の部分は消えて、
  \begin{align*}
    \tilde{\E}[I_1(t)I_4(t)]
    &= \int_0^tue^{2\lambda_1u}du \\
    &= \left[ u\frac{1}{2\lambda_1}e^{2\lambda_1u}\right]_0^t
    - \int_0^t\frac{1}{2\lambda_1}e^{2\lambda_1u}du \\
    &= t\frac{1}{2\lambda_1}e^{2\lambda_1t}
    - \frac{1}{4\lambda_1^2}\left( e^{2\lambda_1t}-1 \right)
  \end{align*}
  となる。

  五つ目を計算する。
  \begin{align*}
    d(I_4^2)
    &= 2I_4dI_4 + \frac{1}{2}2dI_4dI_4 \\
    &= 2ue^{\lambda_1u}I_4d\tilde{W}_1
    + u^2e^{2\lambda_1u}du
  \end{align*}
  となるので、
  \begin{align*}
    \tilde{\E}[I_4^2(t)]
    &= \int_0^tu^2e^{2\lambda_1u}du \\
    &= \left[ u^2\frac{1}{2\lambda_1}e^{2\lambda_1u}\right]_0^t
    - \int_0^t2u\frac{1}{2\lambda_1}e^{2\lambda_1u}du \\
    &= \frac{1}{2\lambda_1}t^2e^{2\lambda_1t}
    - \frac{1}{\lambda_1}\left[
    u\frac{1}{2\lambda_1}e^{2\lambda_1u}\right]_0^t
    + \frac{1}{\lambda_1}\int_0^t\frac{1}{2\lambda_1}e^{2\lambda_1u}du \\
    &= \frac{1}{2\lambda_1}t^2e^{2\lambda_1t}
    - \frac{1}{2\lambda_1^2}te^{2\lambda_1t}
    + \frac{1}{2\lambda_1^2}\frac{1}{2\lambda_1}
    \left( e^{2\lambda_1u}-1 \right) \\
    &= \frac{1}{2\lambda_1}t^2e^{2\lambda_1t}
    - \frac{1}{2\lambda_1^2}te^{2\lambda_1t}
    + \frac{1}{4\lambda_1^3}\left( e^{2\lambda_1u}-1 \right)
  \end{align*}
  となる。

  \ref{enumi: 10.1-3}。
  (ヒントに従った別解答の方が見る価値あり)。
  \[
  d\left(e^{\lambda_1u}\tilde{W}_1\right)
  = e^{\lambda_1u}d\tilde{W}_1 + \lambda_1e^{\lambda_1u}\tilde{W}_1du
  \]
  であるから
  \[
  I_1(s) = e^{\lambda_1s}\tilde{W}_1(s)
  - \lambda_1\int_0^se^{\lambda_1u}\tilde{W}_1(u)du
  \]
  である。
  同じく
  \[
  I_2(t) = e^{\lambda_2t}\tilde{W}_1(t)
  - \lambda_2\int_0^te^{\lambda_2u}\tilde{W}_1(u)du
  \]
  である。
  従って
  \begin{align*}
    I_1(s)I_2(t)
    &= \left( e^{\lambda_1s}\tilde{W}_1(s)
    - \lambda_1\int_0^se^{\lambda_1u}\tilde{W}_1(u)du\right)
    \left( e^{\lambda_2t}\tilde{W}_1(t)
    - \lambda_2\int_0^te^{\lambda_2u}\tilde{W}_1(u)du\right) \\
    &= e^{\lambda_1s+\lambda_2t}\tilde{W}_1(s)\tilde{W}_1(t) \\
    &\ \ \ \ \ \
    - \lambda_1e^{\lambda_2t}\int_0^s
    e^{\lambda_1u}\tilde{W}_1(t)\tilde{W}_1(u)du \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    - \lambda_2e^{\lambda_1s}\int_0^t
    e^{\lambda_2u}\tilde{W}_1(s)\tilde{W}_1(u)du \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + \lambda_1\lambda_2\int_0^s\int_0^t
    e^{\lambda_1u_1}e^{\lambda_2u_2}\tilde{W}_1(u_1)\tilde{W}_1(u_2)du_2du_1
  \end{align*}
  となる。
  最後の式の各項についてそれぞれ期待値を計算する。
  第一項は\(s<t\)であることから
  \[
  \tilde{\E}[e^{\lambda_1s+\lambda_2t}\tilde{W}_1(s)\tilde{W}_1(t)]
  = e^{\lambda_1s+\lambda_2t}\tilde{\E}[\tilde{W}_1(s)\tilde{W}_1(t)]
  = se^{\lambda_1s+\lambda_2t}
  \]
  となる。
  第二項は
  \begin{align*}
    &\tilde{\E}\left[ \lambda_1e^{\lambda_2t}\int_0^s
    e^{\lambda_1u}\tilde{W}_1(t)\tilde{W}_1(u)du\right] \\
    &= \lambda_1e^{\lambda_2t}\int_0^se^{\lambda_1u}
    \tilde{\E}\left[ \tilde{W}_1(t)\tilde{W}_1(u)\right] du \\
    &\overset{\bigstar}{=} \lambda_1e^{\lambda_2t}\int_0^sue^{\lambda_1u} du \\
    &= \lambda_1e^{\lambda_2t}
    \left( \left[ u\frac{1}{\lambda_1}e^{\lambda_1u}\right]_0^s
    - \int_0^s\frac{1}{\lambda_1}e^{\lambda_1u}du\right) \\
    &= \lambda_1e^{\lambda_2t}
    \left( \frac{1}{\lambda_1}se^{\lambda_1s}
    - \frac{1}{\lambda_1^2}\left( e^{\lambda_1s} - 1 \right)\right) \\
    &= se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_2t}\left( e^{\lambda_1s} - 1 \right) \\
    &= se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_1s+\lambda_2t}
    + \frac{1}{\lambda_1}e^{\lambda_2t}
  \end{align*}
  となる。
  ただし\(\bigstar\)の項は\(0\leq u \leq s < t\)であることによる。
  第三項は
  \begin{align*}
    &\tilde{\E}\left[ \lambda_2e^{\lambda_1s}\int_0^t
    e^{\lambda_2u}\tilde{W}_1(s)\tilde{W}_1(u)du \right] \\
    &= \lambda_2e^{\lambda_1s}\int_0^te^{\lambda_2u}
    \tilde{\E}\left[ \tilde{W}_1(s)\tilde{W}_1(u)\right] du \\
    &= \lambda_2e^{\lambda_1s}\int_0^te^{\lambda_2u} (s\wedge u) du \\
    &= \lambda_2e^{\lambda_1s}\left(
    \int_0^se^{\lambda_2u} u du + s\int_s^te^{\lambda_2u}du \right) \\
    &= \lambda_2e^{\lambda_1s}\left(
    \frac{1}{\lambda_2}se^{\lambda_2s}
    - \frac{1}{\lambda_2^2}\left( e^{\lambda_2s} - 1 \right)
    + s\frac{1}{\lambda_2}\left( e^{\lambda_2t}-e^{\lambda_2s} \right) \right) \\
    &= \lambda_2e^{\lambda_1s}\left(
    - \frac{1}{\lambda_2^2}\left( e^{\lambda_2s} - 1 \right)
    + s\frac{1}{\lambda_2}e^{\lambda_2t} \right) \\
    &= se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_2}e^{(\lambda_1+\lambda_2)s}
    + \frac{1}{\lambda_2}e^{\lambda_1s}
  \end{align*}
  となる。
  第四項は
  \begin{align*}
    &\tilde{\E}\left[ \lambda_1\lambda_2\int_0^s\int_0^t
    e^{\lambda_1u_1}e^{\lambda_2u_2}\tilde{W}_1(u_1)\tilde{W}_1(u_2)
    du_2du_1 \right] \\
    &= \lambda_1\lambda_2 \int_0^s\int_0^t e^{\lambda_1u_1}e^{\lambda_2u_2}
    \tilde{\E}\left[ \tilde{W}_1(u_1)\tilde{W}_1(u_2)\right] du_2du_1 \\
    &= \lambda_1\lambda_2 \int_0^s \int_0^t e^{\lambda_1u_1}e^{\lambda_2u_2}
    (u_1\wedge u_2) du_2du_1 \\
    &= \lambda_1\lambda_2 \int_0^s e^{\lambda_1u_1}
    \left( \int_0^{u_1} e^{\lambda_2u_2} u_2 du_2
    + \int_{u_1}^t e^{\lambda_2u_2} u_1 du_2\right) du_1 \\
    &= \lambda_1\lambda_2 \int_0^s e^{\lambda_1u_1}
    \left( \frac{1}{\lambda_2}u_1e^{\lambda_2u_1}
    - \frac{1}{\lambda_2^2}\left( e^{\lambda_2u_1} - 1 \right)
    + u_1\frac{1}{\lambda_2}\left( e^{\lambda_2t}-e^{\lambda_2u_1}\right)
    \right) du_1 \\
    &= \lambda_1\lambda_2 \int_0^s e^{\lambda_1u}
    \left(
    - \frac{1}{\lambda_2^2}\left( e^{\lambda_2u} - 1 \right)
    + u\frac{1}{\lambda_2}e^{\lambda_2t} \right) du \\
    &=
    - \frac{\lambda_1}{\lambda_2}\int_0^s e^{(\lambda_1+\lambda_2)u}du
    + \frac{\lambda_1}{\lambda_2}\int_0^s e^{\lambda_1u}du
    + \lambda_1e^{\lambda_2t} \int_0^s ue^{\lambda_1u}du \\
    &=
    - \frac{\lambda_1}{\lambda_2}
    \frac{1}{\lambda_1+\lambda_2}\left( e^{(\lambda_1+\lambda_2)s}-1\right) \\
    &\ \ \ \ \ \
    + \frac{\lambda_1}{\lambda_2}
    \frac{1}{\lambda_1}\left( e^{\lambda_1s} - 1\right) \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    + \lambda_1e^{\lambda_2t} \left( \frac{1}{\lambda_1}se^{\lambda_1s}
    - \frac{1}{\lambda_1^2}\left( e^{\lambda_1s} - 1 \right)\right) \\
    &=
    - \frac{\lambda_1}{\lambda_2(\lambda_1+\lambda_2)}e^{(\lambda_1+\lambda_2)s}
    + \frac{\lambda_1}{\lambda_2(\lambda_1+\lambda_2)} \\
    &\ \ \ \ \ \
    + \frac{1}{\lambda_2}e^{\lambda_1s} - \frac{1}{\lambda_2} \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    + se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_1s+\lambda_2t}
    + \frac{1}{\lambda_1}e^{\lambda_2t} \\
    &=
    - \frac{\lambda_1}{\lambda_2(\lambda_1+\lambda_2)}e^{(\lambda_1+\lambda_2)s}
    + \frac{1}{\lambda_2}e^{\lambda_1s}
    - \frac{1}{\lambda_1+\lambda_2}
    + se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_1s+\lambda_2t}
    + \frac{1}{\lambda_1}e^{\lambda_2t}
  \end{align*}
  となる。
  これらをあわせて、
  \begin{align*}
    &\tilde{\E}[I_1(s)I_2(t)] \\
    &= e^{\lambda_1s+\lambda_2t}\tilde{W}_1(s)\tilde{W}_1(t) \\
    &\ \ \ \ \ \
    - \lambda_1e^{\lambda_2t}\int_0^s
    e^{\lambda_1u}\tilde{W}_1(t)\tilde{W}_1(u)du \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    - \lambda_2e^{\lambda_1s}\int_0^t
    e^{\lambda_2u}\tilde{W}_1(s)\tilde{W}_1(u)du \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
    + \lambda_1\lambda_2\int_0^s\int_0^t
    e^{\lambda_1u_1}e^{\lambda_2u_2}\tilde{W}_1(u_1)\tilde{W}_1(u_2)du_2du_1 \\
    &= se^{\lambda_1s+\lambda_2t} \\
    &\ \ \ \
    - \left( se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_1s+\lambda_2t}
    + \frac{1}{\lambda_1}e^{\lambda_2t} \right) \\
    &\ \ \ \ \ \ \ \
    - \left( se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_2}e^{(\lambda_1+\lambda_2)s}
    + \frac{1}{\lambda_2}e^{\lambda_1s}\right) \\
    &\ \ \ \ \ \ \ \ \ \ \ \
    + \left( - \frac{\lambda_1}{\lambda_2(\lambda_1+\lambda_2)}e^{(\lambda_1+\lambda_2)s}
    + \frac{1}{\lambda_2}e^{\lambda_1s}
    - \frac{1}{\lambda_1+\lambda_2}
    + se^{\lambda_1s+\lambda_2t}
    - \frac{1}{\lambda_1}e^{\lambda_1s+\lambda_2t}
    + \frac{1}{\lambda_1}e^{\lambda_2t}\right) \\
    &= \left( \frac{1}{\lambda_2} -
    \frac{\lambda_1}{\lambda_2(\lambda_1+\lambda_2)}\right)
    e^{(\lambda_1+\lambda_2)s} - \frac{1}{\lambda_1+\lambda_2} \\
    &= \frac{1}{\lambda_1+\lambda_2}e^{(\lambda_1+\lambda_2)s}
    - \frac{1}{\lambda_1+\lambda_2}
  \end{align*}
  となる。

  \textbf{別解答}。
  ヒントに従う。
  \(dJ_1 = e^{\lambda_1u}\I_{u\leq s}d\tilde{W}_1,
  dI_2 = e^{\lambda_2u}d\tilde{W}_1\)であるから、
  \begin{align*}
    d(J_1I_2)
    &= I_2dJ_1+J_1dI_2+dJ_1dI_2 \\
    &= (\text{何らか})d\tilde{W}_1
    + e^{(\lambda_1+\lambda_2)u}\I_{u\leq s}\left( d\tilde{W}_1\right)^2 \\
    &= (\text{何らか})d\tilde{W}_1
    + e^{(\lambda_1+\lambda_2)u}\I_{u\leq s}du
  \end{align*}
  となる。
  \(s<t\)なので\(J_1(t)=I_1(s)\)となり、
  また伊藤積分の期待値が\(0\)であることから、
  従って
  \begin{align*}
    \tilde{\E}[I_1(s)I_2(t)]
    &= \tilde{\E}[J_1(t)I_2(t)] \\
    &= \tilde{\E}[\int_0^t e^{(\lambda_1+\lambda_2)u}\I_{u\leq s} du] \\
    &= \int_0^s e^{(\lambda_1+\lambda_2)u} du \\
    &= \frac{1}{\lambda_1+\lambda_2}e^{(\lambda_1+\lambda_2)s}
  \end{align*}
  となる。
\end{proof}











\begin{prob}\label{prob: 10.2}
  \begin{enumerate}
    \item \label{enumi: 10.2-1}
    \item \label{enumi: 10.2-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.2-1}。
  \(Y_1,Y_2\)の満たす連立の確率微分方程式
  (式(10.2.59)と式(10.2.60))
  は不確定な部分が\(Y_1,Y_2\)の関数で与えられているので、
  その解\(Y_1,Y_2\)はマルコフ過程となる
  (cf. 多次元版の定理6.3.1、つまり6.6節の文中に書いてあること)。
  従って、割引過程
  \(D(t)f(t,Y_1(t),Y_2(t))\)はマルチンゲールとなる。
  ここで\(D(t) = e^{-\int_0^tR(u)du}\)は割引過程で、
  \(R(t) = \delta_0+\delta_1Y_1(t)+\delta_2Y_2(t)\)は金利過程である。
  \(dD = -RDdt\)なので、従って
  \[
  d(Df) = Ddf - fdD = D (df-Rfdt)
  \]
  の\(dt\)の係数は消える。
  \(df\)を計算する。
  \begin{align*}
    &dY_1 = (\mu - \lambda_1 Y_1)dt + \sqrt{Y_1}d\tilde{W}_1, \\
    &dY_2 = -\lambda_2Y_2dt + \sigma_{2,1}\sqrt{Y_1}d\tilde{W}_1
    + \sqrt{\alpha-\beta Y_1}d\tilde{W}_2,
  \end{align*}
  であるから、
  \begin{align*}
    &(dY_1)^2 = Y_1dt, \\
    &(dY_2)^2 = \left( \sigma_{2,1}^2Y_1 + (\alpha-\beta Y_1)\right) dt, \\
    &dY_1dY_2 = \sigma_{2,1}Y_1dt,
  \end{align*}
  となり、従って\(f_{y_1,y_1}=f_{11},f_{y_2,y_2}=f_{22}\)とおけば、
  \begin{align*}
    df
    &= f_tdt + f_1dY_1 + f_2dY_2
    + \frac{1}{2}f_{11}(dY_1)^2
    + f_{12}dY_1dY_2
    + \frac{1}{2}f_{22}(dY_2)^2 \\
    &= f_tdt + (\mu-\lambda_1 Y_1)f_1dt - \lambda_2Y_2f_2dt
    + \frac{1}{2}Y_1f_{11}dt
    + \sigma_{21}Y_1f_{12}dt
    + \frac{1}{2}(\sigma_{21}^2Y_1 + \alpha + \beta Y_1)f_{22}dt \\
    &\ \ \ \ \ \
    + (\text{マルチンゲールの微分となる項})
  \end{align*}
  となる。
  \(dt\)の係数が\(-Rfdt=-(\delta_0+\delta_1Y_1+\delta_2Y_2)fdt\)であるから、従って
  \begin{align*}
    f_t + (\mu-\lambda_1 y_1)f_1 - \lambda_2y_2f_2
    + \frac{1}{2}y_1f_{11}
    + \sigma_{21}y_1f_{12}
    + \frac{1}{2}(\sigma_{21}^2y_1 + \alpha + \beta y_1)f_{22}
    = -(\delta_0+\delta_1y_1+\delta_2y_2)f
  \end{align*}
  となる。
  これが\(f\)の満たす偏微分方程式である。

  \ref{enumi: 10.2-2}。
  \(T-t = \tau\)とおく。
  \(f(t,y_1,y_2)
  = \exp\left( - y_1C_1(\tau) - y_2C_2(\tau) - A(\tau) \right)\)
  であるから、
  \begin{alignat*}{3}
    &f_t &
    &= f\cdot \frac{d}{dt}\left( - y_1C_1(\tau) - y_2C_2(\tau) - A(\tau)\right) \\
    & &
    &= \left( y_1C_1'(\tau) + y_2C_2'(\tau) + A'(\tau)\right) f, \\
    &f_1 & &= -C_1(\tau)f, \\
    &f_2 & &= -C_2(\tau)f, \\
    &f_{11} & &= C_1^2(\tau)f, \\
    &f_{12} & &= C_1(\tau)C_2(\tau)f, \\
    &f_{22} & &= C_2^2(\tau)f,
  \end{alignat*}
  となる。
  以降\(\tau\)を省略する。
  これらを\ref{enumi: 10.2-1}で得た方程式に代入して
  両辺を\(f(t,y_1,y_2)\)で割れば、
  \begin{align*}
    &\delta_0 + \delta_1y_1 + \delta_2y_2 \\
    &= y_1C_1' + y_2C_2' + A' - (\mu-\lambda_1 y_1)C_1 + \lambda_2y_2C_2
    + \frac{1}{2}y_1C_1^2
    + \sigma_{21}y_1C_1C_2
    + \frac{1}{2}(\sigma_{21}^2y_1 + \alpha + \beta y_1)C_2^2
  \end{align*}
  を得る。
  定数項と\(y_1,y_2\)の係数を比較すると、
  \begin{alignat*}{3}
    &\text{定数項：} & \ \ \ \
    &\delta_0 = A' - \mu C_1 + \alpha C_2^2,  \\
    &\text{\(y_1\)の係数：} & \ \ \ \
    &\delta_1 = C_1' + \lambda_1C_1 + \frac{1}{2}C_1^2
    + \sigma_{21}C_1C_2 + \frac{1}{2}(\sigma_{21}^2+\beta)C_2^2, \\
    &\text{\(y_2\)の係数：} & \ \ \ \
    &\delta_2 = C_2' + \lambda_2C_2,
  \end{alignat*}
  を得る。
  これらを整理すれば所望の連立微分方程式を得る。
\end{proof}












\begin{prob}\label{prob: 10.3}
  \begin{enumerate}
    \item \label{enumi: 10.3-1}
    \item \label{enumi: 10.3-2}
    \item \label{enumi: 10.3-3}
    \item \label{enumi: 10.3-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  めんどくさいので、
  最後の問題以外は\(t\)での微分をたんにダッシュで表す。

  \ref{enumi: 10.3-1}。
  まず\(T\)を固定して\(f\)の満たす偏微分方程式を求める。
  \(D(t) = \exp\left( -\int_0^tR(u)du\right)\)
  とおけば、
  \[D(t)B(t,T) = \tilde{\E}[D(T)\mid\mcF(t)]\]
  は反復条件付きの性質よりマルチンゲールである。
  従ってこれを微分すると\(dt\)の係数は消える。
  \(dD = -RDdt\)であるから
  \(d(Df) = D(df - Rfdt)\)であり、
  従って微分\(df\)における\(dt\)の係数は\(Rf\)となる。
  \(df\)を計算する。
  \begin{align*}
    &dY_1 = -\lambda_1Y_1dt + d\tilde{W}_1, \\
    &dY_2 = -(\lambda_{21}Y_1+\lambda_2Y_2)dt + d\tilde{W}_2,
  \end{align*}
  であるから、
  \begin{align*}
    &(dY_1)^2 = (dY_2)^2 = dt, \\
    &dY_1dY_2 = 0,
  \end{align*}
  となる。
  \(f_{y_1}=f_1,f_{y_2}=f_2,f_{y_i,y_j}=f_{ij}\)と略記する。
  以上より
  \begin{align*}
    df
    &= f_tdt + f_1dY_1 + f_2dY_2 + \frac{1}{2}f_{11}(dY_1)^2
    + f_{12}dY_1dY_2 + \frac{1}{2}f_{22}(dY_2)^2 \\
    &= \left( f_t -\lambda_1Y_1f_1 -(\lambda_{21}Y_1+\lambda_2Y_2)f_2
    + \frac{1}{2}f_{11} + \frac{1}{2}f_{22}\right)dt \\
    &\ \ \ \ \ \
    + (\text{マルチンゲールの微分となる項})
  \end{align*}
  となって、\(dt\)の係数が\(Rf\)であることから、
  \begin{align*}
    (\delta_0(t)+\delta_1y_1+\delta_2y_2)f
    &= f_t -\lambda_1y_1f_1 -(\lambda_{21}y_1+\lambda_2y_2)f_2
    + \frac{1}{2}f_{11} + \frac{1}{2}f_{22}
  \end{align*}
  を得る。

  この方程式に
  \[
  f(t,T,y_1,y_2) = \exp \left(
  -y_1C_1(t,T)-y_2C_2(t,T)-A(t,T)\right)
  \]
  を代入する。
  \begin{align*}
    &f_t = -(y_1C_1'(t,T)+y_2C_2'(t,T)+A'(t,T))f, \\
    &f_1 = -C_1(t,T)f, \\
    &f_2 = -C_2(t,T)f, \\
    &f_{11} = C_1^2(t,T)f, \\
    &f_{22} = C_2^2(t,T)f,
  \end{align*}
  であるから、これらを代入して\(f\)で割れば、
  \begin{align*}
    \delta_0(t)+\delta_1y_1+\delta_2y_2
    &= -(y_1C_1'+y_2C_2'+A')
    + \lambda_1y_1C_1 + (\lambda_{21}y_1+\lambda_2y_2)C_2
    + \frac{1}{2}C_1^2 + \frac{1}{2}C_2^2
  \end{align*}
  を得る。
  定数項と\(y_1,y_2\)の係数を比較して
  \begin{alignat*}{3}
    &\text{定数項：} & \ \ \ \
    &\delta_0(t) = - A' + \frac{1}{2}C_1^2 + \frac{1}{2}C_2^2, \\
    &\text{\(y_1\)の係数：} & \ \ \ \
    &\delta_1 = - C_1' + \lambda_1C_1 + \lambda_{21}C_2, \\
    &\text{\(y_2\)の係数：} & \ \ \ \
    &\delta_2 = - C_2' + \lambda_2C_2,
  \end{alignat*}
  を得る。

  \ref{enumi: 10.3-2}。
  まず\(C_2\)から求める。
  \(C_2 - \frac{\delta_2}{\lambda_2}\)は微分方程式
  \[
  \frac{d}{dt}\left( C_2 - \frac{\delta_2}{\lambda_2}\right)
  = C_2' = \lambda_2C_2 - \delta_2
  = \lambda_2\left( C_2 - \frac{\delta_2}{\lambda_2} \right)
  \]
  を満たすので、
  \[
  C_2(t,T) - \frac{\delta_2}{\lambda_2}
  = Ce^{\lambda_2t}
  \]
  とおける。
  ただしここで\(C\)は定数である。
  週末条件\(C(T,T)=0\)より
  \[
  - \frac{\delta_2}{\lambda_2} = Ce^{\lambda_2T}
  \]
  がわかり、これより
  \(C=-\frac{\delta_2}{\lambda_2}e^{-\lambda_2T}\)
  がわかる。
  以上より
  \[
  C_2(t,T)
  = - \frac{\delta_2}{\lambda_2}e^{-\lambda_2(T-t)}
  + \frac{\delta_2}{\lambda_2}
  \]
  となる。
  次に\(C_1\)を求める。
  \(e^{-\lambda_1t}C_1\)を微分すると、
  \begin{align*}
    \frac{d}{dt}\left( e^{-\lambda_1t}C_1(t,T)\right)
    &= e^{-\lambda_1t}\frac{d}{dt}C_1(t,T)
    - \lambda_1e^{-\lambda_1t}C_1(t,T) \\
    &= e^{-\lambda_1t}
    \left( \frac{d}{dt}C_1(t,T) - \lambda_1C_1(t,T) \right) \\
    &= e^{-\lambda_1t}
    \left( \lambda_{21}C_2(t,T) - \delta_1 \right) \\
    &= e^{-\lambda_1t}
    \left( - \frac{\delta_2}{\lambda_2}\lambda_{21}e^{-\lambda_2(T-t)}
    + \frac{\delta_2\lambda_{21}}{\lambda_2} - \delta_1 \right)
  \end{align*}
  となるので、これを\(\int_T^t\)で積分して
  週末条件\(C_1(T,T)=0\)を用いると、
  \begin{align*}
    &e^{-\lambda_1t}C_1(t,T) \\
    &= C_1(T,T) + \int_T^t\left( e^{-\lambda_1u}
    \left( - \frac{\delta_2}{\lambda_2}\lambda_{21}e^{-\lambda_2(T-u)}
    + \frac{\delta_2\lambda_{21}}{\lambda_2} - \delta_1 \right)
    \right) du \\
    &=
    - \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T}
    \int_T^t e^{(\lambda_2-\lambda_1)u} du
    + \left( \frac{\delta_2\lambda_{21}}{\lambda_2} - \delta_1 \right)
    \int_T^t e^{-\lambda_1u} du \\
    &= \left( \frac{\delta_2\lambda_{21}}{\lambda_2} - \delta_1 \right)
    \frac{1}{-\lambda_1}\left( e^{-\lambda_1t}-e^{-\lambda_1T} \right)
    + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T}
    \int_t^T e^{(\lambda_2-\lambda_1)u} du \\
    &=
    \begin{cases}
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)
      \left( e^{-\lambda_1T}-e^{-\lambda_1t} \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T}
      \frac{1}{\lambda_2-\lambda_1}
      \left( e^{(\lambda_2-\lambda_1)T}-e^{(\lambda_2-\lambda_1)t}\right),
      \ \ \ &(\lambda_1\neq \lambda_2) \\
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)
      \left( e^{-\lambda_1T}-e^{-\lambda_1t} \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T}(T-t),
      \ \ \ &(\lambda_1=\lambda_2),
    \end{cases}
  \end{align*}
  となる。
  両辺に\(e^{\lambda_1t}\)をかけると、
  \begin{align*}
    &C_1(t,T) \\
    &=
    \begin{cases}
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)\left( e^{-\lambda_1(T-t)}-1 \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T}
      \frac{1}{\lambda_2-\lambda_1}
      \left( e^{(\lambda_2-\lambda_1)T+\lambda_1t}
      -e^{(\lambda_2-\lambda_1)t+\lambda_1t}\right),
      \ \ \ &(\lambda_1\neq \lambda_2) \\
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)\left( e^{-\lambda_1(T-t)}-1 \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T+\lambda_1t}(T-t),
      \ \ \ &(\lambda_1=\lambda_2),
    \end{cases} \\
    &=
    \begin{cases}
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)\left( e^{-\lambda_1(T-t)}-1 \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2(T-t)}
      \frac{1}{\lambda_2-\lambda_1}
      \left( e^{(\lambda_2-\lambda_1)(T-t)}-1 \right),
      \ \ \ &(\lambda_1\neq \lambda_2) \\
      \left( \frac{\delta_2\lambda_{21}}{\lambda_1\lambda_2}
      - \frac{\delta_1}{\lambda_1} \right)\left( e^{-\lambda_1(T-t)}-1 \right)
      + \frac{\delta_2\lambda_{21}}{\lambda_2}e^{-\lambda_2T+\lambda_1t}(T-t),
      \ \ \ &(\lambda_1=\lambda_2),
    \end{cases}
  \end{align*}
  となる。
  ただし最後の式の二段目において
  \(\lambda_1=\lambda_2\)であれば
  \(e^{-\lambda_2T+\lambda_1t}\)という部分は
  \(T-t\)にのみ依存することに注意。

  \ref{enumi: 10.3-3}。
  \(A' = \frac{1}{2}C_1^2 + \frac{1}{2}C_2^2 - \delta_0(t)\)なので
  これを\(\int_T^t\)で積分して
  週末条件\(A(T,T)=0\)を用いると、
  \[
  A(t,T) = \int_t^T \left( \delta_0(s)
  - \frac{1}{2}\left( C_1^2(s,T) + C_2^2(s,T) \right)\right)ds
  \]
  となる。
  積分は計算しなくて良いようなのでここで終わっておく。
  \(C_1,C_2\)は求まっているので\(A\)も求められる。

  \ref{enumi: 10.3-4}。
  \[
  B(0,T) = f(0,T,Y_1(0),Y_2(0))
  = \exp\left( -Y_1(0)C_1(t,T)-Y_2(0)C_2(0,T)-A(0,T)\right)
  \]
  の両辺に\(\log\)をつければ
  \[
  \log B(0,T) = -Y_1(0)C_1(t,T)-Y_2(0)C_2(0,T)-A(0,T)
  \]
  となるので、\ref{enumi: 10.3-3}の結果を代入して
  \[
  \log B(0,T) = -Y_1(0)C_1(0,T)-Y_2(0)C_2(0,T)-
  \int_0^T \left( \delta_0(s)
  - \frac{1}{2}\left( C_1^2(s,T) + C_2^2(s,T) \right)\right)ds
  \]
  となる。
  \(T\)で微分すると、
  週末条件\(C_1(T,T)=C_2(T,T)=0\)に注意すれば、
  \begin{align*}
    \frac{\partial}{\partial T}\log B(0,T)
    &= - Y_1(0)\frac{\partial}{\partial T}C_1(0,T)
    - Y_2(0)\frac{\partial}{\partial T}C_2(0,T) - \delta_0(T) \\
    &\ \ \ \ \ \
    + \frac{1}{2}\frac{\partial}{\partial T}\int_0^T
    \left(C_1^2(s,T) + C_2^2(s,T)\right) ds \\
    &= - Y_1(0)\frac{\partial}{\partial T}C_1(0,T)
    - Y_2(0)\frac{\partial}{\partial T}C_2(0,T) - \delta_0(T) \\
    &\ \ \ \ \ \
    + \frac{1}{2}\left( \left(C_1^2(T,T) + C_2^2(T,T)\right)
    + \int_0^T \frac{\partial}{\partial T}
    \left(C_1^2(s,T) + C_2^2(s,T)\right) ds \right) \\
    &= - Y_1(0)\frac{\partial}{\partial T}C_1(0,T)
    - Y_2(0)\frac{\partial}{\partial T}C_2(0,T) - \delta_0(T) \\
    &\ \ \ \ \ \
    + \int_0^T \left( C_1(s,T)\frac{\partial}{\partial T} C_1(s,T)
    + C_2(s,T)\frac{\partial}{\partial T} C_2(s,T)\right) ds \\
  \end{align*}
  を得る。
  \(\frac{\partial}{\partial T}C_i(t,T) , i=1,2\)を計算する。
  関数\(C_i(t,T)\)は\(T-t\)にしか依存しないことに注意すれば、
  ある関数\(\bar{C}_i\)が存在して
  \(\bar{C}_i(T-t) = C_i(t,T)\)となる。
  この等式の両辺を\(t,T\)で微分する。
  \(\tau = T-t\)とおいて\(\bar{C}_i'(\tau)\)で
  \(\bar{C}_i\)の\(\tau\)での微分を表すと、
  \begin{align*}
    &\frac{\partial}{\partial t}C_i(t,T)
    = \frac{\partial}{\partial t}\bar{C}_i(T-t)
    = -\bar{C}_i'(\tau), \\
    &\frac{\partial}{\partial T}C_i(t,T)
    = \frac{\partial}{\partial T}\bar{C}_i(T-t)
    = \bar{C}_i'(\tau),
  \end{align*}
  となる。
  従って\(\frac{\partial}{\partial t}C_i(t,T)
  = -\frac{\partial}{\partial T}C_i(t,T)\)
  がわかる。
  以上と週末条件\(C_i(T,T)=0\)より、
  \begin{align*}
    &\int_0^T \left( C_1(s,T)\frac{\partial}{\partial T} C_1(s,T)
    + C_2(s,T)\frac{\partial}{\partial T} C_2(s,T)\right) ds \\
    &= - \int_0^T \left( C_1(s,T)\frac{\partial}{\partial s} C_1(s,T)
    + C_2(s,T)\frac{\partial}{\partial s} C_2(s,T)\right) ds \\
    &= - \frac{1}{2}\int_0^T \frac{\partial}{\partial s}
    \left( C_1^2(s,T) + C_2^2(s,T)\right) ds \\
    &= - \frac{1}{2}\int_0^T \frac{\partial}{\partial s}
    \left( C_1^2(s,T) + C_2^2(s,T)\right) ds \\
    &= \frac{1}{2}
    \left( C_1^2(0,T) + C_2^2(0,T)\right)
  \end{align*}
  これはモデルパラメーターを用いて表すことのできる式である
  (あまりに面倒な式で整理もできなさそうなのでこの計算は諦めた)。
  以上より
  \begin{align*}
    \delta_0(T)
    &= \frac{\partial}{\partial T}\log B(0,T)
    - Y_1(0)\frac{\partial}{\partial T}C_1(0,T)
    - Y_2(0)\frac{\partial}{\partial T}C_2(0,T) \\
    &\ \ \ \ \ \
    + \int_0^T \left( C_1(s,T)\frac{\partial}{\partial T} C_1(s,T)
    + C_2(s,T)\frac{\partial}{\partial T} C_2(s,T)\right) ds \\
    &= \frac{\partial}{\partial T}\log B(0,T)
    + Y_1(0)\frac{\partial}{\partial t}C_1(0,T)
    + Y_2(0)\frac{\partial}{\partial t}C_2(0,T)
    + \frac{1}{2}\left( C_1^2(0,T) + C_2^2(0,T)\right)
  \end{align*}
  となる。
  右辺の\(\frac{\partial}{\partial T}\log B(0,T)\)以外の項は
  すべて与えられた初期値\(Y_1(0),Y_2(0)\)と
  モデルパラメーターを用いて表すことのできる量である。

  \(\frac{\partial}{\partial t}C_i(0,T)\)を計算してみると
  次のようになったが計算ミスをしているかも：
  \begin{align*}
    \frac{\partial}{\partial t}C_1(0,T)
    &= -e^{-\lambda_1T}\delta_1
    + \frac{\lambda_1\delta_2\lambda_{21}}{\lambda_2}
    \left( e^{-\lambda_1T}-e^{-\lambda_2T}+e^{-\lambda_2T}T\right), \\
    \frac{\partial}{\partial t}C_2(0,T)
    &= -\frac{\delta_2}{\lambda_2}e^{-\lambda_2T}.
  \end{align*}
\end{proof}












\begin{prob}\label{prob: 10.4}
  \begin{enumerate}
    \item \label{enumi: 10.4-1}
    \item \label{enumi: 10.4-2}
    \item \label{enumi: 10.4-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  式(10.7.10)と式(10.7.11)の\(\tilde{B}_1,\tilde{B}_2\)は逆なんじゃないか？
  じゃないと式(10.7.12)が成り立たなさそう。

  \ref{enumi: 10.4-1}。
  \(\hat{X}\)の第一成分と第二成分をそれぞれ
  \(\hat{X}_1,\hat{X}_2\)とかけば、
  \(\hat{X}_1,\hat{X}_2\)は次で定義されている：
  \begin{align*}
    &\hat{X}_1(t) = U(t), \\
    &\hat{X}_2(t) = R(t) - e^{-\lambda_2t}\int_0^te^{\lambda_2u}\theta(u)du.
  \end{align*}
  それぞれ微分する。
  \(\hat{X}_1\)の微分は\(U\)の微分であるから
  \[
  d\hat{X}_1 = dU = -\lambda_1Udt + \sigma_1d\tilde{B}_1
  = -\lambda_1\hat{X}_1dt + \sigma_1d\tilde{B}_1
  \]
  である。
  \(\hat{X}_2\)の微分を計算するために
  \(e^{\lambda_2t}\hat{X}_2\)の微分を二通りの方法で計算すると、
  \begin{align*}
    d\left(e^{\lambda_2t}\hat{X}_2\right)
    &= e^{\lambda_2t}d\hat{X}_2 + \lambda_2e^{\lambda_2t}\hat{X}_2dt \\
    &= e^{\lambda_2t}d\hat{X}_2
    + \lambda_2e^{\lambda_2t}\hat{X}_2dt \\
    &= e^{\lambda_2t}\left( d\hat{X}_2 + \lambda_2\hat{X}_2dt \right), \\
    d\left(e^{\lambda_2t}\hat{X}_2\right)
    &= d\left( e^{\lambda_2t}R(t)
    - \int_0^te^{\lambda_2u}\theta(u)du\right) \\
    &= d\left( e^{\lambda_2t}R(t) \right)
    - e^{\lambda_2t}\theta dt \\
    &= e^{\lambda_2t}\left( dR + \lambda_2Rdt \right)
    - e^{\lambda_2t}\theta dt \\
    &= e^{\lambda_2t}\left( dR + \lambda_2Rdt - \theta dt \right) \\
    &= e^{\lambda_2t}\left( Udt + \sigma_2d\tilde{B}_2 \right) \\
    &= e^{\lambda_2t}\left( \hat{X}_1dt + \sigma_2d\tilde{B}_2 \right) \\
  \end{align*}
  となる。
  これらを比較すれば
  \[
  d\hat{X}_2 = - \lambda_2\hat{X}_2dt + \hat{X}_1dt + \sigma_2d\tilde{B}_2
  \]
  を得る。
  以上で
  \begin{align*}
    &d\hat{X}_1 = -\lambda_1\hat{X}_1dt + \sigma_1d\tilde{B}_1, \\
    &d\hat{X}_2 = - \lambda_2\hat{X}_2dt + \hat{X}_1dt + \sigma_2d\tilde{B}_2,
  \end{align*}
  となるが、これをベクトルの形で表記すれば
  所望の結果となっている。

  \ref{enumi: 10.4-2}。
  \(\tilde{W}_i\)は次で与えられている：
  \begin{align*}
    &\tilde{W}_1 = \tilde{B}_1, \\
    &\tilde{W}_2
    = - \frac{\rho}{\sqrt{1-\rho^2}}\tilde{B}_1
    + \frac{1}{\sqrt{1-\rho^2}}\tilde{B}_2.
  \end{align*}
  これらはマルチンゲールの線形結合なのでマルチンゲールである。
  従って、これらがブラウン運動であることを示すには二次変分を計算すれば良い。
  \(\tilde{W}_1\)は明らかにブラウン運動である。
  \((d\tilde{W}_2)^2\)を計算すると、
  \begin{align*}
    \left(d\tilde{W}_2\right)^2
    &= \left( - \frac{\rho}{\sqrt{1-\rho^2}}d\tilde{B}_1
    + \frac{1}{\sqrt{1-\rho^2}}d\tilde{B}_2\right)^2 \\
    &= \frac{\rho^2}{1-\rho^2}\left(d\tilde{B}_1\right)^2
    - 2\frac{\rho}{1-\rho^2}d\tilde{B}_1d\tilde{B}_2
    + \frac{1}{1-\rho^2}\left(d\tilde{B}_2\right)^2 \\
    &= \frac{\rho^2}{1-\rho^2}dt
    - 2\frac{\rho}{1-\rho^2}\rho dt
    + \frac{1}{1-\rho^2}dt \\
    &= dt
  \end{align*}
  となるので\(\tilde{W}_2\)もブラウン運動である。
  \(\tilde{W}_1,\tilde{W}_2\)が独立であることは
  \begin{align*}
    d\tilde{W}_1d\tilde{W}_2
    &= d\tilde{B}_1 \left(
    - \frac{\rho}{\sqrt{1-\rho^2}}d\tilde{B}_1
    + \frac{1}{\sqrt{1-\rho^2}}d\tilde{B}_2\right) \\
    &= - \frac{\rho}{\sqrt{1-\rho^2}}\left( d\tilde{B}_1 \right)^2
    + \frac{1}{\sqrt{1-\rho^2}}d\tilde{B}_1d\tilde{B}_2 \\
    &= - \frac{\rho}{\sqrt{1-\rho^2}}dt
    + \frac{1}{\sqrt{1-\rho^2}}\rho dt \\
    &= 0
  \end{align*}
  から従う。
  式(10.7.14)を示すには式(10.7.13)の両辺に\(C\)をかければ良い
  (\(C\)も\(\Sigma\)も定数であることに注意)：
  \begin{align*}
    dY
    &= d\left(C\hat{X}\right) \\
    &= Cd\hat{X} \\
    &= C\left( - K\hat{X}dt + \Sigma d\tilde{B} \right) \\
    &= - CK\hat{X}dt + C\Sigma d\tilde{B} \\
    &= - CKC^{-1}Ydt + d\left( C\Sigma \tilde{B}\right) \\
    &= - \Lambda Ydt + d\tilde{W}.
  \end{align*}
  以上で示された。

  \ref{enumi: 10.4-3}。
  \(L=e^{-Kt}\int_0^te^{Ku}\Theta(u)du\)とおく。
  すると
  \(\hat{X} = X - L\)となるので、
  \[C^{-1}Y + L = C^{-1}C\hat{X} + L = \hat{X} + L = X\]
  となる。
  ここで
  \[
  X = \left[
  \begin{array}{c}
    U \\
    R
  \end{array}
  \right]
  \]
  であるから、
  \(L,C^{-1}\)を求めることで
  金利過程\(R\)を\(Y_1,Y_2\)により線形な形で表記できることになる。

  まず\(C\)は求まっているので\(C^{-1}\)は単に逆行列を計算するだけであり、
  結果は
  \[
  C^{-1} = \left[
  \begin{array}{cc}
    \sigma_1 & 0 \\
    \sigma_2\rho & \sigma_2\sqrt{1-\rho^2}
  \end{array}
  \right]
  \]
  となる。\(Y\)を計算する。
  \[
  \Theta = \left[
  \begin{array}{c}
    0 \\
    \theta
  \end{array}
  \right]
  \]
  であるから、
  \[
  e^{Ku}\Theta(u) = \left[
  \begin{array}{c}
    0 \\
    e^{\lambda_2u}\theta(u)
  \end{array}
  \right]
  \]
  となり、
  従って、
  \[
  L = e^{-Kt}\int_0^te^{Ku}\Theta(u)du = \left[
  \begin{array}{c}
    0 \\
    e^{-\lambda_2t}\int_0^te^{\lambda_2u}\theta(u)du
  \end{array}
  \right]
  \]
  となる。
  以上より
  \[
  C^{-1}Y + L = \left[
  \begin{array}{c}
    \sigma_1Y_1 \\
    \sigma_2\rho Y_1 + \sigma_2\sqrt{1-\rho}Y_2 + e^{-\lambda_2t}\int_0^te^{\lambda_2u}\theta(u)du
  \end{array}
  \right]
  \]
  となる。
  よって
  \[
  R(t) = \sigma_2\rho Y_1(t) + \sigma_2\sqrt{1-\rho}Y_2(t) + e^{-\lambda_2t}\int_0^te^{\lambda_2u}\theta(u)du
  \]
  となる。
  とくに\(\delta_1 = \sigma_2\rho, \delta_2 = \sigma_2\sqrt{1-\rho}\)であり、
  \[
  \delta_0(t) = e^{-\lambda_2t}\int_0^te^{\lambda_2u}\theta(u)du
  \]
  となる。
\end{proof}













\begin{prob}\label{prob: 10.5}
\end{prob}

\begin{proof}
  まず\(C(t,T),A(t,T)\)は\(T-t\)にのみ依存する関数であることに注意する。
  すると、ある関数\(\bar{C},\bar{A}\)が存在して
  \begin{align*}
    &C(t,t+\bar{\tau}) = \bar{C}(\bar{\tau}), \\
    &A(t,t+\bar{\tau}) = \bar{A}(\bar{\tau}),
  \end{align*}
  となることがわかる。
  従って、とくに
  \begin{align*}
    L(t) &= -\frac{1}{\bar{\tau}}\log B(t,t+\bar{\tau}) \\
    &= -\frac{1}{\bar{\tau}}\left(
    -C(t,t+\bar{\tau})R(t) - A(t,t+\bar{\tau})\right) \\
    &= \frac{1}{\bar{\tau}}
    \left( \bar{C}(\bar{\tau})R(t) - \bar{A}(\bar{\tau})\right)
  \end{align*}
  となる。
  よって、\(0\leq t_1 < t_2\)に対して
  \begin{align*}
    L(t_2)-L(t_1)
    &= \frac{1}{\bar{\tau}}
    \left( \bar{C}(\bar{\tau})R(t_2) - \bar{A}(\bar{\tau})\right)
    - \frac{1}{\bar{\tau}}
    \left( \bar{C}(\bar{\tau})R(t_1) - \bar{A}(\bar{\tau})\right) \\
    &= \frac{1}{\bar{\tau}} \bar{C}(\bar{\tau})\left( R(t_2) - R(t_1) \right)
  \end{align*}
  となる。
  \(a = \frac{1}{\bar{\tau}} \bar{C}(\bar{\tau})\)とおくと、
  \begin{align*}
    &\Var (L(t_2)-L(t_1)) = a^2 \Var(R(t_2)-R(t_1)), \\
    &\Cov (L(t_2)-L(t_1),R(t_2)-R(t_1)) = a \Var(R(t_2)-R(t_1)),
  \end{align*}
  となることがわかり、
  以上より\(L(t_2)-L(t_1)\)と\(R(t_2)-R(t_1)\)の相関係数が\(1\)であることがわかる。
\end{proof}
















\begin{prob}\label{prob: 10.6}
  \begin{enumerate}
    \item \label{enumi: 10.6-1}
    \item \label{enumi: 10.6-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.6-1}の問題文中の確率微分方程式(10.7.16)は
  ボラティリティが\(\delta_1\)なんじゃないかと思う。

  \ref{enumi: 10.6-1}。
  \(\delta_2=0\)なので式(10.2.6)より
  \[
  R(t) = \delta_0 + \delta_1Y_1(t) + \delta_2Y_2(t)
  = \delta_0 + \delta_1Y_1(t)
  \]
  となる。
  \(Y_1\)について解けば
  \(Y_1 = \frac{1}{\delta_1}(R-\delta_0)\)
  であることに注意。
  一方、式(10.2.4)より
  \[
  dY_1 = - \lambda_1Y_1dt + d\tilde{W}_1
  \]
  なので、代入すれば
  \begin{align*}
    dR &= \delta_1dY_1 \\
    &= - \delta_1\lambda_1Y_1dt + \delta_1d\tilde{W}_1 \\
    &= - \delta_1\lambda_1\left( \frac{1}{\delta_1}(R-\delta_0)\right)dt
    + \delta_1d\tilde{W}_1 \\
    &= \left( \delta_0\lambda_1 - \lambda_1R\right)dt
    + \delta_1d\tilde{W}_1
  \end{align*}
  となる。
  とくに\(a = \delta_0\lambda_1, b = \lambda_1\)である。

  \ref{enumi: 10.6-2}。
  式(10.2.6)、つまり
  \(R = \delta_0 + \delta_1Y_1 + \delta_2Y_2\)
  をそのまま微分して条件を使うと、
  \begin{align*}
    dR &= \delta_1dY_1 + \delta_2dY_2 \\
    &= \delta_1\left( - \lambda_1 Y_1 + d\tilde{W}_1 \right)
    + \delta_2\left( -\lambda_{21}Y_1dt - \lambda_2Y_2dt + d\tilde{W}_2\right) \\
    &= \left( - (\lambda_1\delta_1 + \lambda_{21}\delta_2) Y_1
    - \lambda_2\delta_2Y_2 \right) dt
    + \delta_1d\tilde{W}_1 + \delta_2d\tilde{W}_2 \\
    &= \left( - \lambda_2\delta_1 Y_1 - \lambda_2\delta_2 Y_2 \right) dt
    + \delta_1d\tilde{W}_1 + \delta_2d\tilde{W}_2 \\
    &= - \lambda_2 \left( \delta_1 Y_1 + \delta_2 Y_2 \right) dt
    + \delta_1d\tilde{W}_1 + \delta_2d\tilde{W}_2 \\
    &= - \lambda_2 \left( R - \delta_0 \right) dt
    + \delta_1d\tilde{W}_1 + \delta_2d\tilde{W}_2 \\
    &= ( \lambda_2\delta_0 - \lambda_2 R ) dt
    + \delta_1d\tilde{W}_1 + \delta_2d\tilde{W}_2
  \end{align*}
  となる。
  マルチンゲールの項をブラウン運動の定数倍として書くために、
  \[B \dfn \delta_1\tilde{W}_1 + \delta_2\tilde{W}_2\]
  とおく。
  すると
  \begin{align*}
    (dB)^2 = (\delta_1^2 + \delta_2^2)dt
  \end{align*}
  となるので、
  \[
  \tilde{B} \dfn \frac{1}{\sqrt{\delta_1^2+\delta_2^2}}B
  \]
  とおけばこれはブラウン運動となる。
  このとき
  \[a=\lambda_2\delta_0, b=\lambda_2, \sigma=\sqrt{\delta_1^2+\delta_2^2}\]
  とおけば
  \[
  dR = (a-bR)dt + \sigma d\tilde{B}
  \]
  となることがわかる。
\end{proof}
















\begin{prob}\label{prob: 10.7}
  \begin{enumerate}
    \item \label{enumi: 10.7-1}
    \item \label{enumi: 10.7-2}
    \item \label{enumi: 10.7-3}
    \item \label{enumi: 10.7-4}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.7-1}。
  \(B(t,T) = e^{-C_1(T-t)Y_1(t)-C_2(T-t)Y_2(t)-A(t,T)}\)を
  \(T\)を固定して微分すれば
  \begin{align*}
    dB(t,T)
    &= -B(t,T)d(C_1(T-t)Y_1(t) + C_2(T-t)Y_2(t) + A(t,T)) \\
    &= -B(t,T)(C_1(T-t)dY_1(t) + C_2(T-t)dY_2(t) + A'(t,T)dt) \\
    &= (\text{\(dt\)項})
    - B(t,T)C_1(T-t)d\tilde{W}_1(t)
    - B(t,T)C_2(T-t)d\tilde{W}_2(t)
  \end{align*}
  となる。
  従って
  \begin{align*}
    \tilde{W}_j^T(t) = \int_0^TC_j(T-u)du + \tilde{W}_j(t)
  \end{align*}
  がわかる。

  \ref{enumi: 10.7-2}。
  満期\(\bar{T}\)の債権の時刻\(t\)でのリスク中立価格\(B(t,\bar{T})\)は
  \[
  B(t,\bar{T}) =
  \frac{1}{D(t)}\tilde{E}\left[ D(\bar{T})\middle| \mcF(t)\right]
  \]
  である。
  従って、このコール・オプションのペイオフは
  \(\left( B(T,\bar{T}) - K \right)^+\)であり、
  リスク中立価格は
  \[
  \tilde{E}\left[ D(T)\left( B(T,\bar{T}) - K \right)^+\middle| \mcF(t)\right]
  \]
  となる。
  これを\(T\)-フォワード測度に変換して計算すると、
  \begin{align*}
    &\tilde{E}\left[ D(T)\left( B(T,\bar{T}) - K \right)^+
    \middle| \mcF(t)\right] \\
    &= B(0,T)\tilde{E}\left[ \frac{D(T)}{B(0,T)}\middle| \mcF(t)\right]
    \cdot \tilde{E}^T\left[\left( B(T,\bar{T}) - K \right)^+
    \middle| \mcF(t)\right] \\
    &= \tilde{E}\left[ D(T)\middle| \mcF(t)\right]
    \cdot \tilde{E}^T\left[\left( B(T,\bar{T}) - K \right)^+
    \middle| \mcF(t)\right] \\
    &= D(t)B(t,T)
    \cdot \tilde{E}^T\left[\left( B(T,\bar{T}) - K \right)^+
    \middle| \mcF(t)\right]
  \end{align*}
  となる。
  \(t=0\)とすれば\(D(0)=1\)であるから所望の結果を得る。

  \ref{enumi: 10.7-3}。
  \(Y_1,Y_2\)はリスク中立測度のもとでのガウス過程である
  (cf. 10.2.1節の最後の二文)
  が、式(10.2.43)-(10.2.46)を\(T\)-フォワード測度に変換することで、
  同じ理屈により\(Y_1,Y_2\)は\(T\)-フォワード測度でもガウス過程であることがわかる。
  従ってとくにそれらの線形結合に定数を足した\(X\)は正規分布である。

  \ref{enumi: 10.7-4}。
  示さなければならないのは
  \[\tilde{\E}^T\left[(e^X-K)^+\right] = e^{\mu}N(d_+)-KN(d_-)\]
  である。
  \(X\)は平均\(\mu-\frac{1}{2}\sigma^2\)で分散\(\sigma^2\)の正規分布であるから、
  \begin{align*}
    &\tilde{\E}^T\left[(e^X-K)^+\right] \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}
    \left(e^x-K\right)^+e^{-(x-\mu+\frac{1}{2}\sigma^2)^2/2\sigma^2} dx \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}(e^x-K)\exp\left(
    -\frac{1}{2\sigma^2}\left(x-\mu+\frac{1}{2}\sigma^2\right)^2\right) dx \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    x-\frac{1}{2\sigma^2}\left(x-\mu+\frac{1}{2}\sigma^2\right)^2\right) dx \\
    &\ \ \ \ \ \
    - K\frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    -\frac{1}{2\sigma^2}\left(x-\mu+\frac{1}{2}\sigma^2\right)^2\right) dx \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    -\frac{1}{2\sigma^2}\left(
    x^2 + 2x\left(-\mu+\frac{1}{2}\sigma^2\right)
    + \left(-\mu+\frac{1}{2}\sigma^2\right)^2
    - 2\sigma^2x \right) \right) dx \\
    &\ \ \ \ \ \
    - K\frac{1}{\sqrt{2\pi}\sigma}\int_{-\mu+\log K+\frac{1}{2}\sigma^2}^{\infty}
    e^{-x^2/2\sigma^2} dx \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    -\frac{1}{2\sigma^2}\left(
    x^2 + 2x\left(-\mu-\frac{1}{2}\sigma^2\right)
    + \left(-\mu+\frac{1}{2}\sigma^2\right)^2 \right)\right) dx \\
    &\ \ \ \ \ \
    - K\frac{1}{\sqrt{2\pi}}\int_{-d_-}^{\infty}e^{-x^2/2} dx \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    -\frac{1}{2\sigma^2}\left(
    \left(x -\mu-\frac{1}{2}\sigma^2\right)^2
    - \left( \mu+\frac{1}{2}\sigma^2\right)^2
    + \left(-\mu+\frac{1}{2}\sigma^2\right)^2
    \right)\right) dx - KN(d_-) \\
    &= \frac{1}{\sqrt{2\pi}\sigma}\int_{\log K}^{\infty}\exp\left(
    -\frac{1}{2\sigma^2}\left(
    \left(x -\mu-\frac{1}{2}\sigma^2\right)^2
    - 2\mu\sigma^2 \right)\right) dx - KN(d_-) \\
    &= \frac{1}{\sqrt{2\pi}\sigma}e^{\mu}
    \int_{\log K-\mu-\frac{1}{2}\sigma^2}^{\infty}
    e^{-\frac{1}{2\sigma^2}x^2} dx - KN(d_-) \\
    &= \frac{1}{\sqrt{2\pi}}e^{\mu}\int_{-d_+}^{\infty}
    e^{-x^2/2} dx - KN(d_-) \\
    &= e^{\mu}N(d_+) - KN(d_-)
  \end{align*}
  と計算できる。
  これは所望の結果である。
\end{proof}















\begin{prob}\label{prob: 10.8}
  \begin{enumerate}
    \item \label{enumi: 10.8-1}
    \item \label{enumi: 10.8-2}
    \item \label{enumi: 10.8-3}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.8-1}。
  言われた通りに積分の順序を入れ替えるだけ。

  \ref{enumi: 10.8-2}。
  \(\int_0^t\hat{\alpha}(u,t,T)du\)を\(t\)で微分すると、
  \begin{align*}
    &\frac{\partial}{\partial t} \int_0^t \hat{\alpha}(u,t,T) du \\
    &= \hat{\alpha}(t,t,T)
    + \int_0^t \frac{\partial}{\partial t} \hat{\alpha}(u,t,T) du \\
    &= \hat{\alpha}(t,t,T)
    + \int_0^t \left( \frac{\partial}{\partial t} \int_t^T \alpha(u,v) dv
    \right) du \\
    &= \hat{\alpha}(t,t,T) - \int_0^t \alpha(u,t) du \\
    &= \int_t^T\alpha(t,v)dv - \int_0^t \alpha(u,t) du
  \end{align*}
  となる。
  とくに
  \[
  d\left( \int_0^t \hat{\alpha}(u,t,T) du\right)
  = \left( \int_t^T\alpha(t,v)dv\right)dt
  - \left( \int_0^t \alpha(u,t) du\right)dt
  \]
  となる。
  同じく
  \begin{align*}
    &d\left( \int_0^t \hat{\sigma}(u,t,T) dW(u)\right) \\
    &= \hat{\sigma}(t,t,T) dW(u)
    + \left( \int_0^t \left( \frac{d}{dt}\hat{\sigma}(u,t,T)
    \right) dW(u) \right)dt \\
    &= \hat{\sigma}(t,t,T) dW(u)
    + \left( \int_0^t \left( \frac{d}{dt}\int_t^T\sigma(u,v)
    dv \right) dW(u) \right) dt \\
    &= \hat{\sigma}(t,t,T) dW(u)
    - \left( \int_0^t \sigma(u,t) dW(u) \right) dt \\
    &= \left( \int_t^T\sigma(t,v)dv \right) dW(u)
    - \left( \int_0^t \sigma(u,t) dW(u) \right) dt
  \end{align*}
  となる。
  以上より
  \begin{align*}
    &- d\left( \int_t^Tf(t,v)dv \right) \\
    &= f(0,t)dt
    - \left( \int_t^T\alpha(t,v)dv\right)dt
    + \left( \int_0^t \alpha(u,t) du\right)dt \\
    &\ \ \ \ \ \ \ \
    - \left( \int_t^T\sigma(t,v)dv \right) dW(u)
    + \left( \int_0^t \sigma(u,t) dW(u) \right) dt
  \end{align*}
  となる。

  \ref{enumi: 10.8-3}。
  式(10.3.4)、式(10.3.5)、これまでの結果、それと式(10.3.9)により
  \begin{align*}
    R(t)dt &= f(t,t)dt \\
    &= f(0,t)dt + \left( \int_0^t\alpha(u,t)du \right) dt
    + \left( \int_0^t\sigma(u,t)dW(u) \right) dt \\
    &= \left( \int_t^T\alpha(t,v)dv\right) dt
    + \left( \int_t^T\sigma(t,v)dv \right) dW(u)
    - d\left( \int_t^Tf(t,v)dv \right) \\
    &= \alpha^*(t,T) dt
    + \sigma^*(t,T) dW(u)
    - d\left( \int_t^Tf(t,v)dv \right)
  \end{align*}
  となる。
  これを整理すれば式(10.3.10)を得る。
\end{proof}











\begin{prob}\label{prob: 10.9}
  \begin{enumerate}
    \item \label{enumi: 10.9-1}
    \item \label{enumi: 10.9-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.9-1}。
  無裁定条件が与えられた式の形であることを示す問題である。
  10.3.2節と10.3.3節の議論をそのまま真似るだけ。
  普通に無裁定条件を考えると、
  \(D(t)B(t,T)\)がマルチンゲールとなるような測度、
  つまりリスク中立測度が存在するための条件を考えれば良い。
  そのような測度は (多次元) ギルザノフの定理によって構成されるので、
  まずは\(D(t)B(t,T)\)の微分を計算して、
  ギルザノフの定理の形にもっていく。

  \(B\)の定義やそれらの微分は、
  式(10.3.3)より、
  \begin{alignat*}{3}
    &B(t,T) & &= \exp\left( -\int_t^Tf(t,v)dv\right), \\
    &dB(t,T) & &=
    B(t,T)d\left( -\int_t^Tf(t,v)dv\right)
    + \frac{1}{2}B(t,T)\left(d\left( -\int_t^Tf(t,v)dv\right)\right)^2,
  \end{alignat*}
  となるので、
  まずは\(d\left( -\int_t^Tf(t,v)dv \right)\)を計算する必要がある。
  これを計算すると、
  \begin{align*}
    &d\left( -\int_t^Tf(t,v)dv \right) \\
    &= f(t,t)dt - \int_t^Tdf(t,v)dv \\
    &\overset{\bigstar}{=} R(t)dt - \int_t^T\left( \alpha(t,v)dt
    + \sum_{j=1}^d\sigma_j(t,v)dW_j(t)\right)dv \\
    &\overset{\spadesuit}{=} R(t)dt
    - \left( \int_t^T \alpha(t,v)dv \right) dt
    - \sum_{j=1}^d\left(\int_t^T \sigma_j(t,v) dv\right) dW_j(t) \\
    &\overset{\clubsuit}{=} R(t)dt
    - \alpha^*(t,T) dt
    - \sum_{j=1}^d \sigma_j^*(t,T) dW_j(t)
  \end{align*}
  となる。
  ただし\(\bigstar\)の箇所は\(R(t)=f(t,t)\)を用い、
  \(\spadesuit\)積分の順序を入れ替え、
  \(\clubsuit\)の箇所は
  \begin{align*}
    &\alpha^*(t,T) \dfn \int_t^T \alpha(t,v)dv, \\
    &\sigma_j^*(t,T) \dfn \int_t^T \sigma_j(t,v) dv, \ \ \ (j=1,\cdots,d),
  \end{align*}
  とおいた。
  とくに
  \begin{align*}
    &\left(d\left( -\int_t^Tf(t,v)dv\right)\right)^2 \\
    &= \left( R(t)dt
    - \alpha^*(t,T) dt
    - \sum_{j=1}^d \sigma_j^*(t,T) dW_j(t)\right) \\
    &= \sum_{j=1}^d \left(\sigma_j^*(t,T)\right)^2dt
  \end{align*}
  となる。
  次に\(D(t)B(t,T)\)の微分を計算すると、
  \begin{align*}
    &d(D(t)B(t,T)) \\
    &= B(t,T)dD(t) + D(t)dB(t,T) \\
    &= -R(t)D(t)B(t,T)dt + D(t)B(t,T)
    \left( d\left( -\int_t^Tf(t,v)dv \right)
    + \frac{1}{2}\left(d\left( -\int_t^Tf(t,v)dv\right)\right)^2\right) \\
    &= D(t)B(t,T)\left( -R(t)dt
    + \left( R(t)dt
    - \alpha^*(t,T) dt
    - \sum_{j=1}^d \sigma_j^*(t,T) dW_j(t) \right)
    + \frac{1}{2}\sum_{j=1}^d \left(\sigma_j^*(t,T)\right)^2 dt \right)  \\
    &= - D(t)B(t,T)\left( \left( \alpha^*(t,T)
    - \frac{1}{2}\sum_{j=1}^d \left(\sigma_j^*(t,T)\right)^2 \right) dt
    + \sum_{j=1}^d \sigma_j^*(t,T) dW_j(t) \right)
  \end{align*}
  となる。
  カッコ内が
  \[
  \sum_{j=1}^d \sigma_j^*(t,T) \left( \Theta_j(t)dt + dW_j(t)\right)
  \]
  と整理できれば、
  ギルザノフの定理により構成される新たな測度\(\tilde{\P}\)のもとで
  \(d\tilde{W}(t) = \Theta_j(t)dt + \sigma_j^*(t,T)dW_j(t)\)
  により定義される確率過程\(\tilde{W}_j\)はブラウン運動となり、
  さらにこのとき
  \[
  d(D(t)B(t,T)) = - D(t)B(t,T) \sum_{j=1}^d \sigma_j^*(t,T) d\tilde{W}_j(t)
  \]
  となって\(D(t)B(t,T)\)は\(\tilde{\P}\)のもとでマルチンゲールとなる。
  以上よりリスク中立測度が存在するためには
  \[
  \left( \alpha^*(t,T)
  - \frac{1}{2}\sum_{j=1}^d \left(\sigma_j^*(t,T)\right)^2 \right) dt
  + \sum_{j=1}^d \sigma_j^*(t,T) dW_j(t)
  = \sum_{j=1}^d \sigma_j^*(t,T) \left( \Theta_j(t)dt + dW_j(t)\right)
  \]
  となる\(\Theta_j(t)\)があれば良い、ということになる。
  \(dW_j(t)\)の係数は両辺で同じなので、\(dt\)の係数を比較すると
  \[
  \alpha^*(t,T) - \frac{1}{2}\sum_{j=1}^d \left(\sigma_j^*(t,T)\right)^2
  = \sum_{j=1}^d\sigma_j^*(t,T)\Theta_j(t)
  \]
  を得る。
  \(T\)で両辺を微分すれば
  \[
  \alpha(t,T) - \sum_{j=1}^d \sigma_j(t,T)\sigma_j^*(t,T)
  = \sum_{j=1}^d\sigma_j(t,T)\Theta_j(t)
  \]
  となり、整理すれば
  \[
  \alpha(t,T) = \sum_{j=1}^d \sigma_j(t,T)
  \left( \sigma_j^*(t,T) + \Theta_j(t)\right)
  \]
  を得る。
  これは所望の等式である。

  \ref{enumi: 10.9-2}。
  \ref{enumi: 10.9-1}で得られた式を整理すると
  \[
  \alpha(t,T) - \sum_{j=1}^d \sigma_j(t,T) \sigma_j^*(t,T)
  = \sum_{j=1}^d \sigma_j(t,T)\Theta_j(t)
  \]
  となるので、\(T=T_1,\cdots,T_d\)を入れれば
  \(d\)個の等式
  \[
  \alpha(t,T_i) - \sum_{j=1}^d \sigma_j(t,T_i) \sigma_j^*(t,T_i)
  = \sum_{j=1}^d \sigma_j(t,T_i)\Theta_j(t)
  \]
  を得る。
  これらの等式を縦に並べて
  \(\left(\sigma_j(t,T_i)\right)_{ij}\)の逆行列を左からかければ
  \(\Theta_j(t)\)について解くことができる。
  従ってとくに\(\Theta_j\)は一意である。
\end{proof}




\begin{prob}\label{prob: 10.10}
  \begin{enumerate}
    \item \label{enumi: 10.10-1}
    \item \label{enumi: 10.10-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 10.10-1}。
  今の状況を整理すると、
  \(a(t),b(t),\sigma(t)\)は時刻について確定的な正値の関数で、
  \begin{align*}
    &\beta(t,R(t)) = a(t) - b(t)R(t), \\
    &\gamma(t,R(t)) = \sigma(t), \\
    &C'(t,T) = b(t)C(t,T) - 1, \\
    &A'(t,T) = -a(t)C(t,T) + \frac{1}{2}\sigma^2(t)C^2(t,T),
  \end{align*}
  となっている。
  \(C'(t,T),A'(t,T)\)を\(T\)で微分すれば、上の等式より、
  \begin{align*}
    &\frac{\partial}{\partial T}C'(t,T)
    = b(t) \frac{\partial}{\partial T}C(t,T), \\
    &\frac{\partial}{\partial T}A'(t,T)
    = - a(t) \frac{\partial}{\partial T}C(t,T)
    + \sigma^2(t)C(t,T)\frac{\partial}{\partial T}C(t,T),
  \end{align*}
  を得る。
  これを式(10.3.27)の左辺に代入して整理すれば、
  \begin{align*}
    &\frac{\partial}{\partial T}C(t,T)\beta(t,R(t))
    + R(t)\frac{\partial}{\partial T}C'(t,T)
    + \frac{\partial}{\partial T}A'(t,T) \\
    &= \frac{\partial}{\partial T}C(t,T)\left( a(t) - b(t)R(t) \right)
    + R(t)b(t) \frac{\partial}{\partial T}C(t,T) \\
    &\ \ \ \ \ \ \ \
    + \frac{\partial}{\partial T}
    \left( - a(t) \frac{\partial}{\partial T}C(t,T)
    + \sigma^2(t)C(t,T)\frac{\partial}{\partial T}C(t,T) \right) \\
    &= \sigma^2(t)C(t,T)\frac{\partial}{\partial T}C(t,T) \\
    &= C(t,T)\frac{\partial}{\partial T}C(t,T)\gamma^2(t,R(t))
  \end{align*}
  となる。
  これは所望の結果である。

  \ref{enumi: 10.10-2}。
  今の状況を整理すると、
  \(a,b,\sigma\)は正の定数で、
  \begin{align*}
    &\beta(t,R(t)) = a - bR(t), \\
    &\gamma(t,R(t)) = \sigma\sqrt{R(t)}, \\
    &C'(t,T) = bC(t,T) + \frac{1}{2}\sigma^2C^2(t,T) - 1, \\
    &A'(t,T) = - aC(t,T),
  \end{align*}
  となっている。
  \(C'(t,T),A'(t,T)\)を\(T\)で微分すれば、上の等式より、
  \begin{align*}
    &\frac{\partial}{\partial T}C'(t,T)
    = b\frac{\partial}{\partial T}C(t,T)
    + \sigma^2C(t,T)\frac{\partial}{\partial T}C(t,T), \\
    &\frac{\partial}{\partial T}A'(t,T)
    = - a\frac{\partial}{\partial T}C(t,T),
  \end{align*}
  を得る。
  これを式(10.3.27)の左辺に代入して整理すれば、
  \begin{align*}
    &\frac{\partial}{\partial T}C(t,T)\beta(t,R(t))
    + R(t)\frac{\partial}{\partial T}C'(t,T)
    + \frac{\partial}{\partial T}A'(t,T) \\
    &= \frac{\partial}{\partial T}C(t,T)\left( a-bR(t) \right)
    + R(t)\left( b\frac{\partial}{\partial T}C(t,T)
    + \sigma^2C(t,T)\frac{\partial}{\partial T}C(t,T) \right)
    + \left( - a\frac{\partial}{\partial T}C(t,T)\right) \\
    &= \sigma^2R(t)C(t,T)\frac{\partial}{\partial T}C(t,T) \\
    &= C(t,T)\frac{\partial}{\partial T}C(t,T)\gamma^2(t,R(t))
  \end{align*}
  となる。これは所望の結果である。
\end{proof}



\begin{prob}\label{prob: 10.11}
\end{prob}

\begin{proof}
  各金利支払い日\(T_j\)で
  \(\delta K - \delta L(T_{j-1},T_{j-1})\)のペイオフがある。
  各々の初期価格は定理10.4.1と
  \(B(t,T) = \tilde{\E}\left[ D(T)\middle| \mcF(t)\right]\)より
  \begin{align*}
    &\tilde{\E}\left[ D(T_j)
    \left( \delta K - \delta L(T_{j-1},T_{j-1})\right)\right] \\
    &= \delta K\tilde{\E}\left[D(T_j)\right]
    - \delta \tilde{\E}\left[ D(T_j)L(T_{j-1},T_{j-1})\right] \\
    &= \delta KB(0,T_j) - \delta B(0,T_j)L(0,T_{j-1})
  \end{align*}
  であるから、これらを全て足し合わせることで所望の等式を得る。
\end{proof}










\begin{prob}\label{prob: 10.12}
\end{prob}

\begin{proof}
  \(S(t)\)を時刻\(T+\delta\)でペイオフ\(L(T,T)\)となる
  金利スワップの時刻\(t\)でのリスク中立価格とする。
  このときリスク中立価格評価式より
  \[
  D(t)S(t) = \tilde{\E}\left[ D(T+\delta)L(T,T) \middle| \mcF(t) \right]
  \]
  となる。
  \(L(t,T) = \frac{1}{\delta}\left( \frac{B(t,T)}{B(t,T+\delta)}-1\right)\)
  であるから、
  とくに\(T \leq t \leq T+\delta\)のときは
  \(L(T,T)\)は\(\mcF(t)\)-可測であり、従って
  \[
  D(t)S(t) = L(T,T)\tilde{\E}\left[ D(T+\delta) \middle| \mcF(t) \right]
  = D(t)B(t,T+\delta)L(T,T)
  \]
  となる。
  両辺を\(D(t)\)で割れば定理(10.4.1)の式を得る。

  \(0\leq t\leq T\)のとき。
  \(L(T,T)\)は\(\mcF(T)\)-可測であるから、
  \begin{align*}
    D(t)S(t)
    &= \tilde{\E}\left[ D(T+\delta)L(T,T) \middle| \mcF(t) \right] \\
    &= \tilde{\E}\left[ D(T+\delta)\frac{1}{\delta}
    \left( \frac{B(T,T)}{B(T,T+\delta)} - 1 \right) \middle|\mcF(t) \right] \\
    &= \frac{1}{\delta}\tilde{\E}\left[ \tilde{\E}\left[ D(T+\delta)
    \left( \frac{1}{B(T,T+\delta)} - 1 \right)
    \middle|\mcF(T) \right] \middle|\mcF(t) \right] \\
    &= \frac{1}{\delta}\tilde{\E}\left[
    \tilde{\E}\left[ D(T+\delta) \middle|\mcF(T) \right]
    \left( \frac{1}{B(T,T+\delta)} - 1 \right) \middle|\mcF(t) \right] \\
    &= \frac{1}{\delta} \tilde{\E}\left[ D(T)B(T,T+\delta)
    \left( \frac{1}{B(T,T+\delta)} - 1 \right) \middle|\mcF(t) \right] \\
    &= \frac{1}{\delta} \tilde{\E}\left[ D(T)(1-B(T,T+\delta))
    \middle|\mcF(t) \right] \\
    &= \frac{1}{\delta} \left( D(t)B(t,T)-D(t)B(t,T+\delta) \right) \\
    &= D(t)B(t,T+\delta)\frac{1}{\delta}
    \left( \frac{B(t,T)}{B(t,T+\delta)}-1 \right) \\
    &= D(t)B(t,T+\delta)L(t,T)
  \end{align*}
  となる。
  両辺を\(D(t)\)で割れば定理(10.4.1)の式を得る。
  とくに\(t=0\)のときが本問題である。
\end{proof}























\newpage

\section{ジャンプ過程入門}\label{section: 11}


\begin{prob}\label{prob: 11.1}
  \begin{enumerate}
    \item \label{enumi: 11.1-1}
    \item \label{enumi: 11.1-2}
  \end{enumerate}
\end{prob}

\begin{proof}
  \ref{enumi: 11.1-2}が正しければ、
  \(0\leq s< t \)に対して
  \begin{align*}
    \E\left[ M^2(t)-\lambda t \middle| \mcF(s) \right]
    &= M^2(s) - \lambda s
  \end{align*}
  となるので整理することで
  \[
  \E\left[ M^2(t) \middle| \mcF(s) \right]
  = M^2(s) + \lambda (t-s) \geq M^2(s)
  \]
  を得て、\(M^2\)が劣マルチンゲールであること、
  つまり\ref{enumi: 11.1-1}が示される。
  よって\ref{enumi: 11.1-2}のみ示せば良い。
  \(N(t)-N(s)\)が\(\mcF(s)\)と独立であり
  \(\E[N(t)-N(s)]=\lambda(t-s)\)であることに注意すると、
  \begin{align*}
    &\E\left[ M^2(t)-\lambda t \middle| \mcF(s) \right] \\
    &= \E\left[ \left( M^2(t)-\lambda t \right)
    - \left( M^2(s) - \lambda s \right)\middle| \mcF(s) \right]
    + M^2(s) - \lambda s \\
    &= \E\left[ \left( N^2(t)-2\lambda t N(t)+\lambda^2 t^2 - \lambda t \right)
    - \left( N^2(s)-2\lambda s N(s)+\lambda^2 s^2 - \lambda s \right)
    \middle| \mcF(s) \right] \\
    &\ \ \ \ \ \ \ \
    + M^2(s) - \lambda s \\
    &= \E\left[ \left( N^2(t)-2\lambda t N(t) \right)
    - \left( N^2(s)-2\lambda s N(s) \right) \middle| \mcF(s) \right] \\
    &\ \ \ \ \ \ \ \
    + \lambda^2(t^2-s^2) - \lambda (t-s) M^2(s) - \lambda s \\
    &= \E\left[ \left( N(t) - N(s)\right)^2 + 2N(s)\left( N(t) - N(s) \right)
    - 2\lambda \left( tN(t) - sN(s) \right) \middle| \mcF(s) \right] \\
    &\ \ \ \ \ \ \ \
    + \lambda^2(t^2-s^2) - \lambda (t-s) M^2(s) - \lambda s \\
    &= \E\left[ \left( N(t) - N(s)\right)^2\right]
    + \E\left[ 2N(s)\left( N(t) - N(s) \right)\right] \\
    &\ \ \ \ \ \ \ \
    - 2\lambda \E\left[ t(N(t)-N(s)) + N(s)(t-s) \middle| \mcF(s) \right] \\
    &\ \ \ \ \ \ \ \ \ \ \ \ \ \
    + \lambda^2(t^2-s^2) - \lambda (t-s) M^2(s) - \lambda s \\
    &= \E\left[ \left( N(t) - N(s)\right)^2\right]
    + 2N(s)\E\left[ N(t) - N(s) \right]
    - 2\lambda t\E\left[ N(t) - N(s) \right] \\
    &\ \ \ \ \ \ \ \
    - 2\lambda N(s)(t-s) + \lambda^2(t^2-s^2)
    - \lambda (t-s) M^2(s) - \lambda s \\
    &= \E\left[ \left( N(t) - N(s)\right)^2\right]
    - 2\lambda^2 t(t-s) + \lambda^2(t^2-s^2) - \lambda (t-s) + M^2(s) - \lambda s \\
    &= \E\left[ \left( N(t) - N(s)\right)^2\right]
    - \lambda^2(t-s)^2 - \lambda (t-s) + M^2(s) - \lambda s
  \end{align*}
  となる。
  ここで\(\left( N(t) - N(s)\right)^2\)の平均が
  \(\lambda^2(t-s)^2 + \lambda (t-s)\)であることから、
  計算結果は\(M^2(s)-\lambda s\)となる。
  以上で示された。
\end{proof}





















\begin{prob}\label{prob: 11.2}
\end{prob}

\begin{proof}
  \(0 \leq \tau_{k+1} \leq t\)となるとき
  \(N(s) = k, N(s+t) = k+1\)となり、
  \(t < \tau_{k+1}\)となるとき
  \(N(s) = k, N(s+t) = k\)となる。
  つまり最初の二つの確立は
  たんに\(0 \leq \tau_{k+1} \leq t\)となる確率を計算する問題である。
  \(\tau_{k+1}\)が指数分布であることから、その確率は
  \(1-e^{-\lambda t}\)であり、
  この近似は\(\lambda t + O(t^2)\)である。
  よって\(N(s)=k\)のもとで\(N(s+t)=k+1\)となる確率は\(\lambda t+O(t^2)\)であり、
  \(N(s) = k\)のもとで\(N(s+t) = k\)となる確率は\(1-\lambda t + O(t^2)\)である。

  最後に、\(s+t\)までに二回ジャンプする確率は、
  \(0\leq \tau_{k+1},\tau_{k+2} \leq t\)となる確率以下であるから、
  とくに\(O(t^2)\)で抑えられる。
\end{proof}




















\begin{prob}\label{prob: 11.3}
\end{prob}

\begin{proof}
  普通に計算すると、\(0\leq s < t\)に対し、
  \begin{align*}
    &\E\left[S(t)\middle|\mcF(s)\right] \\
    &= S(s)\cdot \E\left[ S(t)S^{-1}(s)\middle|\mcF(s)\right] \\
    &= S(s)\cdot \E\left[
    (\sigma + 1)^{N(t)-N(s)}e^{-\lambda\sigma(t-s)}
    \middle|\mcF(s)\right] \\
    &= S(s)e^{-\lambda\sigma(t-s)}\cdot
    \E\left[ (\sigma + 1)^{N(t)-N(s)} \right] \\
    &= S(s)e^{-\lambda\sigma(t-s)}\cdot
    \sum_{k=0}^{\infty}(\sigma + 1)^k\frac{\lambda^k(t-s)^k}{k!}
    e^{-\lambda(t-s)}\\
    &= S(s)e^{-\lambda (\sigma+1)(t-s)}
    \sum_{k=0}^{\infty}(\sigma + 1)^k\frac{\lambda^k(t-s)^k}{k!} \\
    &= S(s)
  \end{align*}
  となるので\(S(t)\)はマルチンゲールである。
\end{proof}

















\begin{prob}\label{prob: 11.4}
\end{prob}

\begin{proof}
  まず補正ポアソン過程
  \(M_1(t)=N_1(t)-\lambda_1t, M_2(t)=N_2(t)-\lambda_2t\)
  は各\(t\)で独立であり、
  さらにどちらもマルチンゲール (定理11.2.4) であるから、
  \[\E[M_1(t)M_2(t)]=\E[M_1(t)]\E[M_2(t)]=M_1(0)M_2(0)=0\]
  となる。
  次に積の公式 (系11.5.5) を用いると
  \begin{align*}
    M_1(t)M_2(t)
    &= \int_0^tM_1(-s)dM_2(s) + \int_0^tM_2(-s)dM_1(s)
    + [M_1,M_2](t)
  \end{align*}
  となる。
  \(M_1(-s),M_2(-s)\)は左連続で\(M_1(t),M_2(t)\)はマルチンゲールであるから、
  定理11.4.5より二つの伊藤積分はそれぞれマルチンゲールである。
  以上より\([M_1,M_2](t)\)もマルチンゲールとなる。
  二次変分を計算するには、定理11.4.7を用いれば良い。
  ここで\(M_i(t)\)が補正ポアソン過程であることから、
  \(M_i(t)\)の伊藤積分の項、
  つまり定理11.4.7の\(\Gamma\)にあたる過程は、恒等的に\(0\)であり、
  従って二次変分は同時に行われたジャンプの積み重ね、
  すなわち次のようになる：
  \[
  [M_1,M_2](t) = \sum_{0< s \leq t}
  \left(N_1(s-)-N(s)\right)\left(N_2(s-)-N_2(s)\right).
  \]
  \(N_i(s)\)は単調増加であるから、上の式は非負である。
  よって、ほとんど確実に同時にジャンプすることがない、ということを示すには、
  同時のジャンプの積み重ねの期待値が\(0\)であれば良い。
  だがそれは\([M_1,M_2](t)\)のマルチンゲール性より従う。
  以上で示された。
\end{proof}














\begin{prob}\label{prob: 11.5}
\end{prob}

\begin{proof}
  \begin{align*}
    &f(t,x_1,x_2) \dfn \exp \left( u_1x_1 + u_2x_2
    - \lambda (e^{u_1}-1)t - \lambda (e^{u_2}-1)t\right), \\
    &Y(t) \dfn f(t,N_1(t),N_2(t)),
  \end{align*}
  とおく。
  \begin{align*}
    &f_t = - \lambda \left( e^{u_1} + e^{u_2} - 2 \right)f(t,x_1,x_2), \\
    &N_i^c(t) = 0, \ \ \ (i=1,2), \\
    &Y(0) = 1,
  \end{align*}
  となる。
  \(Y(t)\)がマルチンゲールであることを証明したい。
  \(N_1(t),N_2(t)\)はほとんど確実に同時にジャンプすることはないので、
  そのためには、\(N_1(t),N_2(t)\)は同時にジャンプしないとしてよい。
  すると
  \begin{align*}
    &f(s,N_1(s),N_2(s)) - f(s,N_1(s-),N_2(s-)) \\
    &= f(s,N_1(s-),N_2(s-))
    \left( \exp(u_1(N_1(s)-N_1(s-))+u_2(N_2(s)-N_2(s-)) - 1\right) \\
    &= (e^{u_1}-1)f(s,N_1(s-),N_2(s-))\Delta N_1 \ \ \text{または} \ \
    (e^{u_2}-1)f(s,N_1(s-),N_2(s-))\Delta N_2, \\
    &= (e^{u_1}-1)f(s,N_1(s-),N_2(s-))\Delta N_1
    + (e^{u_2}-1)f(s,N_1(s-),N_2(s-))\Delta N_2,
  \end{align*}
  となる。
  ここで
  \(M_i(s) = N_i(s) - \lambda s , (i=1,2)\)とおけば、
  伊藤の公式より
  \begin{align*}
    Y(t)
    &= 1 + \int_0^t f_t(s,N_1(s),N_2(s))ds
    + \sum_{0 < s \leq t}\left(
    f(s,N_1(s),N_2(s)) - f(s,N_1(s-),N_2(s-)) \right) \\
    &= 1 - \lambda \left( e^{u_1} + e^{u_2} - 2 \right)
    \int_0^t f(s,N_1(s),N_2(s)) ds \\
    &\ \ \ \ \ \
    + \sum_{0 < s \leq t} \left( (e^{u_1}-1)f(s,N_1(s-),N_2(s-))\Delta N_1
    + (e^{u_2}-1)f(s,N_1(s-),N_2(s-))\Delta N_2 \right) \\
    &= 1 + (e^{u_1}-1)\int_0^tf(s,N_1(s-),N_2(s-))dM_1(s)
    + (e^{u_2}-1)\int_0^tf(s,N_1(s-),N_2(s-))dM_2(s)
  \end{align*}
  となる。
  \(M_i(t)\)はマルチンゲールであり、
  また\(f(s,N_1(s-),N_2(s-))\)は左連続であるから、
  積分の項はそれぞれマルチンゲールである。
  よって\(Y(t)\)もマルチンゲールであることがわかった。

  \(Y(t)\)はマルチンゲールであるから、
  \[
  \E[Y(t)] = Y(0) = 1
  \]
  がわかる。
  一方、\(Y(t)=f(t,N_1(t),N_2(t))\)の定義より、
  \begin{align*}
    \E[Y(t)]
    &= \E \left[  \exp \left( u_1N_1(t) + u_2N_2(t)
    - \lambda (e^{u_1}-1)t - \lambda (e^{u_2}-1)t\right) \right] \\
    &= \E \left[  \exp \left( u_1N_1(t) + u_2N_2(t)\right) \right]
    \cdot \exp\left( - \lambda (e^{u_1}-1)t - \lambda (e^{u_2}-1)t\right)
  \end{align*}
  であり、
  以上より
  \[
  \E \left[  \exp \left( u_1N_1(t) + u_2N_2(t)\right) \right]
  = \exp \left( \lambda (e^{u_1}-1)t\right)
  \exp \left(\lambda (e^{u_2}-1)t\right)
  \]
  となる。
  これは\(N_1(t),N_2(t)\)の同時積率母関数が
  それぞれの積率母関数の積に分かれることを主張しており、
  すなわち\(N_1(t),N_2(t)\)は独立であることを意味する。
\end{proof}








\begin{prob}\label{prob: 11.6}
\end{prob}

\begin{proof}
  \(Q(t) = \sum_{i=1}^{N(t)}Y_i\)となる
  同じ分布に従う確率変数の族\(Y_i\)がとれる。
  \(Y_i\)は同じ分布に従うので、
  各\(i\)に対して\(Y_i\)の積率母関数はどれも同じである。
  その関数を\(\varphi\)とおく。
  \begin{align*}
    &X(t) \dfn
    u_1W(t) + u_2Q(t) - \frac{1}{2}u_1^2t - \lambda(\varphi(u_2)-1)t, \\
    &Z(t) \dfn e^{X(t)},
  \end{align*}
  とおく。
  \(X(0)=0,Z(0)=1\)であるから、
  \autoref{prob: 11.5}と同様にして
  \(Z(t)\)がマルチンゲールであることを証明できれば良い。

  \(X(t)\)は
  \begin{itemize}
    \item 伊藤積分の項\(u_1W(t)\)、
    \item リーマン積分の項\(-\frac{1}{2}u_1^2t - \lambda(\varphi(u_2)-1)t\)、
    \item 純粋なジャンプ項\(u_2Q(t)\)、
  \end{itemize}
  からなるので、とくに
  \begin{align*}
    &dX^c(s) = u_1dW(s) - \frac{1}{2}u_1^2ds - \lambda(\varphi(u_2)-1)ds, \\
    &(dX^c(s))^2 = u_1^2ds,
  \end{align*}
  となる。
  また、\(Z\)が時刻\(s\)にジャンプすれば、
  \begin{align*}
    Z(s)-Z(s-)
    &= e^{X(s)}-e^{X(s-)} \\
    &= e^{X(s-)+u_2Y_{N(s)}}-e^{X(s-)} \\
    &= e^{X(s-)}\left( e^{u_2Y_{N(s)}}-1 \right) \\
    &= Z(s-)\left( e^{u_2Y_{N(s)}}-1 \right)\Delta N(s) \\
  \end{align*}
  となる。
  ここで\(R(t) \dfn \sum_{i=1}^{N(t)}\left( e^{u_2Y_i}-1 \right)\)
  とおく。これは複合ポアソン過程である。
  さらに
  \[
  R(s)-R(s-) = \left( e^{u_2Y_{N(s)}}-1 \right)\Delta N(s)
  \]
  となっているので、
  \[
  Z(s)-Z(s-) = Z(s-)\Delta R(s)
  \]
  となる。
  また、各\(e^{u_2Y_i}-1\)の平均は\(\varphi(u_2)-1\)であるから、
  定理11.3.1より
  過程\(S(t) \dfn R(t)-\lambda(\varphi(u_2)-1)t\)はマルチンゲールである。
  伊藤の公式より
  \begin{align*}
    Z(t)
    &= Z(0) + \int_0^t e^{X(s)}dX^c(s)
    + \frac{1}{2}\int_0^te^{X(s)}dX^c(s)dX^c(s)
    + \sum_{0<s\leq t}(Z(s)-Z(s-)) \\
    &= 1 + u_1\int_0^t Z(s)dW(s)
    - \frac{1}{2}u_1^2\int_0^t Z(s) ds
    - \lambda (\varphi(u_2)-1)\int_0^t Y(s) ds \\
    &\ \ \ \ \ \ \ \
    + \frac{1}{2}u_1^2\int_0^t Z(s) ds
    + \sum_{0<s\leq t}Z(s-)\left( e^{u_2Y_{N(s)}}-1 \right)\Delta N(s) \\
    &= 1 + u_1\int_0^t Z(s)dW(s)
    - \lambda (\varphi(u_2)-1)\int_0^t Z(s-) ds
    + \sum_{0<s\leq t}Z(s-)\left( e^{u_2Y_{N(s)}}-1 \right)\Delta N(s) \\
    &= 1 + u_1\int_0^t Z(s)dW(s)
    - \lambda (\varphi(u_2)-1)\int_0^t Z(s-) ds
    + \sum_{0<s\leq t}Z(s-)\Delta R(s) \\
    &= 1 + u_1\int_0^t Z(s)dW(s)
    - \int_0^t Z(s-) d(S(s)) \\
  \end{align*}
  となる。
  ここでブラウン運動による伊藤積分の項はマルチンゲールであり、
  また\(Z(s-)\)は左連続であって\(S(s)\)はマルチンゲールであるから
  最後の項もマルチンゲールとなる。
  以上で\(Z(t)\)はマルチンゲールとなり、
  所望の結果が得られた。
\end{proof}

\begin{prob}\label{prob: 11.7}
\end{prob}

\begin{proof}
  \(\mcF(t)\)を\(Q(t)\)を観測することで得られるfiltrationとする。
  \(x\)を変数として
  \(g(t,x) \dfn \E[h(Q(T)-Q(t)+x]\)とおく。
  \(Q(T)-Q(t)\)は\(\mcF(t)\)と独立で、
  \(Q(t)\)は\(\mcF(t)\)-可測なので、
  独立性の補題より
  \[
  \E\left[ h(Q(T)) \middle| \mcF(t) \right]
  = \E\left[ h(Q(T)-Q(t)+Q(t)) \middle| \mcF(t) \right]
  = g(t,Q(t))
  \]
  が成り立つ。
  これは複合ポアソン過程\(Q(t)\)がマルコフ過程であることを示している。
\end{proof}

\end{document}
